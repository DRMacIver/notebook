<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
    <title>
DRMacIver's Notebook: Thoughts from David R. MacIver
    </title>
    <link rel="stylesheet" href="/pygments.css"/>
    <link rel="stylesheet" href="/tufte.css"/>
    <link rel="stylesheet" href="/latex.css"/>
    <link rel="stylesheet" href="/drmnotes.css"/>
    <link rel="alternate" type="application/atom+xml" title="Atom Feed" href="/feed.xml" />

    <meta name="viewport" content="width=device-width, initial-scale=1">

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(', '\\)']]},
  multiLine: true,
  "HTML-CSS": { 
       linebreaks: { automatic: true }
  },
  SVG: { 
       linebreaks: { automatic: true } 
  }
});
</script>

  </head>

  <body>
    <article>
        <h1><a href="/">DRMacIver's Notebook</a></h1>
        <p class=subtitle>Thoughts from David R. MacIver</p>

        

<section>
<h2><a href="/posts/2018-10-13-10:21.html">2018-10-13</a></h2>


<p class="subtitle">Communicating Knowledge</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-10-13</dd>
</dl>


<p>
<a href="https://twitter.com/DRMacIver/status/1048166537172013056">
  Copied over from Twitter</a>
 so I don't lose this.</p>


<blockquote>
<p>
  My brain is currently trying to synthesise some stuff together that I'm not sure I can articulate in less than a Chidi-thesis worth of content and it's very annoying.</p>
<p>
  The following combine in a way that I have not yet been able to tease out a small t thesis from:</p>
<ul>
<li>
   "The Shock of the Old" - David Edgerton</li>
<li>
   "Shop Class as Soulcraft" - Matthew Crawford</li>
<li>
   "The Two Cultures of Mathematics" - Tim Gowers</li>
<li>
   "Telling is Listening" - Ursula Le Guin</li></ul>
<p>
  Roughly the area I am attempting to sound out is the idea of knowledge which is embodied in a person or a group, and cannot be separated from that without essentially rebuilding it from scratch (possibly with some gentle editing from a teacher who already understands it).</p>
<p>
  Physical skills are very much like this (you can't just read a book to learn a martial art), but I think we treat cognitive skills as if they're
  <em>
   not</em>
  like this, when they absolutely are, and we privilege knowledge based on how close it is to the ideal of transmissibility.</p></blockquote>


</section>
<section>
<h2><a href="/posts/2018-10-13-10:04.html">2018-10-13</a></h2>


<p class="subtitle">Implicit vs Explicit</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-10-13</dd>
</dl>


<p>
<a href="https://www.python.org/dev/peps/pep-0020/">
  The Zen of Python</a>
 :</p>


<ul>
<li>
  Beautiful is better than ugly.</li>
<li>
  Explicit is better than implicit.</li>
<li>
  Simple is better than complex.</li>
<li>
  Complex is better than complicated.</li>
<li>
  Flat is better than nested.</li>
<li>
  Sparse is better than dense.</li>
<li>
  Readability counts.</li>
<li>
  Special cases aren't special enough to break the rules.</li>
<li>
  Although practicality beats purity.</li>
<li>
  Errors should never pass silently.</li>
<li>
  Unless explicitly silenced.</li>
<li>
  In the face of ambiguity, refuse the temptation to guess.</li>
<li>
  There should be one-- and preferably only one --obvious way to do it.</li>
<li>
  Although that way may not be obvious at first unless you're Dutch.</li>
<li>
  Now is better than never.</li>
<li>
  Although never is often better than
  <em>
   right</em>
  now.</li>
<li>
  If the implementation is hard to explain, it's a bad idea.</li>
<li>
  If the implementation is easy to explain, it may be a good idea.</li>
<li>
  Namespaces are one honking great idea -- let's do more of those!</li></ul>


<p>
 The only one of these people seem to remember is "explicit is better than implicit".
Unfortunately, it falls afoul of the problem that almost all "X is better than Y" advice has,
which is that the important qualification "All else being equal" is left, well, implicit.</p>


<p>
 Explicit is more verbose than implicit. Explicit is more expensive than implicit. If you try to make everything explicit then you will
 <em>
  never get anything done</em>
 ,
because as with everything, being explicit has costs as well as benefits. Explicit may be better than implicit, but implicit is cheaper than explicit.
Everything is a trade-off.</p>


<p>
 It can be worth adjusting where you are in trade off space though - just because everything is a trade off doesn't mean you're automatically in the right region of trade off space,
and it's much easier to err in the direction of making things too explicit rather than too implicit.</p>


<p>
 Tying into past posts:</p>


<ul>
<li>
  One theme of the
  <a href="https://notebook.drmaciver.com/posts/2018-09-27-09:19.html">
   making difficult decisions discussion</a>
  is that making your decision making process explicit is often beneficial when you're struggling.</li>
<li>
  In
  <a href="https://notebook.drmaciver.com/posts/2018-10-09-09:57.html">
   Try not to think about it</a>
  I argued that for many decisions it's actually better to make them implicitly rather than explicitly, by building the answer into your habits and environment, because if you make them explicitly then you open up the possibility of making them incorrectly.</li></ul>


</section>
<section>
<h2><a href="/posts/2018-10-13-09:36.html">2018-10-13</a></h2>


<p class="subtitle">Beeminder for Enforced Participation</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-10-13</dd>
</dl>


<p>
 I'm a huge fan of
 <a href="https://www.beeminder.com/">
  beeminder</a>.
I was on a break with it for a while, not for any very good reason, but I've been back using it for a couple of months now, and it's really good to be back.</p>


<p>
 A lot of the things I've been using beeminder for recently are a sort of... "making the fundamental feature of Beeminder contagious".
The fundamental feature of Beeminder for me is that you cannot simply decide to give up on a goal - because the goal will charge you if you don't satisfy it,
and because you have to wait a week for changes to take effect, the choice to stop a goal has to be a deliberate decision planned out in advance.</p>


<p>
 This is fairly huge to me.</p>


<p>
 A lot of goals I've had recently are basically of the form "keep doing the thing". This allows me to create systems with this property - beeminder doesn't track my
 <em>
  success</em>
 at using the system, it just tracks that I'm doing it at all.</p>


<p>
 Examples:</p>


<ul>
<li>
  Writing in my journal</li>
<li>
  Keeping up my book kanban</li>
<li>
  This notebook</li>
<li>
  Using the day plan system</li></ul>


<p>
 The notebook and day plan goals do have some quantity attached to them but it's not that important. The journal and book goals literally all they track is "Did I do the thing today?". If yes, I get a point. If no, I don't.
I can do as much or as little as I like as long as I do
 <em>
  something</em>. The
 <a href="https://notebook.drmaciver.com/posts/2018-09-27-12:18.html">
  system itself is then what keeps me doing it well</a>
 , "all" beeminder is doing is keeping me participating in it.</p>


</section>
<section>
<h2><a href="/posts/2018-10-11-14:54.html">2018-10-11</a></h2>


<p class="subtitle">Stories about Data</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-10-11</dd>
</dl>


<p>
 Consider the difference between the following:</p>


<blockquote>
<p>
  The result was non-significant but when we split it up into N groups it became significant for subgroup Y. Therefore there is a significant effect for group Y.</p></blockquote>


<p>
 Versus:</p>


<blockquote>
<p>
  The result was non-significant but when we split it up into N groups it became significant for subgroup Y. Obviously this is invalid statistically, but that might be an interesting followup experiment to perform.</p></blockquote>


<p>
 It's OK to tell whatever stories you want about your data, as long as you make it clear which ones are and aren't valid inferences.</p>


</section>
<section>
<h2><a href="/posts/2018-10-11-13:37.html">2018-10-11</a></h2>


<p class="subtitle">Auto-parallelising test-case reduction</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-10-11</dd>
</dl>


<p>
 There's a new parallel test-case reducer called
 <a href="https://github.com/googleprojectzero/halfempty">
  half-empty</a>.</p>


<p>
 It uses what is a new to me approach to parallelisation but is apparently also what C-Reduce does, which they call pessimistic parallelism.
The basic idea is that you parallelise based on the assumption that what you're going to try isn't actually going to work, you fork a background process to check if it does actually work,
and the main calculation just proceeds as if it was false. If your assumption that it rarely works mostly holds true, this lets you turn what seem like highly sequential processes into highly parallel ones.</p>


<p>
 It occurred to me that you could fairly easily automate this in a way that lets you write a test-case reducer exactly as if it were sequential but have it magically automatically parallelised in the background.</p>


<p>
 The way it would work is this: You have some test case reducer state object which has a cached version of the predicate. You wrap a reduction pass in some special function (say a decorator in Python).
Now when you call the predicate from within the reduction pass what happens is as follows:</p>


<ol>
<li>
  If the result has already been cached, use that.</li>
<li>
  If the result
  <em>
   hasn't</em>
  been cached, return false and queue the result for background computation, which will update the cache when it is finished.</li>
<li>
  If at any point a backgrounded job returns true instead of false, clear the queue, wait for the current computations to finish, and then restart the reduction pass from the beginning.</li></ol>


<p>
 This makes a couple of assumptions:</p>


<ol>
<li>
  Running the full reduction pass is cheaper than running the predicate.</li>
<li>
  The predicate will rarely return true.</li></ol>


<p>
 Ways it might be useful to patch this:</p>


<ol>
<li>
  Keep the queue size bounded. When the test function calls the predicate and the queue is at capacity, have it block until the queue is emptier.</li>
<li>
  If the pessimistic assumption does not hold, e.g. say if at least 5 of the last 10 predicate calls were true, run the predicate in the foreground instead of backgrounding it.</li></ol>


<p>
 If you want a
 <em>
  really</em>
 cheeky approach (I don't think this will work), here's a neat trick you could try: Use some sort of classifier (language inference, machine learning, whatever) to predict the result of the predicate and use that,
invalidating when the parallel computation gets it wrong..
You could even just be very lazy and just predict whichever outcome is the most common.</p>


<p>
 Actually speaking of language learning, this approach would also work well for L* with a bit more tracking of dependencies, which would give you a fully parallel language learner.</p>


</section>
<section>
<h2><a href="/posts/2018-10-09-09:57.html">2018-10-09</a></h2>


<p class="subtitle">Try not to think about it</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-10-09</dd>
</dl>


<p>
 A useful general principle is "If you have to make a decision to do something, you will eventually get it wrong".
As a result, it is often useful to arrange things to avoid decision making, even when this results in redundant work.
This is especially true when one class of error is much more costly than the other.</p>


<p>
 Some examples:</p>


<ol>
<li>
  Always lock the car when you walk away from it, even if you don't think you need it. Locking the car when you don't need to is cheap, forgetting to lock the car when you need to is very expensive.</li>
<li>
  Leave useful things (chargers, clothing, etc) in places where you are likely to need them (work, a partner's flat, etc, your family home), so that if you forget to bring one there is already a supply there. Having extra stuff is fairly cheap, but forgetting stuff you need is super annoying.</li>
<li>
  Keep small stuff in your bag that is regularly useful, even if you probably don't need it on any given trip (e.g. I always carry a phone charger and a pencil case). Same reasons as above (although the added weight isn't entirely cheap).</li></ol>


</section>
<section>
<h2><a href="/posts/2018-10-07-12:34.html">2018-10-07</a></h2>


<p class="subtitle">Branch and Consolidate</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-10-07</dd>
</dl>


<p>
 Attention conservation notice: This note is even more note to self than then normally are, so may not make much sense.</p>


<p>
 The following implementation strategy has just occurred to me, for writing code that can be both a randomized algorithm and a dynamic programming solution for giving you the full distribution (you can also achieve this by just writing it abstracted by a suitable monad implementation of course).</p>


<p>
 Add two primitives:</p>


<ol>
<li>
<code>
   branch(n)</code>
  conceptually generates a uniform random number \(0, \ldots, n - 1\).</li>
<li>
<code>
   consolidate(data)</code>
  says "the rest of the computation is uniquely determined by this value".</li></ol>


<p>
 In random generation,
 <code>
  branch</code>
 has the obvious implementation and
 <code>
  consolidate</code>
 does nothing.</p>


<p>
 When doing the dynamic programming, we use the standard trick for exhaustively enumerating a tree of unknown shape:
Explore based on prefixes, filling with infinitely many zeroes for branches drawn past the prefix, and increment it lexicographically until we can't any more.
The difference is that whenever we call
 <code>
  consolidate</code>
 with a value we have already seen, we raise an exception to terminate the process and add an entry that says to use the final value.
Conceptually this is the same as just exhaustively enumerating all the possibilities, but with shortcuts.</p>


<p>
 At the end we just solve the obvious dynamic programming problem to calculate the probabilities.</p>


</section>
<section>
<h2><a href="/posts/2018-10-05-10:00.html">2018-10-05</a></h2>


<p class="subtitle">Maybe these two great flavours go together</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-10-05</dd>
</dl>


<p>
 A problem I have is that when trying to fix stuff I want to do too many things at once, and then I don't know which of them worked.</p>


<p>
 A thing that I just occurred to me is that I know rather a lot about test-case reduction.</p>


<p>
 Maybe these things could go together...</p>


<p>
 (You still have the problem that the things you try may interfere with each other but I think that's a lesser issue)</p>


<p>
 Really the proper frame for this is probably
 <a href="https://en.wikipedia.org/wiki/Group_testing">
  group testing</a>
 rather than test case reduction, but use what you know.</p>


</section>
<section>
<h2><a href="/posts/2018-10-05-07:24.html">2018-10-05</a></h2>


<p class="subtitle">Things you didn't know you can be bad at</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-10-05</dd>
</dl>


<p>
<a href="https://twitter.com/DRMacIver/status/1047976938843885568">
  Twitter thread by me</a>
 :</p>


<blockquote>
<p>
  I wonder how many things we're all going around doing badly because the idea of not knowing how to do them well seems too ridiculous to admit to.
Prompted by the fact that I'm reading about Buteyko breathing (with a certain amount of skepticism). On the one hand "You're breathing badly" seems like a ridiculous claim. On the other... who ever taught you to breathe? Are you sure you haven't self-taught bad habits?
But also prompted by recent conversations about conversation. You've probably never been taught to have a conversation. I've had exactly one class on it and it was in the last six months. I know damn well that many people have not self-taught this well...
In general there's this entire class of implicit skills that we mostly don't think of as skills, that we're entirely self-taught on, and that we practice sufficiently non-demonstratively that we can't easily watch what other people do. The result is a very personal skill idiolect</p></blockquote>


<p>
<a href="https://en.wikipedia.org/wiki/Idiolect">
  Idiolect</a>
 is a very good word BTW. Not enough people know and use it.</p>


<p>
 To unpack on this slightly from conversation in that thread, there are two things going on here:</p>


<ul>
<li>
  There are things which don't even look like skills, so people don't know that being good or bad at them is a thing.</li>
<li>
  Even once you point out the possibility of treating these things as skills, the idea that you might be bad at them seems ridiculous.</li></ul>


<p>
 Other people have pushed back on the notion of "bad". In some cases it's just "could be better". I do think in many cases bad is the right word though. For example if it's really true that overbreathing can cause or aggravate asthma, I think that would count at being bad at breathing.</p>


<p>
 Another example is that apparently
 <a href="https://www.npr.org/sections/health-shots/2018/02/26/587735283/lost-art-of-bending-over-how-other-cultures-spare-their-spines?t=1538691407256">
  westerners are apparently bad at bending over</a>.</p>


<p>
 Consider also the way this shows up in our use of language: Someone
 <em>
  has bad posture</em>
 rather than
 <em>
  being bad at posture</em>.</p>


<p>
<a href="https://twitter.com/ryan_nayr_/status/1047971341008130048">
  From ryan on Twitter</a></p>


<blockquote>
<p>
  Things you do very frequently and are thus worth a counterintuitive amount of attention/optimization:
  <em>
   Sleep</em>
  Sit
  <em>
   Walk</em>
  Work
  <em>
   Commute</em>
  Read
  <em>
   Eat</em>
  Drink water
  <em>
   Type</em>
  Decide who to spend time with
* Browse distractions</p>
<p>
  Additions?</p></blockquote>


<p>
 I think I actually
 <em>
  do</em>
 spend a counterintuitive amount of time and attention working on most of these. The only ones I don't do much about in particular are "type" and "drink water", but I feel like I'm already way on the good end of the bell curve of those (actually I probably drink
 <em>
  too much</em>
 water if anything. I have observed this pattern, and I think it ties in to other things too much to be worth addressing on its own).</p>


</section>
<section>
<h2><a href="/posts/2018-10-05-07:01.html">2018-10-05</a></h2>


<p class="subtitle">Vegetables and diet</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-10-05</dd>
</dl>


<p>
 This post by Sarah Constantin about the
 <a href="https://srconstantin.wordpress.com/2018/10/04/fasting-mimicking-diet-looks-pretty-good/">
  Fasting Mimicking Diet</a>
 looks interesting (I generally trust her health recommendations, insofar as I trust anyone's).</p>


<p>
 In particular the concrete diet plan suggested is:</p>


<blockquote>
<p>
  For the first five weekdays of every month, eat nothing but (non-potato) vegetables, cooked in fat if desired.  The rest of the time, eat whatever you want.</p></blockquote>


<p>
 I've
 <a href="https://www.drmaciver.com/2018/07/notes-on-eating-more-vegetables/">
  previously written about trying to eat more vegetables</a>
 , where I'm trying to bring my meals up to at least half vegetables by volume. I've been doing pretty well on this for most non-breakfast meals, with the exception of lunches when I go in to imperial.</p>


<p>
 I'm quite tempted to try this diet, in large part because it will I think force me to sort out my bringing lunch to work situation.</p>


</section>
<section>
<h2><a href="/posts/2018-10-04-08:52.html">2018-10-04</a></h2>


<p class="subtitle">Questions</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-10-04</dd>
</dl>


<p>
 I struggled to refind
 <a href="http://kiriakakis.net/comics/mused/a-day-at-the-park">
  this comic about questions and answers</a>
 so here's a link for later use.</p>


<p>
 Favourite quote:</p>


<blockquote>
<p>
  Once you see that an answer is not serving its question properly anymore, it should be tossed away.</p></blockquote>


</section>
<section>
<h2><a href="/posts/2018-10-03-07:55.html">2018-10-03</a></h2>


<p class="subtitle">The Duties</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-10-03</dd>
</dl>


<p>
 I am generally deeply suspicious of normative ethical theories. I think ethics is hard, and attempts to simplify it to a set of rules inevitably have the problems that taking a complex space and making it legible always do.
They're potentially a useful mental tool, but as soon as you start arguing about which one is true you've lost. Even if I was a moral realist, which I'm not, it seems obviously the case that the ethics that can be told is not the true ethics.</p>


<p>
 So obviously I thought it might be an interesting experiment to set out to build one. The following is part of what I came up with.
This is something I at most weakly believe. I think it's a good model for evaluation of actions, but I don't think it's one I would actually attempt to follow dogmatically.</p>


<p>
 You have one duty: The world and all that is in it should thrive. Things should get better over time, not worse.</p>


<p>
 You have four duties: To yourself, to those around you, to humanity, and to the world.</p>


<p>
 Until you have fulfilled the earlier duties, you should not consider the later.</p>


<ol>
<li>
  Your duty to yourself is that you thrive.</li>
<li>
  Your duty to those around you is that you help them thrive.</li>
<li>
  Your duty to humanity is that your existence should help rather than hinder it in thriving.</li>
<li>
  Your duty to the world is that your existence should help rather than hinder it in thriving.</li></ol>


<p>
 Each duty supersedes the later ones: Ensure you thrive, then others around you, then humanity, then the world.
This does not mean that you should always prioritise yourself above others, but it does mean that you should put your oxygen mask on first before helping others with theirs.</p>


<p>
 To live a good life is to discharge your duties to the best of your ability.
There is no shame in failing to uphold these duties because you are unable, only because you are unwilling.</p>


<p>
 (I originally had a bunch of text explaining the reasoning behind this, but actually this is more intended as an interesting artifact than something I'd propose to defend, so I just deleted it).</p>


</section>
<section>
<h2><a href="/posts/2018-10-03-07:31.html">2018-10-03</a></h2>


<p class="subtitle">You Can't Trust Lawful Good</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-10-03</dd>
</dl>


<p>
<a href="https://twitter.com/CartesianDaemon">
  Jack</a>
 posted a link to
 <a href="https://yougov.co.uk/news/2018/09/21/dungeons-and-dragons-one-three-britons-are-neutral/">
  this YouGov poll</a>
 in which people were asked their D&amp;D alignment and somehow almost nobody thought they were evil. I'm as surprised as you are given the last two years of British politics.</p>


<p>
 The particular thing that
 <a href="https://twitter.com/DRMacIver/status/1043075395237625858">
  was surprising to him</a>
 :</p>


<blockquote>
<p>
  What the everloving fuck? I love the idea of mapping political positions this way, but you reckon "everyone is a bit racist" and "i like theresa may" are... lawful good? How about lawful evil? I think well-meaning fussy philosophical types vote libdem, not ukip.</p></blockquote>


<p>
 My reply:</p>


<blockquote>
<p>
  Paladins are literally cops, Jack.</p></blockquote>


<p>
 So, uh, yeah. ALGCAP (All Lawful Good Characters Are Bastards).</p>


<p>
 I have technically played a lawful good paladin. My interpretation of him probably veered more chaotic good than was strictly accurate.</p>


<p>
 From
 <a href="https://twitter.com/DRMacIver/status/1007533080750551040">
  an earlier discussion</a>
 with some other people:</p>


<blockquote>
<p>
  I
  <em>
   have</em>
  played a paladin and it worked pretty well. He was very good at smiting people with sarcasm (and then a sword).
I think I just decided that traditional interpretations of lawful good as being humourless were too narrow and decided to have fun with the concept
After all, nothing incompatible about a deep burning righteous anger at the injustice of the world and a profound desire to fuck with people.</p>
<p>...</p>
<p>
  Shit, maybe I
  <em>
   am</em>
  the lawful good character.</p></blockquote>


<p>
 (For the record, I am not the lawful good character. I'm very clearly Chaotic Good. Maybe Neutral Good on days when I'm too lazy to be properly chaotic).</p>


<p>
<a href="https://twitter.com/DRMacIver/status/1046703352522985472">
  Jack and I later discussed</a>
 another aspect of the villain versus hero dynamic:</p>


<blockquote>
<p>
  Me: Every time I find myself going "hmm the villain actually has a pretty good point it's a shame they're evil" I start to head canon that I'm consuming media from the "plucky ragtag heroes'" well funded propaganda arm.</p>
<p>
  Jack: What I eventually realised was that villains' motivations ranged from "bizarre" to "excellent" but if what made them villains was doing unjustifiably bad things in the pursuit of that.</p>
<p>
  Me: I think that is broadly true, but that it is remarkably convenient how the people with excellent motivations for changing the system always do unjustifiably bad things in the pursuit of that.</p></blockquote>


<p>
 "Avatar: The Legend of Korra" is possibly the worst example of this I have ever seen: I broadly enjoyed the show, but
 <em>
  every single villain</em>
 was raising legitimate objections to the system, but fortunately they were evil so you could just punch them and move on without addressing the fundamental systemic inequalities that they were objecting to.</p>


<p>
 As I put it elsewhere in that thread:</p>


<blockquote>
<p>
  Gotta love them underdogs and their defence of the status quo</p></blockquote>


<p>
 Recommended reading/viewing on this subject:</p>


<ul>
<li>
  Spiderlight by Adrain Tchaikovsky is an excellent deconstruction of D&amp;D alignment systems.</li>
<li>
<a href="https://www.youtube.com/watch?v=-77cUxba-aA">
   Twisted: The Untold Story of a Royal Vizier</a>
  is
  <em>
   so</em>
  good. I keep wanting to write a new version of Rules of Wishing based on a Twisted set of characters rather than the original movie's.</li></ul>


<p>
 Anyway, that's why
 <del>
  I am</del>
 SOMEBODY ELSE WHO IS NOT ME IS raising an army of crows.</p>


</section>
<section>
<h2><a href="/posts/2018-10-02-10:39.html">2018-10-02</a></h2>


<p class="subtitle">On Formal Mathematics</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-10-02</dd>
</dl>


<p>
 Some thoughts on the question of the formalisability of mathematics.</p>


<p>
 Based on "Rigor and Structure" by John P. Burgess
 <a href="https://twitter.com/DRMacIver/status/1040505316201385986">
  I tweeted</a>
 the following a while back:</p>


<blockquote>
<p>
  I'm reading "Rigor and Structure" by John P. Burgess at the moment, and a point he makes that I really like is that formal logic is best viewed as analogous to a sort of... physics or economics of mathematics. It is a (very good) theoretical model of Actual Mathematics.
And one way the model breaks down is that it's a great model of deducibility, but a poor model of deduction - you can be reasonably confident that if a proposition is formally deducible then it's real-maths deducible, and we also believe the converse mostly on faith but it doesn't follow (and mostly isn't true) that the actual process of proof is well modelled by the formal logic - e.g. proof lengths in informal and formal mathematics are not well correlated, and the styles of proof that you adopt are radically different.</p></blockquote>


<p>
 Ron Pressler took exception to this framing, and I believe in particular to the part that we believe mostly on faith that every informal proof is formalisable.
I've tried several times to write what I believe Ron's argument against this is, but it kept coming out as such an implausible strawman that I must assume that I am misunderstanding some crucial aspect of his point.</p>


<p>
 Another informative text on the subject is Imre Lakatos's "Proofs and Refutations" which makes, I think, a compelling argument that understanding proof purely in terms of its formal content is a very limiting view.
Burgess is arguing around (though not entirely for) the idea that "a proof is that which convinces", but Lakatos is arguing that the primary purpose of a proof is not to convince but to illuminate (this is a huge oversimplification).</p>


<p>
 The problem I have with the idea that we should naturally expect all informal proofs to be formalisable is as follows:</p>


<ol>
<li>
  It's obviously false. Informal proofs lead to formal proof
  <em>
   schemas</em>
  unless you pick your logic very carefully. In particular informal proofs can e.g. quantify over predicates.</li>
<li>
  The arguments I have seen that we should expect it to be true from the deeper Church-Turing principle seem so obviously wrong that I can't even interpret them as coherent: The ability to simulate a human brain well enough to replicate an informal proof on a Turing machine doesn't tell you anything about formal provability of a propostion, it provides a formal proof that an informal proof exists.</li>
<li>
  Many informal proofs most interesting characteristic is that they demonstrate a contradiction or paradox in the natural language that goes away when you attempt to formalise them. For example
  <a href="https://en.wikipedia.org/wiki/Interesting_number_paradox">
   the interesting number paradox</a>
  or
  <a href="https://en.wikipedia.org/wiki/Berry_paradox">
   the Berry paradox</a>. This means that the formalisation process in itself has interesting semantic content.</li>
<li>
  It is typical for any informal proof to have so many logic gaps in it that finding a formal refinement of the proof really constitutes creating an entirely new proof. Therefore even if this is true, it is true in a fairly weak sense.</li></ol>


<p>
 Do I think that any sufficiently precise informal proof of a statement whose natural language meaning has an unambiguous formal equivalent can be refined to a formal proof schema?
Yes, almost certainly.</p>


<p>
 Do I think that the above is obviously true rather than a belief? No, and I don't think it would be possible for it to be obviously true - we don't have a sufficiently pinned down notion of what an informal proof even
 <em>
  is</em>.</p>


<p>
 Do I think this is all a pointless distraction from the actually interesting point made above, which is that formal proof is a much better model of provability than it is of proof? Yes, definitely.</p>


</section>
<section>
<h2><a href="/posts/2018-10-01-08:17.html">2018-10-01</a></h2>


<p class="subtitle">Notes on Interviewing</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-10-01</dd>
</dl>


<p>
<a href="https://twitter.com/DRMacIver/status/1046341533992128512">
  Twitter thread from me</a>
 :</p>


<blockquote>
<p>
  The worst thing about all of these "diversity shouldn't get in the way of finding the best person!!" arguments (I know, it's a hard choice) is the complete and utter disconnect from reality required to believe that anyone has a clue about how to find the best person.
Santa Claus isn't real, and your interview/talk selection/whatever process is probably almost entirely noise rather than signal.
The good news about this is that it means you might as well decide on the outcome you want and then apply your process to select among the options within that outcome.</p>
<p>
  The bad news is I'm going to assume that you've done that, so the outcome you got is the outcome you wanted.
These are legitimately hard problems, and I have more sympathy than most for the trade offs involved in them, so I'm not e.g. going to assume you're a terrible person because of a failure to hire diverse candidates, but I am going to assume you probably weren't trying very hard.
Source: I've fucked up this way, and in retrospect I wasn't trying very hard.</p></blockquote>


<p>
 The two books I recommend to people interviewing are
 <a href="https://amzn.to/2P0g8Qr">
  The Halo Effect</a>
 and
 <a href="https://amzn.to/2ReeP1J">
  Epistemology and the Psychology of Human Judgment</a>.
Neither will, unfortunately, teach you to interview well. I don't know of anything that will. If you have book recommendations on this subject then I would like to hear them.
Instead what these books will teach you is to doubt your own judgement when interviewing, which I think is a pretty good start - the worst interview processes I've been involved in have failed due to people trusting their own judgement over the process.</p>


<p>
 Things I would like people to understand about interviewing:</p>


<ol>
<li>
  Your process has false positive and false negative rates. You mostly can't see the false negative rate, so it's probably very high.</li>
<li>
  Without a better idea of what you're actually looking for, your false positive rate is basically meaningless anyway.</li>
<li>
  You are not actually looking for the best person for the job. You are looking for a person who can do the job well. Trying to find the best person for the job would
  <em>
   extremely</em>
  expensive in interviewing time.</li>
<li>
  The job will change people, so even among a small candidate pool the person who is currently the best fit for the job may not be the same as the person who is the best fit in three months anyway.</li>
<li>
  The "person who is best at the job" according to most easy to track measures may be very different from the person who brings the most to the team.</li></ol>


<p>
 Given this, my advice to you is
 <em>
  not</em>
 throw out your whole interview process. Not because I think your current interview process is good, but because throwing it out and replacing it with something else will cost a lot of political capital and you probably still won't create a good interview process because interviewing is bloody impossible.</p>


<p>
 Instead my advice to you is this:</p>


<ol>
<li>
  Keep an eye on your false negative rate. Maybe let a random or biased set of candidates through the early stage of your pipeline who you would otherwise have ignored.</li>
<li>
  Do pay attention to stuff like what your job ads look like. I don't currently have a good link for advice on this but if someone sends me one I'll edit it in.</li>
<li>
<a href="https://blog.doismellburning.co.uk/how-not-to-screw-up-hiring/">
   Read Kristian's Blog Post</a></li>
<li>
  Think in advance about what you actually want and what you would settle for.</li>
<li>
  Try to make sure you're getting a broader and more diverse audience in to your process in the first place. Watch out for filtering that happens before they reach you - e.g. based on recruiters, job platforms, etc.</li></ol>


</section>
<section>
<h2><a href="/posts/2018-09-28-10:49.html">2018-09-28</a></h2>


<p class="subtitle">What is a neural network?</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-28</dd>
</dl>


<p>
 These are some notes I put together in response to the question "How would you explain neural networks to business people?"</p>


<p>
 The following are the most important things to understand about neural networks:</p>


<ul>
<li>
  Neural networks are an interesting implementation technique for a well studied set of problems.</li>
<li>
  Neural networks do not allow a machine to "think" in any general sense - they are mostly useful for implementing simple decision procedures and predictive models, but they do not do any general reasoning or planning (they may be used as components in systems that do though).</li>
<li>
  Neural networks are only as good as the data you give them.</li></ul>


<h3>
 What do neural networks do?</h3>


<p>
 The general problem that neural networks solve is called
 <em>
  machine learning</em>. This is a somewhat misleading term because how machines "learn" in this sense doesn't map that well to how humans learn.
Machine learning is really just a particular type of automated statistics that can be used to make simple predictions and decisions based on similarity to previously observed data.
There are many ways to do machine learning, and any given instance of it is a particular
 <em>
  algorithm</em>
 , a precise set of rules that describe how the computer "learns" in this particular problem.</p>


<p>
 Any machine learning always starts with some set of data that we "train" on.
Typically we present this to the machine learning algorithm as a collection of
 <em>
  features</em>
 ,
which are a way of breaking down the objects we want to work on into a set of numeric or categorical (i.e. one of a small number of possibilities) properties.
For example:</p>


<ul>
<li>
  We might represent an image as red-green-blue integer values for each pixel.</li>
<li>
  We might represent a person in terms of "age", "country of birth", "gender".</li>
<li>
  We might represent a piece of text as a "bag of words", which counts the number of times each word appears in it.</li></ul>


<p>
 All decisions made by the machine learning process are based only on these features - two things that are somehow different in a way not captured by their features will still get the same result.
Features are not intended to
 <em>
  fully</em>
 represent the things we study, but capture some aspects of it that we think are important and should be sufficient to predict the results we want to know.
The process of turning real world things into useful features is something of an art, and is often as or more important than the actual machine learning you do.</p>


<p>
 Once we have turned our data set into features, we train on it.
This is the process of taking our data set and turning it into a model that we will use as the basis of our future decisions.
Sometimes we do this with the data presented entirely up front, and sometimes the algorithm is designed so that it can learn as you go.
The former is much more common, especially with neural networks, but both approaches are possible.</p>


<p>
 One important difference between machine and human learning is that machine learning tends to need a lot more data than you would expect a human to.
Often we train our machine learning algorithms on hundreds of thousands, or millions of data points, where you might expect a human to learn after only a few. It takes a lot longer for most machine learning approaches to learn what a picture of a dog looks like than it does a toddler.
Why is complicated, and how to do better is an open research problem, but the main reasons are:</p>


<ul>
<li>
  the toddler has a lot of built in machinery about how to do image processing already, while the machine learning system has to learn that from scratch.</li>
<li>
  the machine learning system is much more general and can learn things that humans are bad at as easily as it can learn things that humans are good at - e.g. a toddler would struggle to do much with actuarial data that a machine learning algorithm would find
  <em>
   easier</em>
  than recognising dogs.</li></ul>


<p>
 The need for these large data sets for training is where "big data" comes in. There are a lot of arguments as to what should count as big data, but a good rule of thumb is "if you can fit it on a single computer then it's not big data". Given how large computers can affordably get these days, most things that people call big data probably aren't.</p>


<p>
 Anyway, given a set of input data, there are roughly three types of commonly studied machine learning that we can do with it:</p>


<ul>
<li>
<em>
   Supervised learning</em>
  takes some input data and some labels or scores for it, and tries to learn how to predict those labels or scores for other similar data. For example, you might want to classify an email as "spam" or "not spam", or you might want to predict the life expectancy of someone given a set of data about their health.</li>
<li>
<em>
   Reinforcement learning</em>
  is for making decisions based on data. Based on the outcome of the decision, you feed back into the process with either a "reward" or a "punishment" (I want to emphasise again that this is a metaphor and the algorithm is not in any meaningful sense thinking or able to experience pleasure or pain), and the algorithm adjusts its decision making process to favour decisions that are similar to previous ones that have worked well and different from previous ones that have worked badly. e.g. you might use this for stock picking, and reward the algorithm for picking stocks that do well and punish it for picking stocks that do badly.</li>
<li>
  Unsupervised learning builds a model of the "shape" of the data. I won't talk about this too much, but if you've seen those deep dream pictures or "I trained a bot on this corpus of text and this is what I got" articles, that is usually what's going on here (although the much more common case, particularly with the articles, is that someone has just made it up and no machine learning was involved at all): The system has built a predictive model of the data and is used to randomly generate something that matches that model.</li></ul>


<p>
 Almost all applications of machine learning you hear about are one of these three things, possibly with some additional logic layered on top.
For example AlphaGo, Google's Go playing AI, is roughly a combination of all three in a rules based system that describes the rules of Go, and uses the output of the machine learning to choose moves.</p>


<p>
 There are a very large number of different approaches you can take to these problems, of which neural networks are only one of them.
An easy to understand and classic approach to machine learning is the use of decision trees: Simple rules of the form "If (this feature has this range of values) then (do this) else (do this other thing)".
These are very easy to learn - you pick some feature that splits the data set well,
break the data set into two parts based on that, and then try again on the smaller parts. If nothing works particularly well, you add a rule that says "Predict (most common outcome)" (I am eliding a lot of details here that don't matter to you unless you want to actually implement these ideas).</p>


<p>
 One classic limitations that machine learning struggles with is in learning patterns that require understanding complex aspects of the data that are not easily understood from a small number of features.
If you imagine image processing, to the computer a small image is just a list of a couple hundred thousand numbers.
A human would struggle to get anything useful from that too!</p>


<p>
 Neural networks attempt to overcome this by learning in
 <em>
  layers</em>.
Each layer consists of something that looks a bit like unsupervised learning and a bit like supervised learning, where each layer "learns" to extract high level features from the one below.
In the image case you start with the bottom layer that looks at the raw pixel data, and then it might e.g. try to identify patterns of lines in that data.
Each layer is essentially a new set of features that takes the overly detailed previous layer's features and tries to turn it into a representation that it can more easily work with.
This allows us to combine a very simple learning technique (the "neurons" that are really just a very simple bit of machine learning that tries to turn a set of features into a score between zero and one) into a much more complex one that is able to handle high level features of the data.
This is where the "deep" in "deep learning" comes from - a deep neural network is one with many layers.</p>


<p>
 The result of this is that where a "shallower" machine learning system might suffer from a problem of not being able to see the wood for the trees,
neural networks can make predictions based on a more structured representation of the data, which makes things obvious that were hard for the algorithm to see from the more fine-grained representation.
Some times these structured representations will be ones that are obvious to humans (e.g. lines in images), but often they will not be, especially (e.g. they capture some strategic aspect of the Go board).</p>


<h3>
 Why are neural networks cool right now?</h3>


<p>
 Neural networks are not at all new technology, but are recently seeing a revival for a number of reasons:</p>


<ul>
<li>
  We have a lot more data now, which allows us to paper over any limitations by just training it more.</li>
<li>
  We have much faster computers now, particularly as a lot of neural network training can be made highly parallel (that means that you can break it up into small chunks that can be run at the same time without waiting for each other, then combine the results).</li>
<li>
  We have made a number of incremental improvements to the algorithms that allow us to speed up our training and improve the quality of results.</li></ul>


<p>
 This has allowed us to apply them to problems where it was previously infeasible, which is the main source of all of the current progress in this field.</p>


<h3>
 What is going to go wrong when I use neural networks?</h3>


<p>
 This is important to understand, because things
 <em>
  will</em>
 go wrong.
The main things that it is important to understand about this are:</p>


<ol>
<li>
  It is much more important to have good input data than good algorithms, and gathering good input data is expensive. Machine learning is only as good as its training, and if your input data is biased or missing important examples, your machine learning will perform badly. e.g. A classic failure mode here is that if you train image recognition only on white people, it will often fail to see people of colour.</li>
<li>
  Compared to a human decision maker, neural networks are
  <em>
   fragile</em>. There is an entire class of things called "adversarial examples" where carefully chosen trivial changes that a human wouldn't even notice can cause the neural network to output an entirely different answer.</li>
<li>
  Even without adversaries, machine learning algorithm
  <em>
   will</em>
  make stupid goofs that are obvious to a human decision maker. It will do this even if it is on average better than a human decision maker. This is simply because different things are obvious to machines and humans. Depending on how visible these decisions are, this will probably make you look silly when it happens.</li></ol>


<h3>
 When should I use neural networks?</h3>


<p>
 First off, you should not be making a decision about whether to use neural networks if this article is teaching you new things.
You should be making a decision on whether to use
 <em>
  machine learning</em>. Leave the decision of what type you should be using to an expert - there is a good chance they will choose neural networks (tech people are very trend driven),
but there might be something simpler and better suited for your problem.</p>


<p>
 Roughly the following rules of thumb should help you decide whether to use machine learning:</p>


<ol>
<li>
  Is this a problem that would benefit from being able to make lots of fairly constrained decisions very fast? If no, then
  <em>
   maybe</em>
  talk to an expert (some problems don't look like this on the face of it but can still benefit - e.g. translation isn't obviously of this form, but it can benefit from machine learning), but you're probably out of luck and even if you're not this is going to be a huge and expensive research project.</li>
<li>
  Could you just write down a short list of rules that are sufficient to make those decisions? If yes, just do that instead of trying to learn them from data.</li>
<li>
  If you had an averagely intelligent training human with maybe a couple of days of on the job training and enough background knowledge to understand the problem making those decisions, would their answers be good enough? If no, you're really going to struggle to get your machine learning to be good enough.</li>
<li>
  Think through the failure modes of the previous section. Do you have a plan in place to avoid them, or to mitigate them when they occur? Is the cost of that plan worth the benefits of using machine learning?</li>
<li>
  Reflect on the following question: When someone in the media says "Why did you use a machine rather than a person here?" and your answer is "It was cheaper", how is it going to play out and are you happy with that outcome? If no, your problem is probably politically a poor fit for machine learning.</li></ol>


<p>
 If your problem passed all of those tests, it might well be amenable to machine learning. Go talk to an expert about it.</p>


</section>
<section>
<h2><a href="/posts/2018-09-27-12:18.html">2018-09-27</a></h2>


<p class="subtitle">Principles of (Social) System Design</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-27</dd>
</dl>


<p>
 I think the following two points are under-appreciated when designing systems for people:</p>


<ul>
<li>
  Everything works well in high trust environments where people are personally invested in the goal of the system.</li>
<li>
  Nothing works well in low trust environments or where people are opposed or indifferent to the goal of the system.</li></ul>


<p>
 Therefore when designing systems the most important questions are:</p>


<ol>
<li>
  How can we eject bad actors?</li>
<li>
  How can we retain trust in the system?</li>
<li>
  How can the system help people to achieve the things that they already want to do?</li></ol>


<p>
 I have found this to be very true when designing systems for myself (skipping the first step - I may be a bad actor, but I can't eject myself). I don't have enough practical experience at group system design to say for sure it applies there,
but just based on what I've observed of other systems' failure modes I'm pretty confident that it does.</p>


</section>
<section>
<h2><a href="/posts/2018-09-27-09:19.html">2018-09-27</a></h2>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-27</dd>
</dl>


<p>
 I attended the London
 <a href="http://www.liberatingstructures.com/">
  Liberating Structures</a>
 meetup the other day. I really enjoyed it.
We did a
 <a href="http://www.liberatingstructures.com/17-conversation-cafe/">
  conversation cafe</a>
 which was an interesting format that I'm definitely going to borrow some ideas from.</p>


<p>
 The subject of our cafe was "Making Difficult Decisions". I found this really useful and have been wanting to write up my thoughts on our discussion in a proper article,
but haven't been finding the time or spoons, so here are my notes on the topic so that I can remember what I wanted to say when I actually get around to that.</p>


<p>
 Note: Various of these points were made by various people. I'm going to make them without attribution, partly because the conversation was quite personal, and partly because I haven't recorded the attribution!
I just want to make it clear that although I agree with all of this, it is not at all original to me. I've tried to make this a fair representation of what people said, but it's inevitably filtered and biased by my views on it and what I found interesting. Where my thoughts are things from writing this post rather than from the conversation itself, I have tried to mark them clearly by prefacing them with "Aside:".</p>


<p>
 A theme we hit on early is that it's rarely the decision that is difficult. Once you have got to the point where you understand that there is a decision to be made, we haven't actually found that it's very hard to make it,
and once we've made it we feel an incredible sense of relief.
The difficulty is getting to the point where we have anything as concrete and simple as a single decision.</p>


<p>
 Examples (these are all super paraphrased, I don't have the actual quotes written down):</p>


<ul>
<li>
  "It's easy for me to decide what I want to do at any given moment, but I have no idea how to deal with big picture questions like what to do with my life."</li>
<li>
  "I stayed in a job for seven years that I probably should have stayed in for two." (there were several of these)</li>
<li>
  "I had to admit that a project that I was personally very deeply invested in wasn't working and leave it."</li>
<li>
  "I had been in a miserable relationship for some time and despite my best efforts to make it work, it wasn't."</li>
<li>
  "I had just moved to start a new job and had to admit to myself that it wasn't working out." (there were several of these, one of which was me)</li></ul>


<p>
 In many of these cases, we reported that once we had identified and made the decision we felt
 <em>
  great</em>.</p>


<p>
 A key point that we identified in this "making decisions is easy" aspect is resilience - the ability to feel safe making these decisions. We knew that regardless of which we decided, nothing
 <em>
  too</em>
 bad was going to happen to us.
We mostly talked about emotional resilience.</p>


<p>
 Aside: Financial resilience is also important, but we had a group of people from (I assume) fairly high-paying jobs by nature of the meetup, so this didn't end up really factoring in to the discussion.</p>


<p>
 Another thing that came up was the observation that often there was some sort of crystalising event that prompted the decision. e.g. being asked "Are you happy?", or some particularly bad event at work that forced them to realise that it was time to think about leaving.</p>


<p>
 Aside: I have two personal examples related to this that I didn't bring up. The first is that when I left Google it was prompted by reading the GCL ("
 <del>
  Google</del>
 General Configuration Language") specification from cover to cover and going "fuck this shit". I didn't quit over GCL, but GCL was what prompted me to realise that I should. If you want an idea of what GCL is like, I refer you to
 <a href="http://flabbergast.org/">
  flabbergast</a>
 which is basically an open source implementation of it. The second is that I was recently asked "If you weren't working on this, what
 <em>
  would</em>
 you be working on?" RE Hypothesis, which was a very useful clarifying question for a number of reasons that alas this margin is too large to contain.</p>


<p>
 Some good points that were made in the course of the discussion:</p>


<ul>
<li>
  We like to pretend we make decisions logically, but often they are based on emotion and the logic just exists to post-rationalise the decision.</li>
<li>
  Often the hardest decisions are about leaving a situation where we have a great deal of our identity or relationships bound up in it.</li>
<li>
  The relationships that tie us in to a place are often actually improved by leaving it - if we're miserable there then we might not be much fun to be around!</li>
<li>
  Often when you're staying for other people, they're staying for you, and everyone would be happier if they just all up and left.</li></ul>


<p>
 Someone made the point that we were very focused on "making decisions in hard situations" and asked whether there were easy situations that had hard decisions.
The joking example was that "chocolate or ice cream" is never a hard decision.</p>


<p>
 Aside: This is an instance of the
 <a href="https://en.wikipedia.org/wiki/Buridan%27s_ass">
  Buridan's Ass</a>
 problem. It's tempting to treat making a decision between very similar things as hard, when in fact it should be easy - just flip a coin because it doesn't matter very much.</p>


<p>
 One example we identified as a difficult decision that crops up without an accompanying difficult situation was "Should I flake on this event or not?" - not going feels like letting people down, even if you really don't have the energy or health to go.</p>


<p>
 Aside: Part of why this is a difficult decision is because even though (in most cases) the individual decision doesn't matter, the aggregate effect of it does. I have flaked on two events in a row with a friend recently, both for good reasons (one iron-clad, one merely good), but this feels much worse than twice as bad as flaking on one event, because it shows a pattern of flakiness. See also
 <a href="https://www.vox.com/first-person/2018/8/16/17694356/how-to-make-friends-adulthood">
  this vox article on losing friends</a>.</p>


<p>
 Some questions we finished with:</p>


<ul>
<li>
  How do we notice the decisions that we are not making?</li>
<li>
  How would one practice the skill of hard decisions?</li>
<li>
  How can one cultivate emotional resilience?</li>
<li>
  How can one create an environment that enables others around you to make hard decisions?</li></ul>


</section>
<section>
<h2><a href="/posts/2018-09-27-09:10.html">2018-09-27</a></h2>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-27</dd>
</dl>


<p>
<a href="https://twitter.com/DRMacIver/status/1044619483086770176">
  I made a comment in conversation on Twitter the other day</a>
 that I like and need to think about more:</p>


<blockquote>
<p>
  "A logically omniscient instance of homo economicus" is mostly just a good user persona to have in mind in your system design meetings</p></blockquote>


<p>
 Despite being generally down on SEU, both as a normative and as a descriptive model, I think think this might actually be a good use case of it:
Treat your system design
 <em>
  as if it contains such people</em>
 and ask what they will do will tell you useful things, as long as you don't pretend they are the only people using the system.</p>


<p>
 It's not dissimilar to the principle of design on the assumption that an abusive ex will be using the system: Abusive exes are not your main users (hopefully!) but knowing how they will abuse the system tells you important things about what you need to do.</p>


<p>
 One reason that this is an important user persona to consider is that people will tend to approximate it increasingly well as they get used to the system, and increasingly well as the amount of time and money they have available to bring to bear on it, so you can think of homo economicus as the user persona for people who are willing to sit down and figure out how to actively game your system.</p>


<p>
 A useful feature of both of these personas is that there's a continuum between normal users and them. Someone doesn't have to be an abusive ex to behave like an asshole to another user, and the tools for dealing with an abusive ex help there too. Similarly, if the system pushes homo economicus to awful destructive behaviour that you want to avoid, it will probably nudge normal users in that direction too.</p>


</section>
<section>
<h2><a href="/posts/2018-09-26-09:29.html">2018-09-26</a></h2>


<p class="subtitle">Group Decisions on Names</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-26</dd>
</dl>


<p>
 Here's a question I'm currently wondering about: How would you design a group decision making procedure for naming things?</p>


<p>
 For
 <a href="https://twitter.com/sinister_katze">
  Sinister</a>
 and
 <a href="https://twitter.com/dexter_katze">
  Dexter</a>
 we used
 <a href="https://en.wikipedia.org/wiki/Majority_judgment">
  Majority Judgment</a>.
We brainstormed pairs of names until we ran out, then we cast a vote on them.</p>


<p>
 The voting went as follows:</p>


<ul>
<li>
  Sinister and Dexter: 4, 4, 5</li>
<li>
  Gin and Tonic: 5, 1, 2</li>
<li>
  Lorem and Ipsum: 4, 3, 5</li>
<li>
  Gipfeli and Bretzeli: 2, 3, 4</li>
<li>
  Kappa and Lambda: 5, 3, 3</li>
<li>
  Jam and Chutney: 3, 1, 1</li>
<li>
  Terror and Erebus: 2, 5, 3</li></ul>


<p>
 So how this played out was that in the first round "Sinister and Dexter" and "Lorem and Ipsum" both scored 4, and everything else scored less, so those were the two candidates that made it through to the second round.
We then removed a 4 from each of their scores, and now "Sinister and Dexter" still scored 4 while "Lorem and Ipsum" scored 3, so the cats were named Sinister and Dexter.</p>


<p>
 Was this a good system? No, not really. I'm happy with the result, but the fact that you got a good outcome doesn't mean you had a good system.</p>


<p>
 There are a couple of problems with this. Firstly, the voting system. I don't have a problem with majority judgment (range voters don't @ me), but I think for this kind of very small group decision making any voting system has a legitimacy problem.
For example, imagine we had an option where the votes were 5, 5, 1. This would win, because its initial score was 5, despite one of us hating the name.</p>


<p>
 The bigger problem with this though is that it treats naming as a closed list decision procedure: We decide on the names up front, then we vote on it, and use the outcome of that vote. This is nonsense. Naming is intrinsically open ended - generating new candidates is cheap.</p>


<p>
<em>
  For example</em>
 the following might have been a better procedure:</p>


<ol>
<li>
  Everyone sits silently and writes down as many names as they like.</li>
<li>
  People read out the names they've chosen and, if they like, explain their reasoning and origin. Anyone has the opportunity to veto a name. Vetos are encouraged - the goal is to only leave names in the list where everyone is
  <em>
   happy</em>
  to use the name, even if it's not their favourite.</li>
<li>
  We vote on the names as above using majority judgement.</li>
<li>
  This gives us a candidate name.</li></ol>


<p>
 If we have an existing candidate name, we now take a majority vote whether to replace it with the new one. We then take a vote as to whether to continue the process or use the current candidate name. If we continue, repeat as above, possibly after some break.</p>


<p>
 Note that I don't think this is a particularly good system, it's just a sketch - the point is to incorporate the deliberative process of naming things into the mechanism, and to treat voting as a guideline rather than a source of legitimacy.</p>


</section>
<section>
<h2><a href="/posts/2018-09-25-08:28.html">2018-09-25</a></h2>


<p class="subtitle">Lightweight RPG Systems</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-25</dd>
</dl>


<p>
<a href="https://twitter.com/CHGardiner/status/1043568602283171842">
  This was a good thread about Fail Better Games's new RPG</a>
 ,
which in particular links to a lot of other interesting lightweight systems.</p>


<p>
 Mostly putting this here to save for later because I struggled tor refind it.</p>


<p>
 Another thing which isn't in this thread but was mentioned to me recently and looks a lot of fun is
 <a href="http://onesevendesign.com/lasers_and_feelings_rpg.pdf">
  Lasers and Feelings</a></p>


</section>
<section>
<h2><a href="/posts/2018-09-24-08:27.html">2018-09-24</a></h2>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-24</dd>
</dl>


<p>
 A thing I've been noticing a lot recently in how I think about problems is what an essential role switching between different models of the system has.</p>


<p>
 For example, when thinking about groups of people, it's important to think about the systems - what incentives are at play, how does the group response to events, etc.
You treat the group as an abstracted object that is not made up of complex individuals but instead has a few very simple variables in play.</p>


<p>
 It's
 <em>
  also</em>
 important, both ethically and practically, to think about the group as a collection of individual people. People are complex and will surprise you, and if you neglect their individual needs then you will usually treat people badly.</p>


<p>
 It might be tempting to think that the ideal is a single unified view of the system which accounts for everything, but realistically that's almost always impossible, and switching between multiple very distinct models can often work nearly as well.</p>


<p>
 One thing this does is it combats the problem of legibility - the thing where the easiest way to understand something simply is to make it simple enough to understand, destroying much of its essential complexity and causing massive damage - but this seems to be true even without that. e.g. in mathematics it is often useful to switch between different representations because they make different features more salient.</p>


</section>
<section>
<h2><a href="/posts/2018-09-21-08:46.html">2018-09-21</a></h2>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-21</dd>
</dl>


<p>
 I just read Richard Gabriel's
 <a href="https://www.dreamsongs.com/Files/Incommensurability.pdf">
  The Structure of a Programming Language Revolution</a>.</p>


<p>
 I don't think I have enough grounding in either lisp or the philosophy of science to fully understand it, and want to do a second and closer read with citation chasing,
but one point really stood out for me:</p>


<blockquote>
<p>
  I believe that, in general, this view of engineering and science is false: I believe engineering and science are intertwined, and for programming languages and software creation techniques, its often the case that engineering precedes scienceand its very easy to see it.</p></blockquote>


<p>...</p>


<blockquote>
<p>
  One good example is the steam engine. Engineers began its development while scientists were making their way from the phlogiston theory of combustion to the caloric theory of heat, both today considered hilarious.</p></blockquote>


<p>
 I think this observation is
 <em>
  obviously true</em>
 , and I'm kicking myself for the fact that I didn't think it was obviously true until it was pointed out to me.</p>


<p>
 This is also interesting in the context of the way pure and applied maths work. Often physicists are doing interesting mathematical things that are "completely wrong" until a pure mathematician comes along and provides a theory of how they could work.</p>


</section>
<section>
<h2><a href="/posts/2018-09-21-07:04.html">2018-09-21</a></h2>


<p class="subtitle">Some of my favourite PyCon UK talks</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-21</dd>
</dl>


<p>
 The PyCon UK team are amazingly fast at uploading their videos,
which means
 <a href="https://www.youtube.com/channel/UChA9XP_feY1-1oSy2L7acog">
  the entire conference is now online on youtube</a>
 (There was some problem with one video but I'm not sure whether that's been resolved, so maybe the entire conference bar one talk).</p>


<p>
 If I'm being honest, I don't go to PyCon UK for the talks - I go because it's an amazing community. In general I don't get a huge amount out of talks in most conferences I go to.
However I thought there were some especially high quality talks this year,
including some that I not just watched but am going to
 <em>
  rewatch</em>.</p>


<p>
 So, here are some of my favourite talks that I would actively recommend.</p>


<p>
 The two talks that were so good that I intend to rewatch them (mostly to mine for citations and talking points) are:</p>


<ul>
<li>
<a href="https://youtu.be/2xI42pfz5Ec">
   Sue Sentance - Teaching programming: What's in a teacher's toolkit</a></li>
<li>
<a href="https://www.youtube.com/watch?v=yQo8C_ZHOM8&amp;t=5s">
   Hannah Hazi - The Knowledge in the Code</a></li></ul>


<p>
 Sue Sentance's keynote basically made me go "Welp, I need to redesign all my workshops". Hannah's talk had a lot of interesting material on reading code, and I want to follow the references to read more about it - I don't currently need most of the specific advice on legacy code, but reading code is still a very useful skill, especially given Sue's emphasis on its importance for education!</p>


<p>
 Daniele also gave an impromptu talk about documentation that is going to significantly impact how I write documentation in future.
It was not recorded, but I believe it was a variation on
 <a href="https://www.youtube.com/watch?v=t4vKPhjcMZg">
  this talk at PyCon Australia</a>
 (or possibly
 <a href="https://www.youtube.com/watch?v=azf6yzuJt54">
  this one at PyCon US</a>
 ).</p>


<p>
 Talks I would recommend but was already too much of a member of the choir to get that much out of (all of these are by people I'd consider friends or at least friendly acquaintances. This probably isn't coincidental but wasn't deliberate in my selection except in the sense that I always go to friends' talks if they don't clash with anything else that grabs me):</p>


<ul>
<li>
  Alex Chan's talks on trust and user safety. His keynote was on
  <a href="https://www.youtube.com/watch?v=B3XxPnbehqQ">
   Building Trust</a>
  , and he followed up with another talk
  <a href="https://www.youtube.com/watch?v=XyGVRlRyT-E">
   Assume Worst Intent</a>. Alex and I have already talked about some of these issues before, and have broadly similar opinions on them, so I didn't personally get a huge amount out of them, but they're good material and Alex gave great talks on them.</li>
<li>
  Nikoleta Glynatsi's keynote,
  <a href="https://www.youtube.com/watch?v=z8tL7iqGvnw">
   Why does a smile make a difference?</a>
  was a lot of fun. She discussed her research on game theory, and why bats are awesome.</li>
<li>
  Kristian Glass on
  <a href="https://www.youtube.com/watch?v=AtJ4p27e1r8">
   How to screw up hiring</a></li>
<li>
  Sean Sabbage on
  <a href="https://www.youtube.com/watch?v=U07aAQciHx0">
   Coming to a shared understanding</a></li></ul>


<p>
 Misc talks I enjoyed and got something out of but that don't have any particularly insightful categorisation of</p>


<ul>
<li>
<a href="https://www.youtube.com/watch?v=R-6n-WGMOU8">
   The Story of a 53 year old database</a>
  - I don't think I got anything out of this in the sense of things I will now do differently, but I enjoyed hearing this story. Pairs well with Hannah Hazi's talk.</li>
<li>
<a href="https://www.youtube.com/watch?v=NvRSDV4edY8">
   Coding as a Second Career</a>
  was a fairly personal story but one I think it is helpful to hear.</li></ul>


<p>
 I also thought the lightning talks this year were excellent:</p>


<ul>
<li>
<a href="https://www.youtube.com/watch?v=hp-1plTKOqc">
   Saturday lightning talks</a></li>
<li>
<a href="https://www.youtube.com/watch?v=7w_qgGZM4ao">
   Sunday lightning talks</a></li>
<li>
<a href="https://www.youtube.com/watch?v=9j2AhPmjtOQ">
   Monday lightning talks</a></li>
<li>
<a href="https://www.youtube.com/watch?v=F5jSUJVymXk">
   Tuesday lightning talks</a></li></ul>


<p>
 If you have a burning urge to see me speak (which I'm mostly not doing this year), I gave
 <a href="https://youtu.be/9j2AhPmjtOQ?t=133">
  a talk about voting system</a>. I'm mostly pretty happy with how this turned out.</p>


</section>
<section>
<h2><a href="/posts/2018-09-20-13:09.html">2018-09-20</a></h2>


<p class="subtitle">Notes on Tweeting Too Much At Conferences</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-20</dd>
</dl>


<p>
 Well,
 <a href="https://2018.hq.pyconuk.org/">
  PyCon UK</a>
 , the best conference, is over for another year. Sad face.</p>


<p>
 This year I ended up doing something with a surprising amount of impact on my and others' experience of the conference:
I tweeted a
 <em>
  lot</em>. Yes, I know, even by my standards. I essentially became the unofficial scribe of the conference.
I won't even attempt to embed them, but
 <a href="https://twitter.com/search?f=tweets&amp;vertical=default&amp;q=%23PyConUK%20from%3ADRMacIver%20since%3A2018-09-13%20until%3A2018-09-20&amp;src=typd">
  here's a search query that will give you everything I tweeted on the conference hash tag for this conference</a>.</p>


<p>
 Each day:</p>


<ul>
<li>
<a href="https://twitter.com/DRMacIver/status/1040497560652271616">
   Yay! It's time for the annual week of visiting Brodie's to begin. Oh and #PyConUK is on too.</a></li>
<li>
<a href="https://twitter.com/DRMacIver/status/1041238166806700032">
   It is with Brodies alone I set my mind in motion. #PyConUK day two begins! Get ready for more fun-filled and eclectic thread of conference highlights.</a></li>
<li>
<a href="https://twitter.com/DRMacIver/status/1041590037002022912">
   I pledge allegiance to the coffee of #PyConUK, and to the community for which it stands, one nation undivided under Brodies. Day three begins!</a></li>
<li>
<a href="https://twitter.com/DRMacIver/status/1041962704444030976">
   #PyConUK day four. Yr hmbl crspndt is nursing a splitting headache (not a hangover, honest!) and sadly Brodies won't sell me coffee by the pint. Fortunately I'm sure @NikoletaGlyn's keynote will be nice and gentle and contain no advanced mathematics.</a></li>
<li>
<a href="https://twitter.com/DRMacIver/status/1042324826306879488">
   Good morning #PyConUK day 5! Is everyone hyped and enthus-[Error. Insufficient coffee. Insert Brodies provided latte to continue. Error. Error. Errrroooooorrrrrrrrr...]-iastic for the sprints today?!</a></li>
<li>
<a href="https://twitter.com/DRMacIver/status/1042683288693993473">
   #PyConUK day... six? Wait, there is no #PyConUK day 6. That must mean #PyConUK is... over? I don't understand. What will I live tweet now? ... Maybe some coffee from Brodies will help.</a></li></ul>


<p>
 Why? Well,
 <a href="https://twitter.com/DRMacIver/status/1040497560652271616">
  I'd been talking recently about how conference organisers put up with a lot</a>
 and a point that got made in response to this is that a really helpful thing for attendees to do is tweet about the conference - it helps get more sponsors next year, promotes the ideas of the conference, and generally raises its profile.
This seemed an easy enough thing to do, so I decided to give it a try and got a little bit carried away.</p>


<p>
 People seemed to
 <em>
  really</em>
 like me doing this. Especially the organisers - I heard from a lot of them that the running commentary helped them feel more in touch with the conference. So if this achieved nothing else then I'm happy with it.
It also was appreciated by people who weren't able to make the conference, and in a few cases to those who would never have come because they weren't even programmers (though I of course still think they should come)!</p>


<p>
 People have asked me how I did it, but it's not really complicated: I had a laptop, I touchtype really fast, and I've wasted far too much of my life on Twitter. I had not previously thought the latter was a professional skill, but apparently.</p>


<p>
 I did have a couple of problems with doing it:</p>


<ul>
<li>
  Twitter threading is awful. I'm not sure how much it helped people. I think I will probably not bother threading this the next time I do it, and I screwed up the threading in a bunch of places.</li>
<li>
  Quoting people in real time is basically impossible. I am not a STTR. I ended up paraphrasing a lot and I'm not sure I was clear enough about that.</li>
<li>
  I tried to distinguish where I was reporting what the speaker was saying versus when I was commenting. I did not always remember to do this.</li>
<li>
  I would like other people to do this too next year. I'm concerned that this gave people a very DRMacIver-flavoured view of the conference. This is especially relevant because I think for a variety of reasons (mostly that I rarely go to technical talks) I missed out on a lot of first-time speakers.</li></ul>


<p>
 On the whole though, this level of live-tweeting seems to have been popular, and I will probably do it again at future conferences I attend.</p>


</section>
<section>
<h2><a href="/posts/2018-09-20-09:17.html">2018-09-20</a></h2>


<p class="subtitle">Lean Coffee at PyCon UK</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-20</dd>
</dl>


<p>
 As part of the PyCon UK sprints I ran a variant lean coffee. It worked really well - we had a bit of an initial slow start, peaked at more people than the group could really handle,
and gradually tapered down to a group of four by the end of the day. This was split over three sessions, during which we discussed 23 different cards.</p>


<p>
 The variant we ran was based on
 <a href="https://www.drmaciver.com/2016/05/randomizing-lean-coffee/">
  a previous proposal of mine to randomize lean coffee</a>. Several people had reported that they ran lean coffees this was after my post, and thought that it worked much better, but I'd never actually got around to trying it, and I thought this was a good opportunity.</p>


<p>
 In my entirely unbiased opinion, I can confirm that it works much better.
People seemed to really enjoy the format, and many of them reported that they would take it away and try to run it at work.
For the third session I was basically wiped out (scribing, moderating,
 <em>
  and</em>
 discussing at the same time was something I could
 <em>
  do</em>
 , but it was very high energy),
so I passed on the duties - one person took up moderating, another took up scribing, and there were no problems with doing so, so the system seems to be easy enough to transmit to other people, which is a win.</p>


<h3>
 The Conversation</h3>


<p>
 The point of the system is to provide a structured conversation about a large range of topics in a very short space of time.
We select a card (more on that below). This has a discussion prompt (often a question) and the name of the person who proposed it.
At this point anyone may veto discussing the card. People shouldn't veto cards just because they're uninterested, the veto system exists for topics that would make you unhappy or uncomfortable to have discussed.
This never actually came up in practice. I don't know if that is because people didn't feel empowered to veto or because it was never necessary - I
 <em>
  think</em>
 it is the latter,
but I don't feel like people would have necessarily been willing to veto if they needed to.</p>


<p>
 The proposer gets a (short!) opportunity to elaborate on the theme, then the group votes on whether they want to discuss it.
If a strict majority raise their hands, a 5 minute clock is started, and the group discusses it until the time runs out.
At that point, the group votes whether they want to continue it. If a strict majority does, a new 5 minute timer is started,
and the discussion continues.
The subject may not be extended a second time.</p>


<h3>
 Selecting the Cards</h3>


<p>
 At the beginning everyone writes down as many cards as they like and these are put in a central pile.
These are shuffled, and cards are selected by drawing from the top of the pile.
Anyone can insert a new card at any time they like, at which point the deck is reshuffled.</p>


<p>
 We adopted a system that I like in principle and think worked reasonably well but maybe ended up a bit too complicated - in order to ensure everyone got a good opportunity to seed the conversation,
we deprioritised cards from people who had recently had their topic discussed.</p>


<p>
 The way this worked was that when a card had been discussed we put it face up on the table.
If a card came up from someone whose name was already on the table, we put it aside. Once we had been through the whole deck,
we stacked the cards that were face up so that they were no longer visible,
shuffled the cards that had been put aside, and started the process again.</p>


<h3>
 Details</h3>


<ul>
<li>
  I found it very easy to get cards confused, so I started marking cards that we had completed with a cross or a tick on the back so that we didn't mix them up.</li>
<li>
  One person ended up dominating the conversation a bit (he acknowledged this and welcomed the feedback). We adopted a convention that I would just start waving at him when I thought he'd been talking too long. I actually think we should have adopted this as a universal convention right at the beginning, with everyone feeling empowered to do it - there were almost certainly one or two times when someone should have been waving at
  <em>
   me</em>. Honestly I want to adopt this convention for all conversations, lean coffee or not, because I definitely have some friends who it would be useful for (in a constructive way! I think all of the people I have in mind would love this convention).</li>
<li>
  I tended to interrupt people mid-sentence when the time came up, but I should probably have started waving at them and then cut them off if they didn't wrap up within a sentence or two.</li>
<li>
  A nice thing about this format was that it was really easy for people to drop in and out. This created the question of what we should do when a card whose author has left comes up. We initially said we should just discard them, but then decided to vote on them anyway, but we never actually voted in favour of discussion, so I think we were probably right the first time.</li>
<li>
  I did note-taking in a Google doc for most of it, passing over to one of the other attendees for the third session until he left, at which point I took over again. It was
  <em>
   much</em>
  easier taking notes when I wasn't also moderating, and I would rather omit the note taking activity altogether than try to combine it with moderation duties in future (Note: Be careful when asking for volunteers to be note-taker. This is one of those things that instantly gets gendered, and a woman will probably end up doing it by default if you ask for volunteers, so it's best to either assign the role or do it by lot or something. That being said our volunteer note-taker in the third round was a man. On the third tentacle, PyCon UK attendees are lovely and are probably less prone to this failure mode).</li>
<li>
  We wrote down everyone's email addresses on a card and I'm going to email the notes around to give people an opportunity to sanitize (I already carefully omitted a few things that I didn't think should be public) and then I'll publish the notes publicly.</li>
<li>
  We didn't clarify the meaning of the voting system until quite late, but an important distinction is that you should raise your hand if you
  <em>
   want</em>
  to discuss the topic, not just if you're
  <em>
   happy</em>
  to discuss the topic.</li></ul>


<h3>
 Things that didn't quite work</h3>


<ul>
<li>
  I wasn't a fan of the show of hands system. I would like simultaneous, and maybe anonymous, voting - there was a lot of social pressure to conform I think, with people looking at other people before deciding what to vote. I would also like it to be easier to count, as it turns out that I am bad at counting majority voting in a group that is constantly changing and includes me.</li>
<li>
  I thought people were too nice early on - we had a lot of unanimous votes in favour of discussion. Some of these were legitimately high quality topics, but I feel like the unanimity was implausible for some of them. I'm going to think about mechanisms for offsetting this, but I think simultaneous voting might be enough.</li>
<li>
  There is definitely a size limit on how large the group can get before this gets a bit unwieldy. Four people was viable but maybe a bit too small. Once we were past ten it was definitely too large. The sweet spot is probably somewhere in the five to eight range.</li>
<li>
  I'd like a way to encourage some of the more quiet members of the group to speak as well as to encourage the louder members not to - there were some people in the group (mostly women) who I was pretty sure had interesting things to say but didn't feel able to (possibly due to being unable to get a word in edgewise). They may also just have been enjoying listening, I don't know - I know some people explicitly came just to listen in. Unfortunately they had to leave midway through, so I wasn't able to ask them. I'll do so when I email them.</li>
<li>
  We had a veto system - anyone was allowed to veto a card if they didn't want it discussed. This was introduced halfway through when</li></ul>


<h3>
 In Future</h3>


<p>
 A lot of people came away from this going "This was great, I need to run some of these". Including me! Despite the fact that several people have used my variations on lean coffee before, this is actually the first time
 <em>
  I</em>
 have. I'd already been thinking I'd like to run one of these at Imperial, and now I'm even more sure I would like to do that.</p>


<p>
 We also talked about maybe running some of these earlier in PyCon UK next year. They were a great generator of high insight conversations, and I think provided some really nice social connections with people that it would have been great to form more than six hours before we had to say "Well, see you in a year I guess!".</p>


<p>
 In general, a lot of the things we talked about involved things that might be nice for the conference next year (not criticisms! Almost all of the form "PyCon UK is great, but here's an idea that might make it
 <em>
  even greater</em>
 ). I'm probably going to (finally) get involved in the organisation of PyCon UK next year and once people have decompressed a bit and are ready to receive feedback,
I'm going to write a summary of what those were and circulate it.</p>


</section>
<section>
<h2><a href="/posts/2018-09-13-13:07.html">2018-09-13</a></h2>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-13</dd>
</dl>


<p>
 This is a fairly involved example which I don't expect to convince anyone,
and is just the result of me thinking through some things.</p>


<p>
 Suppose we have a bunch of propositions \(A_1, \ldots, A_n\).
We know a priori that \(A_i \implies A_j\) is false for \(i &gt; j\),
but do not know whether there are any forwards implications.
We have an "implication oracle" which acts as follows:</p>


<ol>
<li>
  It has access to a number of "primitive implications" of the form \(A_i \implies A_j\).
   These implications are considered to be unreliable: They are true with probability \(1 - \epsilon\),
   but with probability \(\epsilon\) they provide no information (i.e. the proposition may be true, we just don't know that).
   These errors are independent.</li>
<li>
  We may query the proof oracle with any pair \(A_i, A_j\) and it tells us the probability of there being a valid proof of \(A_i \implies A_j\) given only a true set of primitive implications.</li></ol>


<p>
 We also have a "plausibility oracle" that gives us our prior probabilities of \(p_i = A_i\) being true.</p>


<p>
 Suppose we want to define an agent that chooses between these propositions, with a reward if the proposition chosen is true.</p>


<p>
 We can define a Bayesian agent that picks whichever of \(k \in \{i, j\}\) has the highest posterior probability\((1 - \epsilon) P(A_k | A_i \implies A_j) + \epsilon p_i\).</p>


<p>
 The problem with this agent is that it is not transitive!</p>


<p>
 Consider the following example: Let \(\epsilon = 0.11\),
and suppose we have the primitive implications \(A_1 \implies A_2\), \(A_2 \implies A_3\) and the prior probabilities \(p_1 = 0.2\), \(p_2 = p_3 = 0.01\).</p>


<p>
 Some boring computation that I can't be bothered to carry over to text results in the above agent preferring \(A_2\) to \(A_1\), \(A_3\) to \(A_2\) and \(A_1\) to \(A_3\).
The reason is that the strength of the implication \(A_1 \implies A_3\) is weaker than that of either the individual implications, as it is \(1 - (1 - \epsilon)^2 \approx 0.21\).
Thus even though we still "believe" this implication, the weaker strength of it makes our prior probabilities overwhelm it.</p>


<p>
 Now, this paradox goes away if we have access to the inner workings of the implication oracle:
If we know all of the primitive implications a priori then we can just calculate the "true" posterior probabilities across all possible combinations of whether the implications are valid or not,
and pick the answer with the highest posterior,
but this effectively requires us to know the entire space of propositions in advance.</p>


<p>
 I think that
 <em>
  no</em>
 strategy which has to decide based only on the answer of those two oracles on the current pair can dominate this strategy,
because this is the dominant strategy for the case where there are only two propositions and the oracles are exactly correct about the probabilities,
but I haven't checked the details of this argument.</p>


<p>
 So what this means in practice is that if some elements of your reasoning are "screened off" from you as black boxes,
and you do not have full knowledge in advance of the set of available options,
even a fully VNM-rational Bayesian reasoner will necessarily exhibit intransitive preferences.</p>


<p>
 However! Note that
 <em>
  this does not mean that they can be Dutch Booked</em>.
The reason for this is that the proper Bayesian reasoner will update their posteriors about propositions as they are forced to make choices.
This may in fact mean that the time varying preferences they make are actually transitive, at least in the limit, while their instantaneous preferences are not.</p>


</section>
<section>
<h2><a href="/posts/2018-09-13-11:02.html">2018-09-13</a></h2>


<p class="subtitle">Notes from reading "Rigour and Structure"</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-13</dd>
</dl>


<blockquote>
<p>
  The distinctive definition-theorem-proof format of professional publications is the single most conspicuous feature of mathematical practice.</p>
<p>
  The quality whose presence in a purported proof makes it a genuine proof by present-day journal standards, and whose absence makes the proof spurious in a way that if discovered will call for retraction, is called rigor.</p>
<p>
  The assessment of purported proofs for rigor is generally not the topic of a separate course.</p>
<p>
  Mathematicians views on the nature of rigor and proof may more often be expressed in aphorisms and epigrams, in anecdotes and jokes, for instance, of the common an engineer, a physicist, and a mathematician genre, than in formal theoretical pronouncements.</p>
<p>
  contrary to the dictum that a proof is what convinces, not everything that convinces is a proof</p>
<p>
  such methods, and other aspects of early modern mathematics, also exemplify what I will call reliance on generic reasoning. By this I mean performing calculations or manipulations that usually or generally work but sometimes or exceptionally fail, treating as universally applicable techniques that are  and may be known to be  only applicable in favorable cases, in the hope and belief that the case in which one is interested is one of the favorable ones, but without any rigorous justification for supposing this to be so.</p></blockquote>


<p>
 On uniform continuity:</p>


<blockquote>
<p>
  The distinction is a matter of the order of quantifiers (all-all-exists vs all-exists-all, or in logicians notation \(\forall\forall\exists\) and \(\forall\exists\forall\) cannot be made unless the quantifiers have been made explicit and not left implicit in expressions like close as desired or close enough.</p>
<p>
  Proofs depending on calculations, in particular, are especially likely to go wrong if the calculations are long and complicated enough.</p>
<p>
  Rigorism imposes no restriction on definitions other than rigor, and leaves one perfectly free to explore definitions that may at first seem complicated and unnatural, if there are grounds for hoping they will be useful and fruitful.</p>
<p>
  Owing to the freedom to introduce useful new notions regardless of simplicity or naturalness, so long only as they are rigorously defined, nothing need be lost.</p>
<p>
  Time and again during the early twentieth century non-rigorous but useful methods introduced by physicists or engineers were found to have rigorous counterparts, the development of which at the very least clarified the scope and limits of the techniques, and more often than not had other side benefits as well.</p>
<p>
  Brouwers mysticism led him to believe that mathematics is largely an incommunicable mental activity, not to say an ineffable meditative practice, and as a result the rules of intuitionist game were never clearly articulated</p>
<p>
  Deduction and Deducibility. Here one must confront the fact that if one looks to logic textbooks, though one will find an agreed characterization of logical consequence, which I have already discussed, one finds no agreed characterization of logical deduction.</p></blockquote>


<p>
 The point being that logic has more to say about the process that determines what the true statements are than how to actually determine the true statements. This is analagous to the enumeration vs predicate view of a set.</p>


<blockquote>
<p>
  [Mathematical logic] resembles mathematical physics and mathematical economics in that its models are highly idealized. In particular, as I have been emphasizing, it gives a quite good model of mathematical deducibility, but a much poorer model of mathematical deduction.</p></blockquote>


<p>
 The point being that formal logic is a kind of "spherical cow in a vacuum" version of actual logic performed by real mathematicians.</p>


</section>
<section>
<h2><a href="/posts/2018-09-10-13:14.html">2018-09-10</a></h2>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-10</dd>
</dl>


<p>
 (Lightly edited)
 <a href="https://twitter.com/DRMacIver/status/1039106038425903104">
  exchange from Twitter</a></p>


<blockquote>
<p>
  Me: These days I think I'm in favour of a hung parliament. *checks dictionary* Oh that's not what it means. Never mind.</p>
<p>
  Jack: Are you fishing for "hanged parliament"?</p>
<p>
  Me: No, people are hanged.
  <em>
   Animals</em>
  are hung.</p></blockquote>


<p>
 I don't actually ascribe to this worldview (I believe very strongly that dehumanizing your opponents is morally indefensible no matter how evil you think they are),
and there are literally dozens of MPs who I would be sad if they were hanged,
but sometimes my inner evil overlord just insists on coming out to play.</p>


<p>
 Also I really want to use this line in a story now.</p>


</section>
<section>
<h2><a href="/posts/2018-09-10-09:52.html">2018-09-10</a></h2>


<p class="subtitle">What might a continuous rational agent look like?</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-10</dd>
</dl>


<p>
 In a
 <a href="https://notebook.drmaciver.com/posts/2018-09-09-21:02.html">
  previous post</a>
 I said I didn't care much about this problem,
which obviously nerd-sniped me into thinking about it.</p>


<p>
 So, the question is: We have a "rational" agent which is making choices over pairs of lotteries \(\mathcal{L}\),
and it does this in terms of a function \(\tau : \mathcal{L}^2 \to [0, 1]\) where \(\tau(u, v)\) means "the probability of choosing \(u\) in preference to \(v\).</p>


<p>
 We had the nice (ish) VNM theory for physically impossible discontinuous rational agents,
but what should the axioms for a continuous rational agent look like?</p>


<p>
 The following seem like they should obviously hold:</p>


<ol>
<li>
  \(\tau(L, M) = 1 - \tau(M, L)\).</li>
<li>
  If we define \(L \prec M\) as meaning \(\tau(L, M) = 1\) then \(\preceq\) should be a partial order.</li>
<li>
  If we define \(L \tilde M\) as meaning \(\tau(L, M) = \frac{1}{2}\) then whenever \(L \tilde L', M \tilde M'\) we have \(\tau(L, M) = \tau(L', M')\).</li>
<li>
  If \(\tau(L, pL + (1 - p) M)\) should be monotonic in \(p\), and whenever it is non-constant that monotonicity should be strict.</li>
<li>
  For any pure lotteries (that is, lotteries which take a single outcome with probability \(1\)) \(\tau(L, M) \in \{0, 1, \frac{1}{2}\). i.e. for any concrete outcomes the agent either has a strict preference or is indifferent between them.</li>
<li>
  \(\tau(L, pM + (1 - p)N) \geq \min \tau(L, M), \tau(L, N)\)</li></ol>


<p>
 Together with the continuity requirement, these give us roughly the equivalence of the first four
 <a href="https://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Morgenstern_utility_theorem">
  VNM axioms in Wikipedia's ordering</a>.</p>


<p>
 In contrast, the independence requirement obviously doesn't and can not hold in any meaningful sense for such an agent.
Pick two lotteries with \(L \prec M\). Consider \(\tau(pL + (1 - p)N, pM + (1 - p)N)\).
This is a continuous function of \(p\), and when \(p = 0\) it is equal to \(\frac{1}{2}\),
therefore for any \(\epsilon &gt; 0\) there must be some \(0 &lt; p &lt; 1\) we must have \(\tau(pL + (1 - p)N, pM + (1 - p)N) &lt; \epsilon\),
which breaks independence in a very strong way.</p>


<p>
 I think this lack of independence is in some sense the "essential difference" between a continuous and a discrete rational agent.</p>


<p>
 I'm not sure the above are the full set of axioms required. They feel a bit weak - I think more may need to be said about the relationships between \(\tau\) values over convex combinations of lotteries.</p>


<p>
 However,
the following two examples might be illuminating in terms of things that obviously
 <em>
  should</em>
 be considered rational agents:</p>


<p>
 Let \(\mu\) be some utility function over outcomes and let \(\alpha: [0, \infty) \to [0, 1]\) be monotonic decreasing with \(\alpha(0) = 1\) and \(\alpha(x) \to 0\) as \(x \to \infty\).
If \(E(\mu(L)) &gt; E(\mu(M))\) then let \(\tau(L, M) = \frac{1 - \alpha(E(\mu(L)) - E(\mu(M)))}{2}\).
Otherwise extend according to the requirement that \(\tau(L, M) = 1 - \tau(M, L)\).</p>


<p>
 The idea is basically that \(\alpha\) acts as a decision procedure about whether it's worth finding out more information - it represents the probability of giving up and flipping a coin. You run this procedure by observing to increasingly high precision until you either know that alpha is large enough that you should give up (based on a non-deterministic choice of doing so) or which side of the border you're on.</p>


<p>
 Another procedure that I think can not be realised as an instance of that but should still be considered rational is how a logically omniscient Bayesian agent who is only able to access the lotteries through sampling might behave.
You start with some prior distribution over lotteries (maybe an improper one) and query the sampler for each, with some cost function \(\alpha: \mathbb{N} \to [0, \infty)\) for how expensive it is to evaluate \(n\) samples (probably \(\alpha\) is a linear function). You stop and choose as soon as you hit a point where your expected value (under your posterior distributions) of acquiring more information is strictly less than the expected value of choosing one of the outcomes.</p>


<p>
 I don't want to suggest that either of the two above are the
 <em>
  only</em>
 possible rational agents in such circumstances.
I suspect in fact that there's a much broader diversity of behaviour possible than for VNM rational agents,
which might make any axiomatic classification hard.</p>


</section>
<section>
<h2><a href="/posts/2018-09-10-08:45.html">2018-09-10</a></h2>


<p class="subtitle">Programming vs Mathematics</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-10</dd>
</dl>


<p>
 Programming: "Custom operators and single letter variable names? Why so terse? Bytes are cheap! Suspish. Not sure if want. Code should be optimised for reading, not writing!"</p>


<p>
 Mathematics: "Let \(\alpha, \gamma, \beta\) be as in theorem 17.1. If \(\gamma \wedge \beta\) is a normal R-domain, then \(\mu(\alpha \oplus \gamma) \dagger \beta\) is quasi-uniform."</p>


<p>
 (No, that's not an actual quote and those terms don't really mean anything)</p>


</section>
<section>
<h2><a href="/posts/2018-09-09-21:02.html">2018-09-09</a></h2>


<p class="subtitle">Physical and Topological Limitations to Rational Choice</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-09</dd>
</dl>


<p>
 Epistemic status: Confident.</p>


<p>
 Attention conservation notice: So much inside baseball.</p>


<p>
 Context: This is something I've known about for a while but couldn't find a concise write-up of that I had previously written and still liked,
so I thought I'd just rewrite it here.</p>


<hr/>


<p>
 The
 <a href="https://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Morgenstern_utility_theorem">
  Von-Neumann-Morgenstern utility theorem</a>
 states that if you ask people to choose between finite lotteries over outcomes,
any "rational" behaviour looks like picking based on whichever gives the greatest expected utility according to some utility function over the outcomes.</p>


<p>
 I have a number of objections to this idea,
but my main one is this:
Regardless of the axioms you choose for rationality,
it's physically impossible to implement an agent that can express the sort of total order over lotteries that VNM rationality is a theorem about,
even if you grant the existence of logically omniscient agents (you can do it if you grant the existence of
 <em>
  actually</em>
 omniscient agents).</p>


<p>
 Why?</p>


<p>
 Well, suppose we have some total preorder \(\preceq \subseteq \mathcal{L}^2\), where \(\mathcal{L}\) is the set of lotteries over some finite set of outcomes.
Take this total order and define the choice function \(\tau : \mathcal{L}^2 \to \{-1, 0, 1\}\) where \(\tau(u, v) = 0\) if \(u \preceq v\) and \(v \preceq u\),
else if \(u \prec v\) then \(\tau(u, v) = -1 = -\tau(v, u)\). i.e. \(\tau\) is a function determining whether we strictly prefer one or are indifferent between the two.</p>


<p>
 Any choice that a physical agent makes must be based on a finite (but not necessarily bounded up front) set of observations.
Each of those observations can only give you information about the world up to some non-zero (but potentially arbitrarily small) tolerance.
In particular, if we have lotteries \(u_1 \preceq u_2\), there is some \(\epsilon &gt; 0\) such that if \(d((u_1, u_2), (v_1, v_2) &lt; \epsilon\),
we must have \(\tau(v_1, v_2) = \tau(u_1, u_2)\), because we only ever looked at \(u_1, u_2\) up to some finite precision.</p>


<p>
 In particular this means that \(\tau: \mathcal{L}^2 \to \{-1, 0, 1\}\) is a continuous function!</p>


<p>
 Unfortunately, \(\mathcal{L}^2\) is a connected topological space and \(\{-1, 0, 1\}\) is totally disconnected.
Thus any continuous function must be constant. We know that \(\tau(u, u) = 0\), so we must have \(\tau(u, v) = 0\) for all \(u, v\).
i.e. the only physically possible total preorder that we can express is the one that is totally indifferent between lotteries.</p>


<p>
 If the above argument makes no sense to you, another way to look at it is that you need to know \(u\) and \(v\) to infinite precision at the boundary.
If you are on a boundary point where \(\tau(u, v) = 0\), moving slightly in the direction of \(u \prec v\) immediately forces your hand,
so you cannot satisfy that continuity property at the boundary.</p>


<p>
 This problem can be made to go away by removing the indifferent set from the set of lotteries you consider - it's perfectly physically possible to distinguish the lotteries if you know a priori that you will definitely have a preference for one of them.
Unfortunately there are several problems with this:</p>


<ol>
<li>
  Where does that a priori knowledge come from? It's obviously not true in general - you have to somehow avoid ever being asked to choose between a lottery and itself.</li>
<li>
  The VNM axioms rely crucially on the use of indifference in the continuity axiom.</li>
<li>
  The implementation of such a choice function is still physically fraught, because as you approach the boundary the amount of precision you require to decide tends to infinity.</li></ol>


<p>
 It is possible that there is some cunning workaround that lets you rescue VNM choice theory, but I find it very implausible that this is the case.
The basic requirement that you construct a discrete function of the world is intrinsically aphysical, and it seems very hard to rescue that.</p>


<p>
 I have yet to sit down and think through exactly what I would like in its place in any great depth, mostly because nobody except me cares about this problem and I don't care enough to pursue it solo,
but my preferred primitive is to replace the choice function with a continuously varying choice probability, so instead you have a function  \(\tau: \mathcal{L}^2 \to [0, 1]\), where \(\tau(u, v)\) is the probability of choosing \(u\) over \(v\),
and \(\tau(v, u) = 1 - \tau(u, v)\).
This neatly side steps all of the problems with using a discrete choice function, because you don't need to know the outcome probabilities with infinite precision in order to make your choice, and \([0, 1]\) is a connected topological space so, unlike discrete choices, it's perfectly possible to construct such functions.</p>


</section>
<section>
<h2><a href="/posts/2018-09-09-19:26.html">2018-09-09</a></h2>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-09</dd>
</dl>


<p>
 I previously wrote
 <a href="https://www.drmaciver.com/2014/10/order-dependence-in-preference-elicitation/">
  a post about NP-hardness in decision theory</a>.
On rereading it, I think its tone really doesn't help its point at all, so I thought I'd quickly write up a more formal version.</p>


<p>
 The basic point is this: If you don't assume computation is free, NP-hard problems prove an interesting barrier to decision making that satisfies the classical "rationality" axioms.</p>


<p>
 Suppose you have an NP-hard problem (say a SAT instance), \(S\), and are offered a choice between the following three options:</p>


<ol>
<li>
  A certain reward \(R_1\).</li>
<li>
  A reward \(R_2 &gt; R_1\) if a particular solution \(x\) witnesses that \(S\) is satisfiable.</li>
<li>
  A reward \(R_3 &gt; R_2\) if \(S\) is satisfiable.</li></ol>


<p>
 Arrange the values such that \(\alpha_2 \ll R_2 - R_1 &lt; R_3 - R_1 &lt; \alpha_3\),
where \(\alpha_i\) is the cost of solving the computational problem that would allow you to determine the pay off of these choices.
i.e. the difference in reward is big enough that it is worth evaluating one solution, but small enough that it's not worth solving the problem.</p>


<p>
 You should always strictly prefer \(3\) to \(2\),
because under every circumstance where \(2\) pays anything, \(3\) pays a larger amount.</p>


<p>
 Additionally, you should prefer \(2\) to \(1\) if and only if \(x\)
 <em>
  is</em>
 a witness - because it's cheap enough to check,
you just acquire the information and be done with it (if you want to quibble about expected payoffs, assume that \(\alpha_2\) is really really small).</p>


<p>
 However, you should also prefer \(1\) to \(3\),
because the possible reward you can gain by solving the problem is not worth the cost,
so you should take the certain reward instead.</p>


<p>
 This means that if \(x\) is chosen so that it
 <em>
  is</em>
 a witness,
you have an intransitive preference \(2 &gt; 3 &gt; 2 &gt; 1\).</p>


<p>
 Another way of thinking about this is that the choices over this problem are not
 <em>
  subset consistent</em>.
The choice you make from \(\{1, 2, 3\}\) in the case that \(x\) is a solution is either \(3\) - evaluating \(2\) tells you that it's worth choosing \(3\) over \(1\),
so you can skip paying the cost and just choose the good option. In contrast, your choice when picking from \(\{1, 3\}\) would be \(2\) - removing a value that was not the chosen answer has caused your opinion to flip.</p>


</section>
<section>
<h2><a href="/posts/2018-09-08-10:59.html">2018-09-08</a></h2>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-08</dd>
</dl>


<p>
 Terry Tao has an interesting series of posts:</p>


<ul>
<li>
<a href="https://terrytao.wordpress.com/2009/11/05/the-no-self-defeating-object-argument/">
   The no self-defeating object argument</a></li>
<li>
<a href="https://terrytao.wordpress.com/2010/10/18/the-no-self-defeating-object-argument-revisited/">
   The no self-defeating object argument, revisited</a></li>
<li>
<a href="https://terrytao.wordpress.com/2010/11/02/the-no-self-defeating-object-argument-and-the-vagueness-paradox/">
   The no self-defeating object argument, and the vagueness paradox</a></li></ul>


<p>
 The idea of the "no self-defeating object" argument is, roughly, that suppose there were some some object that "defats" all objects,
then it would also defeat itself, and thus cannot exist. It's a specific form of reductio ad absurdum,
and can be applied to many different forms of "object" and notions of "defeat".</p>


<p>
 Examples:</p>


<ul>
<li>
  There is no largest number ("defeat" here meaning something like \(\geq n + 1\)).</li>
<li>
  There is no set of sets ("defeat" meaning \(\in\)).</li></ul>


<p>
 In the second post he outlines how we can almost always turn these arguments instead into "every object is defeated by some other object", and this often works better for people uncomfortable with proof by contradiction (which is most non-mathematicians).</p>


<p>
 The third post is especially interesting in the light of
 <a href="https://notebook.drmaciver.com/posts/2018-09-08-08:06.html">
  my recent post about the nature of mathematics</a>
 ,
in that it observes that an unusual characteristic of mathematics is that mathematical statements are intended to have a precise meaning in a way that natural language statements typically are not.</p>


<p>
 This suggests the following modified definition:</p>


<blockquote>
<p>
  Mathematics is the study of unambiguous statements about hypothetical objects</p></blockquote>


</section>
<section>
<h2><a href="/posts/2018-09-08-10:40.html">2018-09-08</a></h2>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-08</dd>
</dl>


<p>
 The
 <a href="http://cs.brown.edu/courses/csci0190/2018/laptop-policy.html">
  laptop policy</a>
 from Shriram Krishnamurthi's "Accelerated Introduction to Computer Science" class is an interesting collection of resources on laptop usage in class.</p>


<p>
 I've definitely found that it is true that longhand note taking improves my retention and focus while device usage immediately kills it. The point about device usage distracting
 <em>
  other</em>
 people around you is particularly interesting though.</p>


<p>
 I feel like imposing this sort of rule is a deeply unpopular move in my social group,
but I think they're mostly wrong about that.
OTOH this is very much a question of competing access needs and I'm not sure what the best way to resolve it is.`</p>


</section>
<section>
<h2><a href="/posts/2018-09-08-10:39.html">2018-09-08</a></h2>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-08</dd>
</dl>


<p>
<a href="https://how.complexsystems.fail/">
  How Complex Systems Fail</a>
 is very good. A lot of the citations have been on my reading stack for a while,
and given that I'd already deprioritised them I'm now inclined to just not bother now that I've read the TLDR.</p>


</section>
<section>
<h2><a href="/posts/2018-09-08-08:06.html">2018-09-08</a></h2>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-08</dd>
</dl>


<p>
 I've been trying to come up with a definition of mathematics that I like and think would be useful in the course of teaching people mathematics.</p>


<p>
 This is of course a big ask, as
 <a href="https://en.wikipedia.org/wiki/Definitions_of_mathematics">
  according to Wikipedia there is a great deal of spirited philosophical debate on the subject</a>
 ,
but on the other hand I think most of those definitions are
 <em>
  terrible</em>
 , so I don't feel too bad about trying myself.</p>


<p>
 The one I dislike the least from that list is
 <a href="http://mathworld.wolfram.com/Mathematics.html">
  Eric Weisstein's</a>
 :</p>


<blockquote>
<p>
  Mathematics is a broad-ranging field of study in which the properties and interactions of idealized objects are examined.</p></blockquote>


<p>
 It's a bit long-winded but mostly captures the sense I want. The phrasing I've been thinking of in preference is something more like:</p>


<blockquote>
<p>
  Mathematics is the rigorous study of hypothetical objects.</p></blockquote>


<p>
 The idea is that in mathematics we're not really concerned with real life physical objects,
we can just say "Suppose there were objects satisfying the following properties, what can we reliably say about them?"</p>


<p>
 Sometimes those objects are ones that can easily be realised as real physical objects. For example the
 <a href="https://en.wikipedia.org/wiki/Mathematical_chess_problem">
  Mathematics of Chess</a>
 studies hypothetical chess boards,
but those hypothetical chess boards can easily be realised by going out and buying an actual physical chessboard.
However, many of them can not be. There is no way to construct a real physical set of natural numbers,
but from a mathematical point of view that's OK - we can reason about the properties of the hypothetical one perfectly well.</p>


<p>
 There are a couple axes of variation on which people differ about the nature of mathematics:</p>


<ol>
<li>
  Is informal mathematics legitimate, or should all mathematics be considered a (possibly bad) approximation to an entirely formal set of reasoning rules?</li>
<li>
  Are some hypothetical objects privileged as the true platonic mathematical objects in a way that others are not?</li></ol>


<p>
 I think this definition is more or less compatible with any combination of answers to these questions:
Formalism is a question of what we count as "rigorous",
and even if there
 <em>
  are</em>
 platonic mathematical objects, we still must study them
 <em>
  as if</em>
 they were hypothetical because by its very nature we cannot have access to the platonic realm.</p>


<p>
 Traditionally the answers to these questions have been correlated more than I think is logically required:
The formalist position is that mathematics doesn't real and that everything is formal manipulation of symbols,
while the platonist position is that we are seeking to discover truths about the ideal platonic realm and the truths are what matter regardless of how we reason about them.</p>


<p>
 I think there's room for a third position though, which is that formalism is interesting but not strictly required, but the objects we describe have no inherent reality and really are allowed to be purely hypothetical.
I've historically self-described as a formalist, but I think this third position is closer to my true beliefs:
I don't think Platonism is philosophically defensible,
but I do think there is a lot of interesting mathematical content and activity that cannot be adequately captured by the formalist position.</p>


<p>
 In many ways this third position is that of Lakatos in his "Proofs and Refutations".
Most of the interesting mathematics happens in a fuzzy middle-ground where you are making your definitions precise enough to be defensible.
This could go all the way to formalism, but it doesn't have to.</p>


<p>
 The mathematics of chess is again an interesting test case here:
Chess is a purely arbitrary set of rules. I think it would be hard to argue that there is a platonic game of chess that is in some essential way different than it would have been if,
say, kings moved like knights or you could win by killing the queen
 <em>
  or</em>
 the king. These are both perfectly valid games that someone could play,
and there is a perfectly valid mathematics in studying them, but we study the mathematics of chess in preference to them because that is the actual game people play.</p>


<p>
 Conversely,
there really is a set of true statements about the game of chess (in an informal sense of chess),
and while mechanising and formalising the study of them might be
 <em>
  useful</em>
 for determining what they are, I think it's fair to say that what actually matters is whether the statement is true of real games of chess,
and the formalisation only matters to the degree that it helps us discover those truths.</p>


<p>
 I don't think the above definition is enough to fully reconstruct an idea of what mathematics is like,
because it leaves open two big questions:</p>


<ol>
<li>
  How do we select which hypothetical objects to study?</li>
<li>
  How do we study them?</li></ol>


<p>
 The answer to the first is comparatively easy, which is that it's based on what I think of as "The Three Good Reasons To Do Things":</p>


<ol>
<li>
  It's useful.</li>
<li>
  It's interesting.</li>
<li>
  Some asshole is forcing you to do something useless and boring.</li></ol>


<p>
 (Most people's encounters with mathematics is of type 3, sadly, which is why I always hear "Oh I
 <em>
  hated</em>
 mathematics at school" when I tell people I did mathematics at university)</p>


<p>
 Of course, point 2 is slightly subtle, because doing mathematics is much easier if other people have done similar mathematics, so you're constrained not just by what
 <em>
  you</em>
 think is interesting, but by what you can convince other people is interesting.</p>


<p>
 The second question is the hard part, and I think we currently do a very poor job of explaining it to people. I need to think further about it.</p>


</section>
<section>
<h2><a href="/posts/2018-09-07-15:47.html">2018-09-07</a></h2>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-07</dd>
</dl>


<p>
 The thing I called
 <a href="https://notebook.drmaciver.com/posts/2018-08-30-07:50.html">
  the Feynmann style</a>
 relates to Tim Gowers's
 <a href="https://www.dpmms.cam.ac.uk/~wtg10/2cultures.pdf">
  The Two Cultures of Mathematics</a>
 ,
where he suggests that there are two cultures of mathematics: Theory building and problem solving. The latter tends to get organised not along the lines of general big ideas and broad theorems,
but instead along heuristics and guiding principles.</p>


<p>
 Gowers refers to the areas of mathematics that are primarily problem-solving as
 <em>
  combinatorial</em>
 ,
but I feel like this kind of problem solving is one that it doesn't seem right to refer to as combinatorial - it's more... calculation?</p>


<p>
 There's a similar sense of being guided by heuristics and general ideas though.</p>


<p>
 For example, one general idea is "replace annoying terms with integrals over some new variables, then swap out the variable".</p>


<p>
 Suppose we didn't know what \(\sum\limits_{n = 1}^\infty (-1)^{n - 1} \frac{1}{n}\) was.
How would we deal with this?</p>


<p>
 (Note: There's all sorts of playing fast and loose with convergence in this post that you can shore up later with some proper calculation but I'm not actually going to do. That's very common in this sort of proof).</p>


<p>
 Well, that \(\frac{1}{n}\) is an annoying term. Lets get rid of it with.
A classic way of doing this is to replace it with \(\int\limits_0^1 x^{n - 1} dx\).</p>


<p>
 We can now do the computation as follows:</p>


<p>
 \begin{align}
\sum\limits_{n = 1}^\infty (-1)^{n - 1} \frac{1}{n} &amp; = \sum\limits_{n = 1}^\infty (-1)^{n - 1} \int\limits_0^1 x^{n - 1} \\
&amp; = \sum\limits_{n = 0}^\infty (-1)^n \int\limits_0^1 x^n \\
&amp; = \int\limits_0^1 \sum\limits_{n = 0}^\infty (-x)^n \\
&amp; = \int\limits_0^1 \frac{1}{1 + x} \\
&amp; = \ln(1 + x) \\
\end{align}</p>


<p>
 Roughly the steps here are:</p>


<ol>
<li>
  Try replacing tricky terms with integrals over simpler terms</li>
<li>
  Use standard sums that you already know the answer for</li>
<li>
  Try swapping sums and integrations</li></ol>


<p>
 Another useful calculational heuristic is "try changing the variable".</p>


<p>
 e.g. what's the limit as \(n \to \infty\) of \(n \ln (1 + \frac{1}{n})\)?</p>


<p>
 Well, let \(x = \frac{1}{n}\). This expression is now \(\frac{ln(1 + x)}{x} = \frac{ln(1 + x) - \ln(1)}{x}\) as \(x \to 0\).
i.e. it's the derivative of \(\ln\) at \(1\), i.e. \(1\).</p>


<p>
 It's hard to explain exactly what the thought process is here. It's like solving a puzzle - you have a bunch of known tricks that you think might work and you try to apply them all.
If you were to mechanize the process then it wuold end up looking like a brute force solver for the problem, but by using intuition you can kinda guide the way.</p>


<p>
 I think maybe one part of the split between problem-solving and theory building is how much of what you end up building escapes the head of the mathematician building it:
Problem-solving skills are much harder to teach to another person than theory is (once that other person has build the skill of acquiring theory, which is also hard to teach)</p>


</section>
<section>
<h2><a href="/posts/2018-09-07-15:27.html">2018-09-07</a></h2>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-07</dd>
</dl>


<p>
 Compare and contrast:</p>


<ul>
<li>
<a href="https://www.cambridge.org/core/journals/journal-of-the-american-philosophical-association/article/aristotle-on-trolling/540BB557C82186C33BFFB61E35A0B5B6">
   "Aristotle" on trolling</a></li>
<li>
<a href="https://www.drmaciver.com/2014/02/etiquette-for-the-devils-advocates/">
   Etiquette for the Devil's advocates</a></li></ul>


<p>
 I think the role the "Aristotle" (AKA
 <a href="http://individual.utoronto.ca/rbarney/Home.html">
  Rachel Barney</a>
 ) describes is probably quite a useful one in the right context,
the problem is that the nature of Trolling as defined in that paper is intrinsically that it is done
 <em>
  not</em>
 in the right context.</p>


<p>
 There's a thing that happens in Vernor Vinge's "A Deepness in the Sky" where the Evil Overlord  is experimenting with different configurations you can put a group mind in.
I sometimes think about this as an analogy for how to construct better modes of group problem solving (in a non-evil-overlord way that in no way involves my using the army of crows that I don't have to impose my will on the unsuspecting masses. Yes) .</p>


<p>
 In particular, I think it's often actively useful for someone to explicitly take an adversarial role in a group discussion,
and it improves the resulting group's intelligence.
The difficulty is that you need to do this in a context where the group consents to this, and with a fairly explicit discussion in advance of boundaries.
It also helps to be able to ask the adversary to step out of the adversarial role and clarify their position.</p>


</section>
<section>
<h2><a href="/posts/2018-09-07-12:32.html">2018-09-07</a></h2>


<p class="subtitle">When come back bring pie(s)</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-07</dd>
</dl>


<p>
 There's a metaphor people use: Some people fight for a larger slice of the pie, others see that it's better to enlarge the pie.</p>


<p>
 I've seen this metaphor used for everything from intersectional feminism to the Patrician of Ankh-Morpork's extremely libertarian brand despotism.
Broadly the point is this: It's better to build a positive sum game where everyone benefits than it is to compete in a zero or negative sum game.</p>


<p>
 The relationship between this point and the metaphor is interesting.
I agree with the thing that I am claiming to be the underlying point (but then I would), but I think what the actual metaphor demonstrates is also interesting:
People don't understand how pies work.</p>


<p>
 What happens when you build a bigger pie?</p>


<ol>
<li>
  You run into scaling issues, limited both by the size of your oven and also (if you build a better oven) the square-cube law (actually I'm not sure if this is the square-cube law at work, as pies tend to be scaled horizontally faster than they are scaled vertically, but either way once your pie gets big enough it's very hard to ensure it's cooked all the way through - you end up with overdone outsides and and underdone middle).</li>
<li>
  The same people who couldn't eat your smaller pie still can't eat your larger one.6</li></ol>


<p>
 The correct solution is not to enlarge the pie. It's to
 <em>
  bake more pies</em>
 , and also the provide tasty food that is not pie because not everyone likes pie.</p>


<p>
 If you've ever tried catering to a diverse group of dietary requirements, at some point you hit the point where you realise that it's much much easier to make multiple dishes than it is to try to create a single dish that can feed everyone.
A vegan gluten free nut free diabetic friendly pie is certainly possible, but it is a pie that basically nobody is going to
 <em>
  want</em>
 to eat.
In contrast, a wide variety of desserts that can cater to each particular restriction that your group encounters,
without attempting to shoehorn everyone into a one size fits all badly model.</p>


<p>
 The Unit of Caring has a notion she uses a lot of
 <em>
  competing access needs</em>.
She
 <a href="https://theunitofcaring.tumblr.com/post/135162290121/hi-i-have-a-quick-question-i-tried-googling-but">
  explains it well here</a>
 ,
but the important quote (to save you from Tumblr's giant GDPR screen) is:</p>


<blockquote>
<p>
  Competing access needs is the idea that some people, in order to be able to participate in a community, need one thing, and other people need a conflicting thing, and instead of figuring out which need is real we have to acknowledge that we cant accommodate all valid needs.
I originally encountered it in disability community conversations: for example, one person might need a space where they can verbally stim, and another person might need a space where theres never multiple people talking at once. Both of these are valid, but you cant accommodate them both in the same space.</p></blockquote>


<p>
 Trying to build a space that works for everyone is more or less impossible, and what you will end up with is a space that works badly for everyone.
Instead we need the ability to have multiple spaces which we acknowledge as valid and allow people to freely move between these spaces as long as they are prepared to accept the local rules.</p>


<p>
 In an interesting coincidence, this came up in a completely different context recently.
A while back
 <a href="https://www.drmaciver.com/2016/05/randomizing-lean-coffee/">
  I sketched out a way of using randomization to improve the design of Lean Coffee meetups</a>.
 <a href="https://twitter.com/georgesdubus/status/1037957014599749632">
  This morning a friend reported</a>
 :</p>


<blockquote>
<p>
  I used to organize David-Style lean coffees at my previous job. (...)
The interesting limitation we ran into is that toward the end, the attendence was two groups with mostly disjoint interests.</p></blockquote>


<p>
 The nice thing about small-scale democratic processes like this is that splitting the union is a completely legitimate move.
If you have two groups with disjoint interests, why not run them as two groups? Ideally at different times so that people who really
 <em>
  are</em>
 interested in both can attend both.</p>


<p>
 How to do this sort of thing at a larger scale seems to be one of the great unsolved problems of society.</p>


</section>
<section>
<h2><a href="/posts/2018-09-06-10:14.html">2018-09-06</a></h2>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-06</dd>
</dl>


<p>
 Follow on to
 <a href="https://notebook.drmaciver.com/posts/2018-09-05-13:24.html">
  misc thoughts about voting design for talk scheduling</a>.</p>


<p>
 Here's how a system that is much closer to classic STV could work.
Assume everyone has a ranking of all the talks they wish to attend (this isn't actually reasonable to ask for, but you could get people to score talks according to some ordinal scores and then randomly tie break, or tie break in organiser preferred order or something).</p>


<p>
 The system has the following three parameters:</p>


<ol>
<li>
  The number of time slots.</li>
<li>
  The number of talks per time slot.</li>
<li>
  The minimum number of attendees required for a talk to be worthwhile (should be at least one). Callt his the threshold.</li></ol>


<p>
 You also need to pick a quota system. Either the
 <a href="https://en.wikipedia.org/wiki/Comparison_of_the_Hare_and_Droop_quotas">
  Droop or the Hare quota</a>
 are the obvious choices.
My natural bias is to use the Hare quota, as it's better for minority interests and I think that's a nice feature to have in your conference talk selection (conferences have a tendency to have the same talks over and over again and I think this would help offset that).</p>


<p>
 The system could easily be adapted to more complicated constraints in which not all talk/time slot combinations are valid, but I'm going to ignore that.</p>


<p>
 Conceptually what happens is everyone is given one voting-buck,
and a talk slot "costs" an amount of voting-bucks equal to the quota.
People band together to form buying blocs and each spend the same percentage of their remaining pool of voting money to buy a slot (this is basically how normal STV works too).</p>


<p>
 The system involves running the following process to a fixed point:</p>


<ol>
<li>
  Set the list of eligible talks to all talks which have at least the threshold number of people voted for them.</li>
<li>
  Give everyone exactly one vote (note: as the process evolves, people will have fractional votes).</li>
<li>
  People vote for (talk, slot) pairs, where the slot has not already been filled and the talk is both eligible and not yet scheduled.
   They will vote for a pair if:
  <ol>
<li>
    The talk their highest ranked talk among the available talks.</li>
<li>
    If there are slots which have no talks they want to see in them, they will only vote for pairs in those slots.
   Otherwise they will vote for pairs where they prefer the talk to the one currently scheduled there.
   Note that a voter can vote for multiple (talk, slot) pairs.</li></ol></li>
<li>
  If there are no such pairs, we have scheduled all of the talks we can (even if there still unfilled slots). Stop and report this as the schedule.</li>
<li>
  If any of the pairs has a total number of votes exceeding the quota, pick the one with the most votes and schedule that.
   For each voter who voted for it, multiply their remaining vote by \(1 - \frac{q}{r}\), where \(q\) is the quota and \(r\) is the total vote for the elected slot
   (i.e. we've removed \(q\) from their total vote and everybody pays it equally).</li>
<li>
  If no pair was elected, take the talk with the lowest maximum vote over all vote pairs, and remove it from the list of eligible talks.</li>
<li>
  If a pair was elected, now check if any talks can no longer meet the threshold - i.e. if for every slot you could schedule them in,
   count the number of people for whom that is their favourite talk in that slot. If there are no slots where this exceeds the threshold, remove the talk from the eligible list.</li>
<li>
  If we removed any talks from the eligible list, reset all of the state except the list of eligible talks and go back to step 2. Otherwise go back to step 3.</li></ol>


<p>
 Most of this is just variant STV, with some of the specific details owing to specific types of STV.
The main difference is that because the same voter may cast their vote for multiple options simultaneously,
we need to be careful not to elect more than one "candidate" at once,
plus the specialised drop-out rule for talks that fail to meet the threshold.</p>


<p>
 Most of my problems with it are the same as my problems with STV in general: It looks like an iterative optimisation process, but it's not at all clear what it is you are optimising for.
So it might work well, but I'm not really sure how you would measure "well" in this context.
It seems plausibly worth a try though.</p>


</section>
<section>
<h2><a href="/posts/2018-09-05-13:24.html">2018-09-05</a></h2>


<p class="subtitle">Mechanisms for talk scheduling and voting</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-05</dd>
</dl>


<p>
 I've been thinking about mechanism design for conference scheduling again.
I've
 <a href="https://www.youtube.com/watch?v=OkusHEBOhmQ">
  previously argued that conference scheduling should be treated as an optimisation problem</a>
 ,
but I no longer believe that's true.</p>


<p>
 In particular I think the following hold:</p>


<ul>
<li>
  If we treat talk selection as a voting problem, we must employ some mechanism of proportional representation</li>
<li>
  In a multi-track conference, scheduling and selection cannot be separated.</li></ul>


<p>
 Lets see some examples in support of this.</p>


<p>
 Suppose you're running a Python conference, and 60% of the people attending are web developers and 40% are data scientists.
You put together a set of talk proposals, people vote on them, and you take all of the top voted talks.
What you end up with is of course a conference consisting entirely of web development talks.</p>


<p>
 (Note: Despite the running Python example, this post is not actually about
 <a href="https://2018.hq.pyconuk.org/schedule/">
  The PyCon UK Schedule</a>
 , which I've barely looked at.)</p>


<p>
 For some contexts maybe that's OK, but given that a lot of the value in conferences is the hallway track, it's nice to be able to put together heterogenous conferences.
You could fix this by artificially selecting for certain subjects, but proportional representation seems like a much better approach because it doesn't require you to know all the ways in which your audience is heterogenous in advance.
So, in the above example, we would have roughly 60% web dev talks and 40% data science talks,
but also if it turned out that about 10% of the audience were really excited about Flask,
we could have about 10% Flask talks.</p>


<p>
 If the conference is single-track we're more or less done: Pick your favourite (non party-list based, so probably some variant of STV), proportional voting system,
use that to select your talks, and call it a day.</p>


<p>
 I'd like to pause here by saying that I'm increasingly a fan of single track conferences, so I think "do a single track conference and call it a day" might actually be the correct solution.</p>


<p>
 But lets suppose you're less on board with that and want a multi-track conference.</p>


<p>
 For simplicity, lets imagine that our Python conference now has two rooms,
with talks running in the same time slots in each room,
and attendees now have to choose which of the two to attend.
Lets say it's a single day conference and there are five time slots,
so ten talks.</p>


<p>
 According to our above PR argument, we should run six web dev talks,
but does it really make sense for us to do so?
There are only five time slots,
so (by
 <a href="https://en.wikipedia.org/wiki/Pigeonhole_principle">
  the pigeonhole principle</a>
 if you want to get fancy about it) you're inevitably going to put two web dev talks back to back.
That might be OK - maybe you're scheduling a Django and a Flask talk against each other - but maybe there's a strict preference where there are five obviously best web dev talks and the sixth is pretty good (preferable by web devs to any data science talk) but not good enough (will not get any attendees when scheduled against any of the top five talks). What's the point in selecting that talk given that?</p>


<p>
 In the other direction, lets say we have 20% of the audience who are really interested in random forests,
and so we select two random forests talks,
which we then proceed to schedule in the same time slot.
Now despite 20% representation at the talk level,
they only have 10% representation at the time slot level!</p>


<p>
 (I want to draw an analogy to
 <a href="https://en.wikipedia.org/wiki/Gerrymandering">
  gerrymandering</a>
 here but I don't think it quite works)</p>


<p>
 So, tracking creates an upper bound on how much proportional representation is worth doing, and also scheduling within those tracks affects the amount of proportionality you actually get.</p>


<p>
 So what to do about it?</p>


<p>
 Well, I'm not entirely sure. I started designing a whole complex system in support of this that this note was originally supposed to be about, but I decided I didn't like it very much.</p>


<p>
 The basic ideas were:</p>


<ol>
<li>
  Give each participant a "voting currency" - everyone starts with an equal amount, and talk slots effectively get auctioned off, with the proceeds distributed among everyone equally (possibly among everyone who still has any interest in attending remaining talks).</li>
<li>
  Participants will only vote for talks in slots that are strictly better for them than the talks already scheduled in that slot.</li>
<li>
  Define a threshold of "Minimum number of people required to be worth running a talk". Whenever a talk no longer would meet that requirement (because every slot it could be scheduled in has talks people prefer more), it is immediately excluded and the process restarts from the beginning. This is akin to how exclusions work in
  <a href="https://en.wikipedia.org/wiki/Wright_system">
   The Wright System of STV</a>
  , and is designed to avoid "spoiler" talks, where people who preferred them effectively get screened off from voting in the process until the talk is excluded.</li></ol>


<p>
 The details kinda became a weird hybrid of STV and the
 <a href="https://en.wikipedia.org/wiki/Vickrey%E2%80%93Clarke%E2%80%93Groves_mechanism">
  Vickrey-Clarke-Groves mechanism</a>
 and the more I looked at it the less convinced I became that it was the right way to do things or that I actually understood how the VCG mechanism plays out in practice.</p>


<p>
 I do think the above examples are important to consider though.</p>


</section>
<section>
<h2><a href="/posts/2018-09-05-11:08.html">2018-09-05</a></h2>


<p class="subtitle">My parents, Ayn Rand and God</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-05</dd>
</dl>


<p>
<a href="https://twitter.com/bazzalisk/status/1037277763219152897">
  From bazzalisk on Twitter</a>
 :</p>


<blockquote>
<p>
  You know him better than I and You know him better than me are both grammatically valid but mean different things</p></blockquote>


<p>
 The former means "You know him better than I do", the latter means "You know him better than you know me".</p>


<p>
 The title of this note comes from the following probably-apocryphal book dedication,
used as an argument for the oxford comma:</p>


<blockquote>
<p>
  This book is dedicated to my parents, Ayn Rand and God.</p></blockquote>


<p>
 Without the Oxford comma,
the implication is that the author's parents are Ayn Rand and God,
with the Oxford comma, this is a dedication to four people (the author's parents, and also to Ayn Rand and God).
 <a href="http://mentalfloss.com/article/33637/best-shots-fired-oxford-comma-wars">
  Mental Floss has a bunch of similar ones</a>.</p>


<p>
<a href="http://msgboard.snopes.com/cgi-bin/ultimatebb.cgi?ubb=get_topic;f=95;t=000863;p=0">
  Snopes think this probably never happened</a>
 ,
but OTOH the following is part of their argument:</p>


<blockquote>
<p>
  Since Rand was such an outspoken atheist, I find it hard to believe that anyone would mention both her and God as sources of inspiration.</p></blockquote>


<p>
 And, well, this seems to ignore the existence of Paul Ryan and a significant chunk of the US political right.
Also I'm now amused by the idea of Ayn Rand's atheism being a reaction to God being a deadbeat dad.
Someone should write that fanfic, but it's not going to be me.</p>


<p>
 There is of course
 <a href="https://amzn.to/2LYsLcz">
  an entire book about comedic misinterpretations due to bad grammar</a>
 ,
but that's not exactly what's going on here:
Instead these are interesting grammatically valid examples that are right on the edge of ambiguity.</p>


<p>
 It's unclear to me whether this actually tells us anything useful.
We could probably derive some normative advice about correct use of grammar from it,
but this sort of thinking about things in terms of their edge cases is a very modern-mathematician view of the world,
which doesn't come very naturally to others.</p>


<p>
 The general widely deployed solution to linguistic ambiguity is instead that we just guess or ask,
and frankly that probably works better than trying to remove it.</p>


</section>
<section>
<h2><a href="/posts/2018-09-02-21:22.html">2018-09-02</a></h2>


<p class="subtitle">Fiction for Kristian</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-02</dd>
</dl>


<p>
 This is a small collection of fiction I've written that I like enough to actively recommend and think count as "finished".</p>


<h3>
 Fan fiction</h3>


<p>
 The two pieces of Stargate fan fiction that I've written and would recommend are
 <a href="https://archiveofourown.org/works/3673335">
  Stargate Physics 101</a>
 and
 <a href="https://archiveofourown.org/works/5023654">
  Interview with a System Lord</a>.
Both are not only canon-compatible (more or less. Stargate Physics 101 doesn't quite line up with Stargate Universe, but I don't care about Universe),
but are 100% my headcanons of how the universe works.</p>


<p>
 Completion status: 100% finished standalone pieces. I may write other Stargate fan fiction at some point, and if I do then as part of the universe's canon those will naturally be part of its backstory,
but there will never be sequels per se to these pieces.</p>


<p>
 Recommendation strength: Stargate Physics 101 is one of my most popular pieces and works even if you have never watched Stargate. If you like any of infrastructure science fiction, software testing, or stargate, it's worth reading.
Interview with a System Lord is worth reading if and only if you like Stargate SG1 (and especially if you like Ba'al) and want a moderately amusing story exploring a weird headcanon. Warning: May cause mild sympathy for the devil.</p>


<p>
<a href="https://archiveofourown.org/works/4637439/chapters/10575111">
  The Rules of Wishing</a>
 is a piece of fan fiction of Disney's Aladdin.
Premise:</p>


<blockquote>
<p>
  What if people were good at wishing? The Genie's rules have holes you could drive a herd of camels through, but they don't have to. Aladdin and Jafar's wishes are shallow and limited, and lack the foresight that really effective wishing entails, but wouldn't a battle between effective wishers be much more interesting? And while we're at it, why does Jasmine have so little agency and basically act as a prize to be won in a battle between two men when literally the entire point of her narrative is that she's not that?</p></blockquote>


<p>
 It has been argued to be rational!fic though I'm not sure I agree with the classification.
Jasmine in this is probably my joint favourite character I've ever written.</p>


<p>
 Completion status: Has a mini non-canon sequel
 <a href="https://archiveofourown.org/works/13523703">
  The Consequences of Wishing</a>
 that explains the divergence between this story and the film.
May, but probably won't, spawn another sequel, but the current ending wraps it up entirely to my satisfaction and any sequel would be a new story in the same universe with the same characters rather than a continuation of this story.</p>


<p>
 Trigger warning: Moderately violent.</p>


<p>
 Recommendation strength: Honestly, you should read this if you like my fiction at all and are not put off by the trigger warning.</p>


<p>
<a href="https://archiveofourown.org/works/13354146">
  Counterparts</a>
 is a crossover fic between Lucifer (the TV show) and Old Harry's Game (the radio show).</p>


<p>
 Completion status: Very standalone. It's not impossible I may do a followup involving The Good Place, but it stands on its own regardless of whether I do.</p>


<p>
 Recommendation strength: Well it amuses
 <em>
  me</em>. Based on feedback, if you like Lucifer it will probably also amuse you. Familiarity with the Old Harry's Game is helpful but not strictly required.</p>


<h3>
 Original Fiction</h3>


<p>
<a href="https://archiveofourown.org/works/9233966/chapters/20941043">
  Programmer at Large</a>
 is a story about gender, social anxiety, and legacy code.
It seems to have a lot of fans.</p>


<p>
 Completion status: Abandoned, but it kinda works that way. It's a series of slice of life chapters, and the protagonist's life is never really "finished". However it definitely has some unsatisfying dangling plot threads that will never be resolved. However most of the strength of this story is at the chapter level anyway - it has some of my best writing in it, but as a whole story I do not feel that it works. I intend at some point to take it apart and refactor and modularise it into several smaller stories. I am fully aware of the irony of saying this about a story about legacy code.</p>


<p>
 Recommendation strength: Mixed. There's some stuff in there I really like, and a lot of people seem to love it, but like I said I don't feel that it hangs together in its current incarnation.</p>


<p>
<a href="https://archiveofourown.org/series/754683">
  The Diaries of Vicky Frankenstein</a>
 more normally AKA "The Vicky Stories". Series of short stories about Dr Vicky Frankenstein and her adventures in joining a biotech startup run by the vampire Ada Lovelace.</p>


<p>
 Completion Status: (Hopefully permanently) incomplete in the sense that I fully intend to keep writing Vicky stories (but don't more than about one every six months), but each Vicky story is a complete standalone short story that happens to be set in the same world and use the same characters. There are minimal to no dangling plot threads between the stories.</p>


<p>
 Recommendation Status: I  writing Vicky and think you should read these. Also, contains a (99% SFW) lesbian sex scene between two amoral monsters that reviewers describe as "ridiculously adorable", so there's that.</p>


</section>
<section>
<h2><a href="/posts/2018-09-02-13:13.html">2018-09-02</a></h2>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-02</dd>
</dl>


<p>
 Compare and contrast two interesting links:</p>


<ul>
<li>
  Siderea's
  <a href="https://siderea.livejournal.com/1230660.html">
   The Asshole Filter</a></li>
<li>
  Cormac Herley's
  <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/WhyFromNigeria.pdf">
   Why do Nigerian Scammers Say They are from Nigeria?</a></li>
<li>
  Karl Popper's "The Paradox of Tolerance"</li></ul>


<p>
 (Note that I've not read the latter two and should. I've only read digested versions of them).</p>


<p>
 In general often the right way to judge an action is not actually on its immediate effects,
but on what long-run effect they will have on the sort of people you will surround yourself with.
This can make seemingly good actions harmful and seemingly bad or nonsensical ones quite useful.</p>


<p>
 I think about this a bunch in the context of codes of conduct:
Often the benefit of the code of conduct is not whether it is ever enforced,
but that it filters out people who don't like codes of conduct.</p>


</section>
<section>
<h2><a href="/posts/2018-09-01-17:41.html">2018-09-01</a></h2>


<p class="subtitle">Notation for test-case reducers</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-01</dd>
</dl>


<p>
 A thing I've been noticing recently is that it's really useful to have compact notation for describing things.
Usually this is equivalent to primivitives + some combinators.</p>


<p>
 One thing that I think it would be useful to have such a notation for is (greedy) test-case reduction passes.
They combine pretty well, and it makes it useful to discuss various things.</p>


<p>
 For example, if you have reducers \(A\), \(B\), you can define the reducer \(AB\) which runs \(A\), then
runs \(B\) on its result. You can also define the reducer \(A^+\) which runs \(A\) to a fixed point.</p>


<p>
 Another interesting combinator is \(/\). \(A / B\) runs \(A\), then runs \(B\) if \(A\) didn't do anything..</p>


<p>
 There are a bunch of really basic algebraic relations that hold, like composition and \(/\) are associative,
and \((A^+)^+ = A^+\), but not a huge amount beyond that.</p>


<p>
 A bunch of interesting questions about test-case reduction can be compactly expressed in this notation though.
For example, suppose you want to reduce to something that is a fixed point of both \(A\) and \(B\).
You could do \((AB)^+\), but you could also do \((A^+B^+)^+\), and it's quite natural to do this in some contexts.
My suspicion, which I've yet to verify, is that it's almost never the right thing to do.</p>


<p>
 You can kinda regard the quadratic mode failure of greedy search as an instance of this problem:
If \(\delta_i\) is the operation that deletes the element at position \(i\), the correct pass to run for greedy deletion is \((\delta_0^+ \ldots \delta_n^+)^+\),
but if you start again at the beginning every time you succeed you are running \((\delta_0 / \ldots / \delta_n)^+\).</p>


</section>
<section>
<h2><a href="/posts/2018-09-01-16:08.html">2018-09-01</a></h2>


<p class="subtitle">Modes of writing</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-01</dd>
</dl>


<p>
 Two posts on writing to contrast:</p>


<ul>
<li>
<a href="https://blog.malignat.us/2018-05-12/on-the-creative-merits-of-paper">
   On the creative merits of paper</a></li>
<li>
<a href="http://devonzuegel.com/post/comparison-of-text-editing-methods">
   Comparison of text editing methods</a></li></ul>


<p>
 Devon posted the second on twitter and it reminded me of the first, which I struggled to refind, which is part of why I'm posting it here.</p>


<p>
 I've been finding having a paper journal very useful, but I'm also finding having this new notebook useful in an entirely different way.
The contrast is very interesting.</p>


</section>
<section>
<h2><a href="/posts/2018-09-01-09:17.html">2018-09-01</a></h2>


<p class="subtitle">Can a machine design?</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-09-01</dd>
</dl>


<p>
<a href="http://echo.iat.sfu.ca/library/cross_01_machine_des.pdf">
  Can a machine design?</a>
 by Nigel Cross is an interesting paper about architecture (the real kind!) and its relation to automation.
I found it via Adam Marshall Smith's PhD thesis
 <a href="https://adamsmith.as/papers/mechanizing_exploratory_game_design_book.pdf">
  Mechanizing exploratory game design</a>
 (truthfully via
 <a href="https://twitter.com/maxkreminski/status/964923822766833664">
  this tweet</a>
 about it from Max Kreminski),
which is an excellent thesis on mechanically assisted creativity (I must admit I skimmed the technical content as less relevant to me - I care about the meta more than I care about game design qua game design).</p>


<p>
 Most relevant quote for me:</p>


<blockquote>
<p>
  Despite this apparently
easy pace of interaction, all of the designers reported that they
found the experiments hard work and stressful. They reported that
the main benefit of using the "computer" was increased work
speed, principally by reducing uncertainty (i.e., they relatively
quickly received answers to queries, which they accepted as reliable
information).
I also tried a few variations from my standard experiments. The most interesting was to reverse the normal set of expectations of the functions of the designer and the "computer."
The "computer" was given the job of having to produce a design to the
satisfaction of the observing designer. It immediately was apparent
that, in this situation, there was no stress on the designerin fact, it
became quite funand it was the "computer" that found the experience
to be hard work.</p></blockquote>


<p>
 i.e. it's much more fun to tweak a computer's output than it is to be critiqued by one.
An important observation for people in correctness research I think!</p>


</section>
<section>
<h2><a href="/posts/2018-08-31-09:43.html">2018-08-31</a></h2>


<p class="subtitle">Some free user experience consulting for Google</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-08-31</dd>
</dl>


<p>
 I am not a UX expert. I've worked with people who are, and I'm probably a lot better than my otherwise utter incompetence at front-end work would suggest,
but I'm at best OK.</p>


<p>
 Nevertheless, as a user I get to see a lot of the sharp edge of the problems, and I'm good enough at UX that I think I can see what the shape of the solution is.</p>


<p>
 The product I would like to offer Google some free advice on is the following: Google Maps's driving navigation.</p>


<p>
 On a related note, if you can recommend a good driving navigation app to me (iPhone, sadly), that would be delightful.
It would be especially useful if it were one that understood features of English roads like "has roundabouts" and "is verrah verrah smol" that seem alien to people from the US (although given how much of Google maps is in Zurich,
I'm still surprised by its failure to understand these).</p>


<p>
 Anyway, free UX consulting.
User stories are cool I hear, so here are my two user stories for Google maps:</p>


<blockquote>
<p>
  As a driver, I would like to survive my trip.</p></blockquote>


<p>
 and</p>


<blockquote>
<p>
  As a driver, I would like to be able to drive without a constant sense of paranoia.</p></blockquote>


<p>
 Currently Google Maps fails both of these so hard that I have conjectured that I have somehow triggered a special murder-mode for ex-Googlers,
because honestly if Google Maps treats most drivers like it treats me then either not many people can be using it or I would have expected a better publicised death toll from it.
I am not actually being hyperbolic here (or even parabolic).</p>


<p>
 Google maps reliably does everything in its power to destroy my trust in it, which is not ideal in something that I have to use while driving.</p>


<p>
 As the most basic minimum that would be required to restore my trust, I would like to propose the following feature:</p>


<blockquote>
<p>
  Google maps should never, under any circumstances, exit navigation without an audible confirmation that it has done so.</p></blockquote>


<p>
 There is what is almost certainly a bug in Google maps where sometimes it just goes "lol, I'm done here" and exits navigation without telling me.
This is
 <em>
  functionally indistinguishable</em>
 from the sort of confirmation Google maps uses to tell me to just keep going straight.
As a result, whenever Google maps is silent for an extended period of time, I end up feeling a gnawing sense of paranoia that it's just not telling me what to do and I'm going in completely the wrong direction.</p>


<p>
 Almost all of the time this is not the case and the correct thing to do is to keep going straight (although Google maps's notion of what "keep going straight" is is often very funny and involves amusing interpretations of the word "going straight" that include things like "turning left" - it is not very good at actually knowing where the road markings are, and if the road follows around to the right it will often confuse a left turn with keep going straight. However, I will forgive it data problems, particularly on the weird back country roads I often drive),
but this bug triggers just often enough (last incidence: about an hour ago) that the exceedingly common operation of
 <em>
  driving in a straight line</em>
 fills me with deep unease whenever I use Google maps for navigation.</p>


<p>
 Even if this bug were fixed, the damage is done, and I will never believe Google maps is still running if it is silent.</p>


<p>
 On top of that, I would like to propose the following feature:</p>


<blockquote>
<p>
  Google maps should never be silent for an extended period of time.</p></blockquote>


<p>
 I'll grant that if the last instructions were "Keep going for 500 miles" it doesn't need to give me a mile counter every five minutes,
but if it could tell me every half hour or so "Yup, everything is cool, keep going" that would be great.
In normal operation,
every five minutes sounds about right.</p>


<p>
 The second source of paranoia is that Google maps gives absolutely no feedback as to when you have done something wrong.
I know the whole nagging satnav going "Make a U-Turn. Make a U-Turn. Make a- *urk* (noise as satnav is thrown out window)" has a bad reputation,
but there's a happy medium: When you do something Google maps does not expect,
it should say something along the lines of "You missed a turn, I'm going to try to turn you around" or "You missed a turn, finding a new route".</p>


<p>
 Fun instances where it was very useful to have a second person in the car yesterday:</p>


<ol>
<li>
  When Google maps took me 30 miles up the wrong motorway before eventually turning me around.</li>
<li>
  When Google maps was very upset that I didn't drive through the traffic cones blocking the route it wanted me to take and insistently tried to turn me around for another go.</li></ol>


<p>
 Feedback that I had done the wrong thing would have been very helpful on the first, because I would have spent a lot of time confused without it.
Feedback on the second that it was taking me around for another pass would also have been very helpful. I would have probably ignored its instructions even without Luke to assist me,
but I would have felt much less certain about it.</p>


<p>
 Anyway, those is the main sources of paranoia.
Lets talk about the other moderately important feature:
Not dying and/or killing people.</p>


<p>
 This is a very simple issue:
Google maps literally never gives you enough advance warning.
This is especially true in the following two cases:</p>


<ul>
<li>
  with motorway driving. If you tell me "In one mile, take the exit" when I am doing 70 mph (yes, um, definitely 70 mph, that's the speed limit after all) in the right hand lane of a motorway,
  you are saying "In the next 30 seconds, merge across three lanes of possibly quite busy traffic". This is a style of advice that will literally kill people and, worse, make them miss their turning.</li>
<li>
  with roundaboutes and other turnings where there is a lane you need to be in, I need to know what lane that is
  <em>
   before</em>
  reaching the roundabout. It happens all the time that I either exit a roundabout,
  leave a motorway and Google maps is like "tum ti tum, la la, nothing to see here, oh hey there's a roundabout coming up. Atttt... theeee.... rouuuundabout.... taaaake..... the.... third... exit....".
  Often I am
  <em>
   on the fucking roundabout</em>
  before it tells me what lane I need to be in.</li></ul>


<p>
 Giving this sort of last minute instruction is deeply unsafe,
and needs to stop.</p>


<p>
 On top of that there's all sorts of data problems and things where Google maps just clearly doesn't understand UK roads,
but I don't realistically expect those to be fixed, especially with the UK dooming itself to irrelevance next year and the only Google UK presence being in a city where you already have to embrace paranoia and risk loss of life and limb to drive in anyway, so I won't bother venting about those now.</p>


<p>
 In the meantime, I'm serious about that desire for recommendations of less murdery navigation apps. Please?</p>


</section>
<section>
<h2><a href="/posts/2018-08-31-06:57.html">2018-08-31</a></h2>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-08-31</dd>
</dl>


<p>
 I'm a big fan of the
 <a href="https://en.wikipedia.org/wiki/Brzozowski_derivative">
  Brzozowski derivative</a>
 ,
introduced in "Derivatives of regular expressions" by Janusz A. Brzozowski.</p>


<p>
 The basic idea is that given some language \(L\) over an alphabet \(A\),
and some string \(u\) over \(L\),
you can define the derivative language \(\partial(L, u) = \{v: uv \in L\}\).
We can extend this further (and it will be useful to do so below).
If \(M\) is some other language, we can define \(\partial(L, M) = \{v: \exists u \in M, uv \in L\}\).
I'm not currently sure if the derivative of a regular language by a regular langauge is regular in general. It is in the case we'll see later,
and I suspect it is in general.</p>


<p>
 This seems like a pretty trivial observation until you realise the following three things:</p>


<ol>
<li>
  \(u \in L\) if and only if \(\epsilon \in \partial(L, u)\)</li>
<li>
  \(uv \in L\) if and only if \(v \in \partial(L, u)\)</li>
<li>
  For most common representations of languages, it's actually pretty easy to calculate a representation of their derivative.</li></ol>


<p>
 Putting these together, you can use the Brzozowski derivative to calculate a deterministic (not necessarily finite!) automaton for almost any language that you can easily represent.
You label states with descriptions of languages,
a state is accepting if it matches the empty string,
and transitions to the states labelled by the derivatives.</p>


<p>
<a href="http://www.ccs.neu.edu/home/turon/re-deriv.pdf">
  Regular-expression derivatives reexamined</a>
 by Owens et al. has some nice practical details of doing this in the context of functional programming.</p>


<p>
 To see this in action, consider the standard regular expression operators.
These satisfy the following identifies:</p>


<ol>
<li>
  \(\partial(A | B, u) = \partial(A, u) | \partial(B, u)\)</li>
<li>
  \(\partial(AB, u) = \partial(A, u)B | \nu(A) \partial(B, u)\), where \(\nu(A) = \epsilon\) if \(\epsilon \in A\) or \(\emptyset\) otherwise (i.e. the derivative can skip over \(A\) if and only if \(A\) contains the empty string)</li>
<li>
  \(\partial(A^*, u) = \partial(A, u) A^*\)</li></ol>


<p>
 A result proved in Brzozowski's original paper (apparently. I can't currently seem to access it, and am going off thecite in "Regular-expression derivatives reexamined) is that a small number of reasonable normalisation rules over the representation of the language is enough to ensure that you only get finitely many states in the state machine generated by partial derivatives of regular expressions.
It's certainly true that you only get finitely many if you have full equivalence for the regular languages labelling the states - the derivative automaton is actually the minimal automaton representing a language.</p>


<p>
 There are two very nice things about this representation of the language's automaton though:</p>


<ol>
<li>
  It can be done
  <em>
   lazily</em>. This means that even when your deterministic automaton has exponentially (or infinitely!) many states, you only ever need to explore the states that you walk when matching strings.</li>
<li>
  It is very easy to extend with new operators.</li></ol>


<p>
 An example of (2) is that regular expressions reexamined actually does it for extended regular expressions with intersection and negation, because might as well right? It's no harder than doing it with the normal ones, even though adding these to your regular expression language can cause exponential blowup in the size of the automata compiled from your regex.</p>


<p>
 But there are even more interesting ones if you're prepared to go for more esoteric operations!</p>


<p>
 Have you heard of the
 <a href="https://en.wikipedia.org/wiki/Levenshtein_automaton">
  Levenshtein automaton</a>
 ? The set of strings within some finite edit distance of another string is a regular language and you can define a nice automaton matching it.
But in fact, a stronger result is true: For any regular language \(L\) and natural number \(n\), the set \(E(L, n) = \{u: \exists v \in L, d(u, v) \leq n\}\) is a regular language.
Why?</p>


<p>
 Well, we can calculate its derivative!
The derivative of \(E\) is \(\partial(E(L, n), u) = E(\partial(L, u), n) | E(L, n - 1) | E(\partial(L, \cdot), n - 1) | \partial(E(\partial(L, \cdot), n - 1), u)\).
That is, at each character we can either:</p>


<ol>
<li>
  Continue matching the original language (cost 0).</li>
<li>
  Insert a new character in front of something in the original language (cost 1)</li>
<li>
  Replace a character in the original language with \(u\) (cost 1)</li>
<li>
  Drop a character from the original language and try again (cost 1)</li></ol>


<p>
 In the course of doing this we apply the following rewrite rules:</p>


<ol>
<li>
  \(E(L, 0) = L\)</li>
<li>
  \(E(\emptyset, n) = \emptyset\)</li></ol>


<p>
 As long as the number of reachable representations for the original languages is finite,
so is the number of reachable states in our Levenshtein construction:
Every state is labelled by a set of languages of the form \(E(\partial(L, U), k)\) where \(U\) is a language defined by \(u_1 \ldots u_m\) with each \(u_i\) either a single character or a \(\cdot\),
and \(m + k \leq n\). There are only finitely many such labels as long as there are only finitely many derivatives of \(L\),
although in principle there may be exponentially many.
Because of the laziness of our construction that often won't matter - you can still determine membership for a string of length \(k\) with only \(O(k)\) state traversals (though calculating those states could in principle require up to \(O(nm)\) work, where \(m\) is the number of states in the original automaton).</p>


<p>
 You can also use this to determine the minimum edit distance between two regular languages,
because you can test whether \(E(L, n) \cap L' = \emptyset\) by calculating and walking the generated DFA for the left hand side,
so this gives you a decision procedure for \(d(L, L') \leq n\).</p>


<p>
 Is this a practical algorithm? Not sure. I've played with it a little bit, but I've not really put it to the test,
but I think it's an interesting example of the flexibility of the Brzozowski derivative,
and it was at least mildly surprising to me that the edit ball of a regular language is itself regular.</p>


</section>
<section>
<h2><a href="/posts/2018-08-30-12:39.html">2018-08-30</a></h2>


<p class="subtitle">Mathjax and Python Markdown</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-08-30</dd>
</dl>


<p>
 I've been having an interesting time of things with this notebook and getting Python markdown and Mathjax to play well with each other.
In particular I have not been enjoying the markdown extension API at
 <em>
  all</em>.</p>


<p>
 Anyway, it turns out that it is easy to do what I need, just slightly undocumented and with some annoyingly silent failure modes.</p>


<p>
 Here is the (slightly simplified) code from this notebook that makes MathJax work correctly:</p>


<div class="codehilite">
<pre><span></span><span class="kn">from</span> <span class="nn">markdown.inlinepatterns</span> <span class="kn">import</span> <span class="n">HtmlPattern</span>

<span class="n">LATEX_BLOCK</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">"(</span><span class="se">\\</span><span class="s2">begin{[^}]+}.+?</span><span class="se">\\</span><span class="s2">end{[^}]+})"</span>
<span class="n">LATEX_EXPR</span>  <span class="o">=</span> <span class="sa">r</span><span class="s2">"(</span><span class="se">\\</span><span class="s2">\(.+?</span><span class="se">\\</span><span class="s2">\))"</span>


<span class="k">class</span> <span class="nc">MathJaxAlignExtension</span><span class="p">(</span><span class="n">markdown</span><span class="o">.</span><span class="n">Extension</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">extendMarkdown</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">md</span><span class="p">,</span> <span class="n">md_globals</span><span class="p">):</span>
        <span class="c1"># Needs to come before escape so that markdown doesn't break use of \ in LaTeX</span>
        <span class="n">md</span><span class="o">.</span><span class="n">inlinePatterns</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s1">'mathjaxblocks'</span><span class="p">,</span> <span class="n">HtmlPattern</span><span class="p">(</span><span class="n">LATEX_BLOCK</span><span class="p">,</span> <span class="n">md</span><span class="p">),</span> <span class="s1">'&lt;escape'</span><span class="p">)</span>
        <span class="n">md</span><span class="o">.</span><span class="n">inlinePatterns</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s1">'mathjaxexprs'</span><span class="p">,</span> <span class="n">HtmlPattern</span><span class="p">(</span><span class="n">LATEX_EXPR</span><span class="p">,</span> <span class="n">md</span><span class="p">),</span> <span class="s1">'&lt;escape'</span><span class="p">)</span></pre></div>


<p>
 The HtmlPattern class takes an expression and treats anything matching that expression as something that the markdown processor should not touch further.</p>


<p>
 Some caveats to note:</p>


<ul>
<li>
  Those brackets around the expression? Those are
  <em>
   important</em>. The way that the regular expression processing works is that it messes with your regex a bit, and then uses capturing group \(2\) as the output (\(1\) will be everything in the current block prior to the start of your regex). This means that if you must use groups in your regex, make them named groups.</li>
<li>
  For reasons I haven't fully understood and have chosen not to bother understanding because the current behaviour is correct for my needs, despite allegedly being an HTML block, this extension does seem to do entity escaping on the contents of your MathJax.</li></ul>


</section>
<section>
<h2><a href="/posts/2018-08-30-07:50.html">2018-08-30</a></h2>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-08-30</dd>
</dl>


<p>
 I'm going to start trying to port over some contents from
 <a href="https://github.com/DRMacIver/research-notebook">
  my research notebook</a>
 into here,
as this is intended long-term to be a replacement for it.
This will require some figuring out in terms of how to present maths.</p>


<p>
 As a starting point,
here's a theorem:</p>


<p>
 \(H(m) = \sum\limits_{q = 1}^m {(-1)}^{q - 1} {m \choose q} \frac{1}{q}\)</p>


<p>
 Where \(H(m)\) is the m'th harmonic number \(H(m) = \sum\limits_{i}^m \frac{1}{i}\).</p>


<p>
 This came up in "Birthday Paradox, Coupon Collectors, Caching Algorithms and Self-Organizing Search" by Flajolet et al. (which is excellent) where it was stated as "well known". It wasn't well known to
 <em>
  me</em>
 ,
so I set out to prove it.</p>


<p>
 The following is my proof:</p>


<p>
 The main idea is to use a standard tricks of turning sums and integrals into other sums and integrals that happen to be easier to solve.
We use the following standard results:</p>


<ul>
<li>
  \(\frac{1}{n} = \int\limits_0^1 x^{n - 1}dx\)</li>
<li>
  \((1 + x)^m = \sum\limits_{q=1}^m {m \choose q} x^q\)</li>
<li>
  \((1 - x)^{-1} = \sum\limits_{q = 0}^\infty x^q\) for \(|x| &lt; 1\).</li></ul>


<p>
 We then perform the following manipulations (don't worry if some of these are clear as mud. They kinda should be):</p>


<p>
 \begin{align}
\sum\limits_{q = 1}^m {(-1)}^{q - 1} {m \choose q} \frac{1}{q} &amp;= \sum\limits_{q = 1}^m {(-1)}^{q - 1} {m \choose q} \int\limits_0^1 x^{q - 1} dx\\
&amp;= \int\limits_0^1 \sum\limits_{q = 1}^m {(-1)}^{q - 1} {m \choose q} x^{q - 1} dx\\
&amp;= \int\limits_0^1 -x^{-1} \sum\limits_{q = 1}^m {m \choose q} {(-x)}^q dx\\
&amp;= \int\limits_0^1 -x^{-1} \left( \sum\limits_{q = 0}^m {m \choose q} {(-x)}^q - 1 \right)dx \\
&amp;= \int\limits_0^1 -x^{-1} \left( {(1 - x)}^m - 1 \right)dx \\
&amp;= \int\limits_0^1 {(1 - x)}^{-1} (x^m - 1) dx \\
&amp;= \int\limits_0^1 \sum\limits_{n = 0}^\infty x^n (x^m - 1) dx \\
&amp;= \sum\limits_{n = 0}^\infty \int\limits_0^1 x^n (x^m - 1) \\
&amp;= \sum\limits_{n = 0}^\infty \frac{1}{n + m} - \frac{1}{n} \\
&amp;= \lim\limits_{k \to \infty}  H(m) - \sum\limits_{n = k}^{m + k} \frac{1}{n + m}\\
&amp;= H(m)\\
\end{align}</p>


<p>
 Notable magic tricks performed:</p>


<ul>
<li>
  \(\int\limits_0^1 -x^{-1} \left( {(1 - x)}^m - 1 \right)dx  \to \int\limits_0^1 {(1 - x)}^{-1} (x^m - 1) dx \) is a change of variables \(x \to 1 - x\).</li>
<li>
  \(\sum\limits_{n = 0}^\infty \frac{1}{n + m} - \frac{1}{n} \to \lim\limits_{k \to \infty}  H(m) - \sum\limits_{n = k}^{m + k} \frac{1}{n + m}\) is because you can use a change of variables \(k \to k - m\),
and then group the terms that cancel out.</li>
<li>
  The final limit is because \(|\sum\limits_{n = k}^{m + k} \frac{1}{n + m}| \leq \frac{m}{k}\).</li></ul>


<p>
 This is a style of calculation I think of as the Feynmann style because
 <del>
  it's very good at seeming more clever than it actually is</del>
 he was fond of smugly boasting about using this sort of trick in preference to contour integration.
Given its prevalence prior to Feynmann, my only defence of the terminology is that it's not really intended as a compliment.</p>


<p>
 I find the Feynmann style completely unenlightening to read - the only way to read a Feynmann style proof is to do it yourself, using the original as a guide when you get stuck.</p>


<p>
 I think that's in some ways its point. It's not a proof technique designed to leverage enlightenment,
but instead it leans heavily on your puzzle solving skills. That can be useful sometimes when you just want to brute force your way through a problem and don't really care about understanding it on any sort of deeper level.</p>


<p>
 I was exposed to the Feynmann style quite early on,
due to reading Schaum's Outlines of Advanced Calculus (an earlier edition. I'm not sure how early. Brown covered one. I sadly gave away my copy, and the 1974 edition one I ordered doesn't seem to be quite it) prior to going to university.
It has quite a lot of exercises using calculations like this,
and afterwards I realised that this is what Feynmann had been talking about in "Surely you're joking, Mr Feynmann" (I didn't understand what a contour integral was until a few years later).</p>


<p>
 Somehow despite this the Feynmann style of brute force problem solving never really integrated into my mathematics,
and it's only some years later I've come to appreciate its merits.
I
 <em>
  still</em>
 prefer to achieve insight and make the problem trivial,
but sometimes the problem isn't worth the insight and you're better off just putting in the hard work and solving it.</p>


<p>
 Putting in the hard work is also useful because sometimes it leads you to the insight you missed and you can throw away most of the work.
This didn't happen here,
but I think that's OK - it's not that interesting a problem,
so I don't really feel upset by the lack of insight into it.</p>


</section>
<section>
<h2><a href="/posts/2018-08-29-09:35.html">2018-08-29</a></h2>


<p class="subtitle">Notes on tiling with polyominoes</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-08-29</dd>
</dl>


<p>
 Gary Fredericks wrote about
 <a href="https://gfredericks.com/gfrlog/99">
  a backtracking algorithm for tiling a board with polyominoes</a>.</p>


<p>
 His solution is roughly "turn the problem into exact cover and then apply a bunch of interesting optimisations in this context to the naive backtracking algorithm".
The paper
 <a href="https://arxiv.org/pdf/cs/0011047.pdf">
  Dancing Links</a>
 by Donald E. Knuth in fact studies this exact problem as an application of the exact cover algorithm.</p>


<p>
 I think some of the optimisations Gary performs are not ones that would be performed by a modern SAT solver because they are actually too expensive to be worth it if you're good at the SAT problem-e.g.
I know modern SAT solvers tend not to bother decomposing problems into independent problems because the cost is too high-but
it's possible they synergise well enough to be worth it. e.g. the number theory optimisation combined with the independent components may well be worth it,
especially with the heuristic of prioritising moves that disconnect the board.</p>


<p>
 I've been doing a bit of casual reading about this class of problem recently.
I thought I'd use the opportunity of this new notebook to collect some references.
Ideally these would be proper cites,
but I haven't got the citation part of the notebook system working yet.</p>


<p>
<a href="https://www.jstor.org/stable/pdf/2307321.pdf">
  Checker Boards and Polyominoes</a>
 by Solomon W. Golomb is a classic here.
It looks at the question of tiling the chessboard with a single square monomino and 11 tetrominos of various shapes.
In particular it establishes:</p>


<ul>
<li>
  You can do this with right tetrominoes given any placement of the monomino</li>
<li>
  There are only four squares where you can place the monomino if you want to do it with straight tetrominoes.</li></ul>


<p>
<a href="http://chalkdustmagazine.com/blog/polyominoes/">
  How to Tile a Chessboard</a>
 by Trupti Patel is a nice expository piece on this.</p>


<p>
 Golomb also wrote
 <a href="http://publisher-connector.core.ac.uk/resourcesync/data/elsevier/pdf/03f/aHR0cDovL2FwaS5lbHNldmllci5jb20vY29udGVudC9hcnRpY2xlL3BpaS9zMDAyMTk4MDA2NjgwMDMzOQ%3D%3D.pdf">
  Tiling with Polyominoes</a>
 ,
studying much more general questions of how to tile truncated chessboards with polyominoes.</p>


<p>
 A classic version of this is what
 <a href="https://en.wikipedia.org/wiki/Mutilated_chessboard_problem">
  Wikipedia refers to as the mutilated chessboard problem</a>
 (apparently following Max Black):</p>


<blockquote>
<p>
  Suppose a standard 88 chessboard has two diagonally opposite corners removed, leaving 62 squares. Is it possible to place 31 dominoes of size 21 so as to cover all of these squares?</p></blockquote>


<p>
 The answer is no. In
 <a href="https://www.tandfonline.com/doi/pdf/10.1080/07468342.2004.11922062">
  Tiling with Dominoes</a>
 , N. S. Mendelsohn discusses two proofs:</p>


<blockquote>
<h3>
  First solution</h3>
<p>
  From the checkerboard diagram, the region contains 30 black cells and 32 white cells.
Since each domino covers 1 black and 1 white cell, tiling is impossible.</p>
<h3>
  Second solution</h3>
<p>
  When I was first shown the problem many years ago, it did not occur to me to colour
the cells. The region itself had seven cells in the top and bottom rows and eight cells in
the remaining rows. The same held for the columns. I proceeded to obtain information
on how many dominoes pointed horizontally and how many vertically. The first count
dealt with the vertical dominoes. If the region is tiled, the horizontal dominoes in the
top row occupies an even number of cells. Hence, the cells in the top row that are not
occupied by horizontal dominoes are odd in number. Thus there are an odd number of
vertical dominoes between the first and second rows. Since the second row has eight
cells, and an odd number are occupied by vertical dominoes coming down from the
first row, there remain an odd number of cells in the second row. The same argument
now shows there is an odd number of vertical dominoes from the second row to the
third. Continuing this way, we see that there is an odd number of vertical dominoes
between any pair of consecutive rows. Hence the total number of vertical dominoes is
the sum of seven odd numbers, which is odd. In the same way, using columns instead
of rows, there is an odd number of horizontal dominoes. Hence the total number of
dominoes is even. Since there are 62 cells to cover, the number of dominoes required
is 31, an odd number. Therefore, tiling is impossible.</p></blockquote>


<p>
 He goes on to say:</p>


<blockquote>
<p>
  Why do I produce two solutions to the puzzle? It is because I am interested in
the question of which is the better solution. At first glance, it appears that the first
solution is the better. It is much shorter and is easily understood by many people with
virtually no knowledge of mathematics. But are there considerations that might judge
the second solution to be the better one?</p></blockquote>


<p>
 He then discusses whether the second one is better because it generalises better,
when setting out to prove Gomory's theorem (which I've not been able to find a copy of the original of so far, but I haven't looked very hard):
If you remove two squares of the same colour, you can always tiling the remainder with dominoes.
The proof involves the construction of a hamiltonian circuit on the adjacency graph,
and seems fiddly but interesting.
I've only skimmed it and would like to digest it further.</p>


<p>
 However note that we saw a generalisation in a different direction in the first paper linked! Golomb's proof of the impossibility tiling with straight tetrominoes unless the monomino was in a very specific location was
 <em>
  also</em>
 a colouring argument.</p>


<p>
 The wikipedia page references "Across the board: the mathematics of chessboard problems" by John J. Watkins.
I should probably look up a copy.</p>


</section>
<section>
<h2><a href="/posts/2018-08-28-08:14.html">2018-08-28</a></h2>


<p class="subtitle">First!</p>


<dl class="metadata">
<dt>Published</dt>
<dd class="post-date">2018-08-28</dd>
</dl>


<p>
 This is an experimental new blog intended for notes, thoughts, and whatever else I want to put here.
It will likely be biased towards short notes rather than longform essays.
It's loosely inspired by
 <a href="https://shitpost.plover.com/">
  Mark Jason Dominus's shitposting blog</a>
 and by my frustrations with WordPress, but I'm not really sure where it's going yet.</p>


<p>
 It's also a place where I'll be experimenting with notation,
and generally trying to find a low friction way to express myself in a manner that I like.
As such it's all a bit cobbled together out of spit, bailing wire, and Python.</p>


<h3>
 Notational Highlights</h3>


<p>
 I kinda hate LaTeX, but it's the best typesetting language for mathematics that I know of,
so this notebook supports it using
 <a href="https://www.mathjax.org/">
  mathjax</a>.</p>


<p>
 Testing: \(e^{i\pi} = -1\)</p>


<p>
 A test of code highlighting.</p>


<div class="codehilite">
<pre><span></span><span class="k">class</span> <span class="nc">SomeClass</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">""""A python class"""</span>

    <span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">"""A method definition"""</span></pre></div>


<p>
 As you've probably noticed, I'm using
 <a href="https://edwardtufte.github.io/tufte-css/">
  Tufte CSS</a>.
I'm not sure it's exactly what I want, but it's a lot closer to what I want than most other things I've tried.
I will likely be messing aroudn with this further.</p>


<p>
 I'm also using
 <a href="http://www.makotemplates.org">
  mako templates</a>
 ,
and fully intend to define a metric tonne of macros to make this usable.</p>


<p>
 In general I expect the actual source code for this site to be totally unusable to anyone who is not me.
If anything,
if it's
 <em>
  not</em>
 then I probably haven't done enough customization for my brain.</p>


</section>

    </article>
<footer>
Copyright David R. MacIver.

CSS mostly due to <a href="https://edwardtufte.github.io/tufte-css/">Tufte CSS</a> by Dave Liepmann.
</footer>
  </body>
</html>
