<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
  <id>https://notebook.drmaciver.com/</id>
  <title>DRMacIver's notebook</title>
  <updated>2020-07-08T14:56:00+01:00</updated>
  <author>
    <name>David R. MacIver</name>
    <email>david@drmaciver.com</email>
  </author>
  <link href="https://notebook.drmaciver.com" rel="alternate"/>
  <link href="https://notebook.drmaciver.com/feed.xml" rel="self"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="0.9.0">python-feedgen</generator>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2020-06-27-11:07.html</id>
    <title>Ideas Get You Unstuck</title>
    <updated>2020-06-27T12:28:23+01:00</updated>
    <content type="html">

&lt;p class="subtitle"&gt;Ideas Get You Unstuck&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2020-06-27&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;From &lt;a href="https://amzn.to/3d13X1P"&gt;the wave in the mind&lt;/a&gt; by Ursula K. Le Guin, page 279:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;I started the book five times, it got nowhere. I had to stop.&lt;/p&gt;
&lt;p&gt;I had to sit patiently and say nothing, at the same time every day, while the fox looked at me from the corner of its eye, and slowly let me get a little bit closer.&lt;/p&gt;
&lt;/blockquote&gt;


&lt;p&gt;On the next page, 280:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;Critics talk as if stories were all idea, but intellect does not make story and more than ideology makes art. The story had to make itself, find its center, find its voice, Sutty's voice. Then, because I was waiting for it, it could give itself to me.&lt;/p&gt;
&lt;/blockquote&gt;


&lt;p&gt;Le Guin is talking about the process of story formation, and how it comes through an accretion of pieces that cause it to fit together. However I find it strange that she uses the fact that she had to sit and wait for Sutty's voice as evidence that a story is &lt;em&gt;not&lt;/em&gt; just composed about ideas, because Sutty's voice is, itself, an idea, and it came to her as most ideas inevitably do - at first slowly, and then suddenly.&lt;/p&gt;


&lt;p&gt;She's right of course that a story is not just composed of ideas. As with basically everything, a story is mostly composed of work, and skill in doing that work. Ideas serve the purpose they serve everywhere: They're there to get you unstuck.&lt;/p&gt;


&lt;p&gt;Generally, if you're not currently stuck, you need to either do the work. If you're not good enough to do the work, you need to learn to be better at it (you can, of course, then get stuck in the learning process). That's where an idea helps you out: It &lt;a href="https://notebook.drmaciver.com/posts/2020-02-26-16:07.html"&gt;gives you something to try&lt;/a&gt;. An idea is a thought that points to a way to improve the situation.&lt;/p&gt;


&lt;p&gt;The two main ways of getting stuck are:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;You don't know what to do.&lt;/li&gt;
&lt;li&gt;You know what to do but you don't know how to do it.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;I think Le Guin is only using "idea" to refer to things that solve the first kind of getting stuck, but they're if anything more important for the second type. Ideas of the first kind are cheap: There are a million things to do at any moment, ideas about what to do are cheap, and if you're struggling to figure those out it's probably an emotional problem (e.g. "everything feels pointless and I hate myself" or "I'm not good enough to do any of these") rather than actual difficulty generating ideas.&lt;/p&gt;


&lt;p&gt;The second version though is still idea generation, but it's idea generation on hard mode, because you can't just pick an idea and see where it leads the ideas you generate actually have to have a decent chance of working, for some very specific notion of work. These are the times that force you to actually develop the skill of idea generation,
and the first part of that skill is that process that Le Guin describes of &lt;a href="https://mathwithbaddrawings.com/2017/09/20/the-state-of-being-stuck/"&gt;getting stuck and sitting with it&lt;/a&gt;.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2020-06-27-11:07.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2020-06-28-15:58.html</id>
    <title>I'm not actually that curious</title>
    <updated>2020-06-28T17:46:46+01:00</updated>
    <content type="html">

&lt;p class="subtitle"&gt;I'm not actually that curious&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2020-06-28&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;Small personal note, but I've noticed a number of people have a particular misconception of me,
and thought I'd clear it up.&lt;/p&gt;


&lt;p&gt;You know how I read insatiably, driven by pure curiosity, and know a huge amount of different things just because I wanted to know them?&lt;/p&gt;


&lt;p&gt;Yeah, I don't do that.&lt;/p&gt;


&lt;p&gt;At least, I don't do that often. It's a thing I do &lt;em&gt;sometimes&lt;/em&gt;, but an idle scan of my bookshelves suggests that no more than about one book in twenty is something I've read out of pure interest. Generally speaking if I'm reading something nonfiction it's because I expect it will actually improve my life in some material way.&lt;/p&gt;


&lt;p&gt;I'd like this to not be the case: It would be wonderful if I could just read things because I thought they were interesting, but I actually find it very difficult to be interested in knowledge that I can't use in some way to solve practical problems. I suspect that will improve as the ongoing project to improve my emotional landscape progresses, but I'm very much not there yet.&lt;/p&gt;


&lt;p&gt;Don't get me wrong, a lot of the books I read are super interesting in their own right, and I do appreciate that aspect of them. I also don't do well at reading boring books. But I don't &lt;em&gt;select&lt;/em&gt; books because they're interesting, I select books because they'll help me with something. The emotion that most commonly drives me to read a book isn't curiosity, it's distress: Something is bad, and my stress response is to understand more about the subject matter so I can make it better, so I read a book about it.&lt;/p&gt;


&lt;p&gt;It's not &lt;em&gt;always&lt;/em&gt; distress. Sometimes it's because I'm annoyed that something doesn't make sense. Sometimes it's a simple desire for improvement, or some really concrete problem to solve. Sometimes it's just a general background faith that even if I don't have a specific problem I'm trying to solve then the book will be good for &lt;em&gt;something&lt;/em&gt;.&lt;/p&gt;


&lt;p&gt;This might seem odd given my reading material ("David, what are you reading?" "I'm reading a Christian theology book about how giving yourself over to Christ will solve capitalism." "Of course you are.") but what you have to bear in mind is that I am a deeply unreasonable person with a very idiosyncratic approach to knowledge.&lt;/p&gt;


&lt;p&gt;If you read my &lt;a href="https://notebook.drmaciver.com/posts/2020-05-09-11:26.html"&gt;notes towards a manifesto&lt;/a&gt;, a lot of what I'm working on is "general humaning skills". What field do you need to read in in order to figure out how to do humaning better? Basically all of them I'm afraid.&lt;/p&gt;


&lt;p&gt;When I say &lt;a href="https://notebook.drmaciver.com/posts/2020-02-24-10:37.html"&gt;All knowledge is connected&lt;/a&gt; I think most people nod sagely and agree that this is true in principle, and you do get people reading out their field a bit (e.g. Software developers reading architecture books is a thing, though mostly because books about software development are mostly terrible, and every field has a subculture of people telling you that you need to read &lt;a href="https://twitter.com/DRMacIver/status/1270346474027712513"&gt;Zen and the Art of Motorcycle Maintenance&lt;/a&gt; to truly understand it). But I don't think, by and large, people fully embrace it as a praxis, mostly because it's really hard and time consuming.&lt;/p&gt;


&lt;p&gt;I have three advantages here:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;I take the idea seriously and am willing to put in the work.&lt;/li&gt;
&lt;li&gt;I don't find it that hard. I'm good at reading books, I'm good at connecting up knowledge, and I generally prefer hitting practical problems with huge theory hammers.&lt;/li&gt;
&lt;li&gt;I have a relatively large amount of time to devote to the problem, especially &lt;a href="https://drmaciver.substack.com/p/why-am-i-not-working-on-my-phd"&gt;on days when I'm failing to work on my PhD&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;The result is that yes I just really &lt;em&gt;am&lt;/em&gt; the sort of person who goes "Community drama seems like a really hard problem. Why don't I read &lt;a href="https://notebook.drmaciver.com/posts/2019-05-09-15:33.html"&gt;a text on Talmudic law&lt;/a&gt; so I can understand it better?" and have a project to learn phenomenology so I can improve my own subjective emotional experience.&lt;/p&gt;


&lt;p&gt;Does this work?&lt;/p&gt;


&lt;p&gt;Honestly, yes. I cannot say that I recommend it to everyone, or even to most people, but I've found it extraordinarily helpful. It's not sufficient in its own right, but I've been taking this seriously for a few years and really kicked it into high gear this year with the addition of the writing practice to properly integrate this knowledge, and I've seen huge improvements in my life enabled by it.&lt;/p&gt;


&lt;p&gt;I expect I'll keep reading like this for at least another couple of years - with any luck I'll gradually include a higher fraction of pure interest reading as time goes on, but I doubt I'm at any risk of solving all my problems any time soon.&lt;/p&gt;


&lt;p&gt;I can't read everything relevant to my problems of course. I'm not trying to. What I'm trying to do is cultivate a &lt;a href="https://notebook.drmaciver.com/posts/2020-04-13-11:35.html"&gt;domus&lt;/a&gt; that gives me a sufficient wealth of &lt;a href="https://notebook.drmaciver.com/posts/2020-06-27-11:07.html"&gt;ideas to get me unstuck&lt;/a&gt; on making progress with the problems I have.&lt;/p&gt;


&lt;p&gt;(A domus is a concept I got from reading about the early history of civilisation and the role of grain cultivation - James C. Scott is an author I tend to just read because I assume I'll get something useful out of it even if I don't know what going in. Haven't been wrong yet)&lt;/p&gt;


&lt;p&gt;When I encounter a limitation, I read new material to overcome it. Because the category of problems I am trying to solve is, in the limit, &lt;em&gt;all of human endeavour&lt;/em&gt;, there's no shortage of limitations. The result is a constant switching around of what I'm working on based on what I can currently make progress on, and reading whatever seems most currently accessible and relevant to the bits I'm actively stuck on. This tends to cause me to bounce around a lot between different fields, because once I've read a book (or a couple books sometimes) about a subject I need a while to let it bed in and try applying it and integrating it before I'm ready to read more in that area.&lt;/p&gt;


&lt;p&gt;From the outside this process &lt;em&gt;does&lt;/em&gt; looks a lot like curiosity, but as a David expert I'm here to tell you that this isn't cute, and Davids only behave this way when they're under stress.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2020-06-28-15:58.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2020-06-30-17:03.html</id>
    <title>Free and Open Source Social Technology</title>
    <updated>2020-06-30T18:39:22+01:00</updated>
    <content type="html">

&lt;p class="subtitle"&gt;Free and Open Source Social Technology&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2020-06-30&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;From &lt;a href="https://amzn.to/36FzofT"&gt;Where Good Ideas Come From&lt;/a&gt; by Steven Johnson, page 242:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;As Lawrence Lessig has so persuasively argued over the years, there is nothing "natural" about the artificial scarcity of intellectual property law. [...] Ideas are intrinsically copyable in the way that food and fuel are not. You have to build dams to keep ideas from flowing.&lt;/p&gt;
&lt;/blockquote&gt;


&lt;p&gt;This is in the context of Johnson talking about what he calls the &lt;em&gt;fourth quadrant&lt;/em&gt; - ideas generated by networks of people operating outside of market incentives. The fourth quadrant is in fact a great source of innovation, and a large part of that is this relative lack of intellectual property dams. If someone comes up with a great idea and isn't interested in making money off it, they're usually delighted if you copy them. Good etiquette requires that you &lt;em&gt;credit&lt;/em&gt; them, and ideally (in the spirit of open source) if you make any improvements to the idea you pay it back by telling them or others about it, so as long as everyone behaves like a vaguely good citizen sharing ideas that you don't intend to monetize is a net positive for everyone.&lt;/p&gt;


&lt;p&gt;One difficulty is when ideas escape the network and into the market - if you share your idea and someone goes "that's a great idea, I'm going to make money off it", that's less good. Firstly, you feel exploited (in many cases this will be literally &lt;a href="https://www.currentaffairs.org/2017/09/the-question-of-cultural-appropriation"&gt;cultural exploitation&lt;/a&gt;) and secondly now there's an entity who likely has more money (and thus power) than you who is liable to claim ownership of the idea and/or make demands of you, and because you gave the idea away for free you have little leverage.&lt;/p&gt;


&lt;p&gt;If I sound bitter, this is of course because we run into this problem in FOSS a lot.&lt;/p&gt;


&lt;p&gt;But there's a nice example where this doesn't really come up that much, which is &lt;a href="https://www.drmaciver.com/2019/08/the-missing-social-technology-sector/"&gt;social technology&lt;/a&gt;. You do get people "selling" social technology through writing books and doing consulting or training courses, but even there it tends to be pretty much part of the network rather than the market, with members of the network also making money off it.&lt;/p&gt;


&lt;p&gt;A lot more people are developing social technology, and more general technologies in the form of &lt;a href="https://notebook.drmaciver.com/posts/2020-05-09-11:26.html"&gt;the techniques of being human&lt;/a&gt;. In the last year or so I've been hanging out with the group who I tend to refer to as "feelings Twitter" - a very loosely aligned group of people who basically do a lot of weird therapy and talk about their feelings and the tools they've used to explore them. This is very much an example of fourth quadrant innovation, with people mixing and matching, generating new techniques, boosting ideas that have worked well for them.&lt;/p&gt;


&lt;p&gt;So far this all seems to work out pretty well, and I think a large part of that is that even though you can make money off this sort of thing very few of us are trying to do so (I suppose I kinda am trying to make money off it, in that the newsletter is paid, but I'm pretty far from being there). Being better humans is &lt;a href="https://drmaciver.substack.com/p/what-do-you-do"&gt;our work but not our job&lt;/a&gt;.&lt;/p&gt;


&lt;p&gt;At the moment I don't see much risk of us falling into the FOSS trap of having to support companies who are using our stuff for free (providing free therapy in your DMs is a lot more likely, but I think quite a different problem and not necessarily a problem at all), and if a company uses our ideas that's generally going to be somewhere between neutral an positive for us (it might be a bit annoying if and when they butcher them).&lt;/p&gt;


&lt;p&gt;And, to go back to the original quote, a lot of that is because you can't patent social technologies. Lets keep it that way.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2020-06-30-17:03.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2020-07-01-09:38.html</id>
    <title>Cultivating the Skills of Context</title>
    <updated>2020-07-01T11:12:32+01:00</updated>
    <content type="html">

&lt;p class="subtitle"&gt;Cultivating the Skills of Context&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2020-07-01&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;Have you noticed how there are jokes that really can only exist in their extremely specific context?&lt;/p&gt;


&lt;p&gt;&lt;a href="https://twitter.com/DRMacIver/status/1268905827399761921"&gt;Here's an example&lt;/a&gt;. The joke is kinda obvious in context, but it entertained me, and there is really &lt;em&gt;no&lt;/em&gt; other context in which that joke could possibly have existed.&lt;/p&gt;


&lt;p&gt;Something &lt;a href="https://twitter.com/DRMacIver/status/1276155095370084354"&gt;I lightly advocated for recently&lt;/a&gt; is the use of niche analogies. e.g. I get good mileage out of &lt;a href="https://notebook.drmaciver.com/posts/2020-02-20-09:31.html"&gt;analogies between programming and therapy&lt;/a&gt;. I also get good mileage out of analogies between farming and ethics. I also get good mileage out of &lt;a href="https://notebook.drmaciver.com/posts/2020-06-05-09:08.html"&gt;analogies between farming and ethics&lt;/a&gt; ("cultivating" is itself something of a farming analogy). These analogies will typically only work for a small group of people, because they have to be in the intersection of the groups who understand each of the things being compared, but they may work very well for those people.&lt;/p&gt;


&lt;p&gt;In &lt;a href="https://drmaciver.substack.com/p/unusual-foundations"&gt;unusual foundations&lt;/a&gt; I argued that you have a unique set of skills and background, and as a result may be able to take advantage of them in unique ways that allow you to achieve things more easily than advice would suggest.&lt;/p&gt;


&lt;p&gt;A lot of software is &lt;a href="https://www.drmaciver.com/2018/11/situated-software/"&gt;situated&lt;/a&gt; - it is extremely embedded in a particular environment and use case, and has none of the things that you might expect from a more general purpose piece of software, to the point where it may be easier to write a new one than to adapt the software to a new context (this notebook blog is itself a piece of situated software).&lt;/p&gt;


&lt;p&gt;What all of these have in common is that they are things that only work in a very specific context. They don't generalise (or "scale" if you prefer) outside of that context, because they take advantage of hyper-specific features that are not widely shared.&lt;/p&gt;


&lt;p&gt;Is that a bad thing?&lt;/p&gt;


&lt;p&gt;When I tell (or, more realistically, hear) a really funny joke that works only in that specific context, I always feel a little annoyed because I would like to share the joke and can't. But maybe the reason the joke is so funny is precisely &lt;em&gt;because&lt;/em&gt; of its uniqueness - its reliance on the situation is what gives it its novelty and makes it funny.&lt;/p&gt;


&lt;p&gt;Advice that generalises is great, because it can help more people, but the nature of advice is that the more you generalise it the less good it becomes, because you have to simplify it so people understand, you have to add preconditions or remove the things that depend on those preconditions. Often by the time you've reached enough people you've put in a lot of work and made it less good as a result. This is the whole reason I wrote the unusual foundations post - for any given general purpose piece of advice there is probably a better context specific piece of advice. So you end up trading off between number of people you help and how much you help them.&lt;/p&gt;


&lt;p&gt;(This isn't entirely true because helping more people &lt;a href="https://notebook.drmaciver.com/posts/2020-06-30-17:03.html"&gt;gives you more people to innovate on the advice&lt;/a&gt;, but you can have your cake and eat it too by sharing the advice in its context-specific form, along with explaining the context, and let other people innovate to adapt it to themselves)&lt;/p&gt;


&lt;p&gt;This pattern repeats over and over again, with generalising things being a lot of work and typically making them worse.&lt;/p&gt;


&lt;p&gt;But of course one nice thing about generalising is that you often don't have to do that work in the first place. Someone &lt;a href="https://www.drmaciver.com/2017/02/thinking-through-the-implications/"&gt;has already invented the hammer&lt;/a&gt;, I don't need to come up with a custom context-specific artisanal solution to hammer in this particular nail.
As a result, in the moment a general purpose solution is often easier than a context-specific one &lt;em&gt;as long as that general purpose solution already exists&lt;/em&gt;.&lt;/p&gt;


&lt;p&gt;This is, I think, the source of a lot of mediocrity: It's too much work to do the good thing, so we fall back to the known thing. We only use a context-specific solution when there isn't an easy general purpose one, or when the context-specific one is obvious to us (e.g. the jokes).&lt;/p&gt;


&lt;p&gt;(The general-purpose solution is, of course, not &lt;em&gt;always&lt;/em&gt; worse than a context-specific one - often a general-purpose solution has been refined through a great deal of time and effort, and trying to adopt a context-specific one is like rolling your own crypto: It's bad)&lt;/p&gt;


&lt;p&gt;But everything we do has a rich set of context. This means that we should expect there to be a rich set of context-specific solutions available to us, and we're often likely ignoring them and trying to fit an inappropriate general purpose solution to the situation in question.&lt;/p&gt;


&lt;p&gt;The solution is, I think, to generalise from the solutions we find in context, but not by generalising the solution and instead generalising the process by which we found it. By cultivating the skills of looking at a context and identifying whether it permits things that are not possible in the broader world, we lower the effort of finding context-specific solutions, which will often allow us to move from mediocrity to excellence.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2020-07-01-09:38.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2020-07-02-10:06.html</id>
    <title>From Maintaining to Making</title>
    <updated>2020-07-02T10:36:44+01:00</updated>
    <content type="html">

&lt;p class="subtitle"&gt;From Maintaining to Making&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2020-07-02&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;From &lt;a href="https://amzn.to/3bW2J6t"&gt;The Shock of the Old&lt;/a&gt; by David Edgerton, page 98:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;There are many examples in the history of twentieth-century technology where enterprises started by maintaining a technology, moved on to manufacture components or the whole thing, and then to innovate. But equally there are others where maintenance did not lead to such a development.&lt;/p&gt;
&lt;/blockquote&gt;


&lt;p&gt;This point is, of course, straight out of &lt;a href="https://amzn.to/2WYUxyi"&gt;The Economy of Cities&lt;/a&gt; by Jane Jacobs (and Edgerton explicitly mentions it).&lt;/p&gt;


&lt;p&gt;I think one of the interesting dynamics of maintenance is that maintenance is intrinsically &lt;a href="https://notebook.drmaciver.com/posts/2020-07-01-09:38.html"&gt;context-specific&lt;/a&gt;. You're not maintaining cars, you're maintaining this specific car. Over time, two identical objects have their own events and history - sometimes they're deliberately modified, sometimes they're just used in a particular way which causes particular strains. This intimately affects what you need to do to maintain them.&lt;/p&gt;


&lt;p&gt;The skill of generalising from that maintenance is differently hard - it involves thinking about how things behave when stripped of their context, and robs you of a lot of context-specific tools. For example, it is not in the nature of the &lt;a href="https://notebook.drmaciver.com/posts/2020-03-26-09:48.html"&gt;kludge&lt;/a&gt; to generalise.&lt;/p&gt;


&lt;p&gt;But, equally, maintenance both gives you a strong incentive to generalise, because although each object you maintain is different, you get to see many objects and start to notice the patterns through them over and over again. A maintainer is significantly more aware of what the lifecycle of the objects in use is than the manufacturer, and this probably leads very naturally into superior manufacturing if you've got the means and inclination to do so.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2020-07-02-10:06.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2020-07-03-21:03.html</id>
    <title>Death of the Reader</title>
    <updated>2020-07-03T21:15:21+01:00</updated>
    <content type="html">

&lt;p class="subtitle"&gt;Death of the Reader&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2020-07-03&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;From &lt;a href="https://amzn.to/3ekINM9"&gt;Clear and simple as the truth&lt;/a&gt; by Thomas and Turner, page 138:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;Word for word, Gallanda's version is the worst written, the most fraudulent and the weakest, but it was the most widely read. [...] Its orientalism, which we now find tame, dazzled the sort of person who inhaled snuff and plotted tragedies in five acts. [...] We, mere anachronistic readers of the twentieth century, perceive in these volumes the cloyingly sweet taste of the eighteenth century and not the evanescent oriental aroma that two hundred years ago was their innovation and their glory. No one is to blame for this missed encounter, least of all Galland.&lt;/p&gt;
&lt;p&gt;Jorge Luis Borges, "Los traductores de las 1001 noches" [The translators of the 1001 nights]&lt;/p&gt;
&lt;/blockquote&gt;


&lt;p&gt;I wrote before about the difficulty of &lt;a href="https://notebook.drmaciver.com/posts/2020-06-20-15:10.html"&gt;understanding historical fact from historical records&lt;/a&gt;. This, I think, highlights another problem for understanding history: As modern readers, it is extremely difficult for us to understand how a text would have been read at the time.&lt;/p&gt;


&lt;p&gt;I've encountered this problem with reading historical mathematics. It is very hard to read historical mathematics, because one tends to read them through the lens of modern mathematics. For example, reading texts from prior to the invention of modern mathematical notation, it's very easy to think of it in terms of its modern representation.&lt;/p&gt;


&lt;p&gt;The thing is, that modern representation makes certain things very obvious that were not at all obvious to historical mathematicians.&lt;/p&gt;


&lt;p&gt;In general, it is very hard to read a text without looking at it through the lens of culture that we have built since that text was written. That culture gives us ways of looking, and thinking, and feeling, about the contents of the text that make it impossible for us to read it as it would have been read at the time.&lt;/p&gt;


&lt;p&gt;Sometimes that culture is even informed by the text. For example, I found reading 1984 very tedious, because I found its contents obvious and predictable, but a lot of why they are obvious and predictable is that everybody has read 1984.&lt;/p&gt;


&lt;p&gt;I am reminded of people who read Lord of the Rings and find it laughable because all of the characters in it are fantasy cliches.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2020-07-03-21:03.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2020-07-05-11:29.html</id>
    <title>Getting Test-Case Reduction Unstuck with Automaton Inference</title>
    <updated>2020-07-05T12:24:56+01:00</updated>
    <content type="html">

&lt;p class="subtitle"&gt;Getting Test-Case Reduction Unstuck with Automaton Inference&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2020-07-05&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;A question I get asked a lot by friends is why I don't talk about my PhD much.
The answer is generally very simple: It's because almost nobody actually wants to know about my PhD, and it's not worth the half hour of bringing them up to speed while they politely pretend that they do.&lt;/p&gt;


&lt;p&gt;But, on the other hand, (a small handful of) people do generally seem interested when I talk about my technical work on Twitter, and this notebook is where I get to write about whatever the hell I want, and part of &lt;a href="https://drmaciver.substack.com/p/why-am-i-not-working-on-my-phd"&gt;the plan to sort out my PhD&lt;/a&gt; is to do some more non-paper research writing.&lt;/p&gt;


&lt;p&gt;So today's post is about my research. Sorry for everyone who is here mainly for feelings and social commentary.&lt;/p&gt;


&lt;p&gt;Context: I work on a thing called test-case reduction. Test-case reduction is basically "just" constrained optimisation of a total order (the reduction order), over some set (the test cases), where the constraint is just a black box predicate you've been handed (the interestingness test), and you've been handed a single witness of the set (the initial test case).&lt;/p&gt;


&lt;p&gt;For reasons that are explained in &lt;a href="https://drmaciver.github.io/papers/reduction-via-generation-preview.pdf"&gt;our paper about Hypothesis&lt;/a&gt; I'm particularly interested in the case where the test cases are all byte strings (we present it as bit strings in the paper, but same deal really) where the order is the shortlex order. i.e. \(s \preceq t\) if \(|s| &amp;lt; |t|\) or \(|s| = |t|\) and \(s \leq t\) in the lexicographic order.&lt;/p&gt;


&lt;p&gt;There is an idea that I've had in the back of my head for a while:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;Given some interestingness test \(p\) and some starting test case \(s\), the set \(\{t: p(t) \wedge t \preceq s\}\) is finite and thus a regular language.&lt;/li&gt;
&lt;li&gt;If we had a deterministic finite automaton for that language, we could just read off the shortlex-minimal string matched by that automaton using a breadth-first search, giving us the global minimum interesting test case.&lt;/li&gt;
&lt;li&gt;We can infer (an approximation to) that automaton using &lt;a href="https://www.sciencedirect.com/science/article/pii/0890540187900526"&gt;the L* algorithm&lt;/a&gt; (or see &lt;a href="https://www.youtube.com/watch?v=zlHck7X4F20"&gt;my PyCon UK talk on the subject&lt;/a&gt; for a less technical account).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This suggests a great approach to test-case reduction: We set up the L* algorithm, make sure it gets the correct result on our initial test case, read off the minimal matching string of the automaton, check if that's correct and if not pdate the automaton, and iterate that until the automaton-minimal string is also interesting.&lt;/p&gt;


&lt;p&gt;This idea is genuinely very good except for two small problems.&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;It's prohibitively slow.&lt;/li&gt;
&lt;li&gt;It doesn't work.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;It's prohibitively slow because the complexity of L* is weird and depends a lot on the language being learned, but in practice you're lucky if it's only \(O(n^2)\) when you use it this way. It doesn't work because although the language is regular it doesn't have a particularly nice structure a lot of the time and the algorithm isn't always able to pick up on important details as a result. For example, L* does not easily learn the constraint that two bytes can be equal but it doesn't matter what value they take beyond that.&lt;/p&gt;


&lt;p&gt;This is all very unfortunate because it's a lovely idea.
Fortunately, as I discovered recently, there is actually a context in which L* can potentially be a significant boon to test-case reduction after all: You can use it offline to learn new reduction passes (a reduction pass is basically just a simple test-case reducer, but effective test-case reducers tend to be assembled out of multiple reduction passes) that are &lt;em&gt;not&lt;/em&gt; prohibitively slow and correspond to established deficiencies in your existing reducer.&lt;/p&gt;


&lt;p&gt;We can find deficiencies in a reducer by basically looking for ways it gets "stuck". This is based on an idea called &lt;a href="https://agroce.github.io/issta17.pdf"&gt;test case normalization&lt;/a&gt; which is essentially that the goal of a reducer should be that its output does not depend on the initial test case, only the interestingness test.&lt;/p&gt;


&lt;p&gt;If you have some interestingess test that demonstrable does not normalize on an initial corpus of test cases (in my case these are generated by Hypothesis) you can learn a set of new reduction passes that normalizes that corpus. You do this by picking the two smallest examples, adding a reduction pass that turns the larger of the two into the smaller, and rerunning until all of the corpus is normalized (which takes at most one pass per corpus element).&lt;/p&gt;


&lt;p&gt;Suppose \(s \preceq t\) are the two smallest elements of that corpus after reduction. There is a trivial reduction pass that just replaces the string \(t\) with the string \(s\) wherever it finds it. This is actually quite good, because after reduction (assuming the initial reducer is doing an OKish job of normalizing) you're much more likely to see \(t\) than chance would suggest. You can improve these odds further by removing a common prefix and suffix from each of \(s\) and \(t\).&lt;/p&gt;


&lt;p&gt;But you can also generalise this further. Suppose we've extracted those common prefixes, say \(u\) and \(v\).
We now use L* to learn the predicate \(f(x) = s \preceq axb \wedge |axb| \leq |t| \wedge p(axt)\). i.e. we learn a smallish language that captures just enough information to turn the central bit of \(t\) into the central bit of \(s\).&lt;/p&gt;


&lt;p&gt;We now use this language to define a new reduction pass which finds any substrings that match this DFA and replace them with the smallest element of it. By making sure L* has learned enough about \(s\) and \(t\) to correctly predict them, this ensures that the new pass can transform \(t\) into \(s\).&lt;/p&gt;


&lt;p&gt;At a high level what this is doing is essentially learning patterns where your existing reducer gets "stuck" and learn just enough about the linguistic structure of the test case format to work around them.&lt;/p&gt;


&lt;p&gt;Does this work?&lt;/p&gt;


&lt;p&gt;Well, maybe.&lt;/p&gt;


&lt;p&gt;There are roughly two ways this can go wrong:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;The DFA may still be impractical to learn.&lt;/li&gt;
&lt;li&gt;The learned passes may not generalise well enough to be useful, so this ends up with a very large number of passes.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Initial experiments on Hypothesis are pretty promising as to whether the DFAs can be learned, but the Hypothesis test-case format is very forgiving. I'll be surprised if this works well enough out of the box on human-readable test-case formats and I expect it will need more tinkering. In particular when the reduced test-cases in the corpus are far apart, I think one needs some intermediate steps to learn smaller transformations first (I have some ideas for how to use &lt;a href="https://en.wikipedia.org/wiki/A*_search_algorithm"&gt;A*&lt;/a&gt; to do this. I do know algorithms that aren't just a letter and an asterisk, I promise).&lt;/p&gt;


&lt;p&gt;The number of learned passes is potentially more of a problem, but conveniently I was &lt;a href="https://github.com/HypothesisWorks/hypothesis/pull/2478"&gt;already working&lt;/a&gt; on an approach to make it practical to run test-case reduction with a large number of mostly useless passes.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2020-07-05-11:29.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2020-07-06-09:52.html</id>
    <title>Indexing a DFA in shortlex order</title>
    <updated>2020-07-06T10:56:10+01:00</updated>
    <content type="html">

&lt;p class="subtitle"&gt;Indexing a DFA in shortlex order&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2020-07-06&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;Bad news feelings-readers, it's another technical post. Having feelings will resume shortly (probably in tomorrow's newsletter if nothing else)&lt;/p&gt;


&lt;p&gt;I &lt;a href="https://twitter.com/DRMacIver/status/1278986162443636736"&gt;asked the other day&lt;/a&gt; about how to find the shortlex-predecessor of a string in a regular language represented by a DFA. I eventually came up with &lt;a href="https://gist.github.com/DRMacIver/89a7a27b70bbb795748fd20d1ad50f82"&gt;a solution that wasn't too bad&lt;/a&gt;.
This morning in the shower I came up with a better one (disclaimer: I haven't written code for this or tested it, so it's probably subtly wrong and has off by one errors, and it may perform poorly, but the basic idea is sound in theory).&lt;/p&gt;


&lt;p&gt;The basic idea is this: It's well known that using breadth first search we can enumerate the regular language in shortlex-ascending order as \(x_0, \ldots, x_n, \ldots\). Finding the predecessor of \(s\) given this enumeration is as simple as looking up \(s = x_n\) and returning \(x_{n - 1}\). Unfortunately, \(n\) may be exponentially large in \(|s|\) so doing the enumeration is horribly impractical.&lt;/p&gt;


&lt;p&gt;But! It turns out, you don't have to, and this solution can be made workable (given a good bigint library to represent the indices) as follows:&lt;/p&gt;


&lt;p&gt;Maintain a dynamic programming table \(C(i, k)\) which counts the number of accepted strings of length \(k\) starting from state \(i\) in the DFA. Also maintain a dynamic programming table \(R(i, k) = \sum\limits_{j = 0}^k C(i, j)\) (i.e. the number of strings of length at most \(k\) accepted from state \(i\)).&lt;/p&gt;


&lt;p&gt;What this table lets you do is essentially skip over the bits of the breadth first search that you know won't lead to where you're going, and count how many strings you skipped by doing so.&lt;/p&gt;


&lt;p&gt;Now, you look up \(x_n\) by first comparing values of \(R(0, k)\) to find \(k\) with \(R(0, k) &amp;lt; n \leq R(0, k + 1)\).
We know \(k = |x_n|\). Now, walk the DFA, using \(C(i, k)\) to determine which node to transition to (using essentially the same idea - this is easier to explain in code, but I haven't written the code yet!).&lt;/p&gt;


&lt;p&gt;Now, to find \(x_n = s\) we just count the number of strings in the langugage which are shortlex smaller than \(s\).
This can be established relatively easily: First count \(R(0, |s| - 1)\), all strings that are shorter than \(s\), and then work out the number of strings of length \(|s|\) that are lexicographically smaller than \(s\) by adding up sum of the strings of length \(k - i\) by walking the DFA and after reading \(i\) characters count the number of strings of length \(|s| - i - 1\) that you would get from following each \(c &amp;lt; s_i\).&lt;/p&gt;


&lt;p&gt;To be honest, I think this explanation was all clear as mud, sorry. I think either you'll get the idea immediately from the initial seed of "Use dynamic programming to get the indices" or the explanation won't clarify it, and I should have written the code instead of trying to explain this in prose. Alternatively, this is a sign that I really need to get much better at explaining this sort of thing in prose. &lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2020-07-06-09:52.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2020-07-07-22:30.html</id>
    <title>The Possibility and the Actuality of Change</title>
    <updated>2020-07-07T22:36:13+01:00</updated>
    <content type="html">

&lt;p class="subtitle"&gt;The Possibility and the Actuality of Change&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2020-07-07&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;(A very short post, because I've been struggling to maintain the daily writing habit recently and it's useful to remind myself that this is possible)&lt;/p&gt;


&lt;p&gt;From &lt;a href="https://amzn.to/2ZCqSNc"&gt;A Little Book on the Human Shadow&lt;/a&gt; by Robert Bly, page 77:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;Wallace Stevens was not willing to change his way of life, despite all the gifts he received, and all the advice he read in his own poems.&lt;/p&gt;
&lt;/blockquote&gt;


&lt;p&gt;This is, I think, a useful reminder to anyone who wants to change their life, but it's especially a useful reminder to me and others who have a perhaps overly intellectual approach to the problem. I'm building a practice of change on a huge amount of reading and writing, which can lead to the trap of confusing the knowledge of how to change with the change itself.&lt;/p&gt;


&lt;p&gt;Much of what I write is, if I do say so myself, very good advice to how to change and improve your life (especially if your problems look like mine). I'm not always that great at following it - I'm no Wallace Stevens (though I do not know if Bly's criticisms of him are at all fair) - I do listen to my own advice, and I do follow it, but perhaps not as consistently as I might.&lt;/p&gt;


&lt;p&gt;Knowing how and what to change is important - vital even - but change has to be grounded in a willingness to change, and to then do the work of changing.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2020-07-07-22:30.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2020-07-08-14:56.html</id>
    <title>Precarity and Conformity</title>
    <updated>2020-07-08T14:56:00+01:00</updated>
    <content type="html">

&lt;p class="subtitle"&gt;Precarity and Conformity&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2020-07-08&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;From &lt;a href="https://amzn.to/36wKnYH"&gt;Rewriting the Rules&lt;/a&gt; by Meg-John Barker, page 94:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;We've seen throughout this book that rigid rules are generally bad both for those who fall outside them &lt;em&gt;and&lt;/em&gt; for those who fit within them.&lt;/p&gt;
&lt;/blockquote&gt;


&lt;p&gt;A thing I find myself thinking about a lot is &lt;em&gt;precarity&lt;/em&gt;: Specifically, the scenario where nothing is wrong &lt;em&gt;now&lt;/em&gt;, but you are well aware that this could change at any time.&lt;/p&gt;


&lt;p&gt;This is I think different from a lot of cases where we think of precarity as being associated with things being bad in the moment. e.g. poverty is a precarious situation, because you can't absorb sudden large financial blows, but poverty is also quite bad in the moment.&lt;/p&gt;


&lt;p&gt;Many privileged states however have a form of precarity to them. This often goes hand in hand with privileges. For example, being able-bodied is a precarious situation - there are no invulnerable bodies, and you could lose your status as able-bodied at any time.&lt;/p&gt;


&lt;p&gt;The reality, of course, is that &lt;em&gt;all&lt;/em&gt; situations are precarious. Just as there are no invulnerable bodies, there are no invulnerable lives. Everything can be lost, and we don't like to think about that.&lt;/p&gt;


&lt;p&gt;But although everything is precarious, some situations are significantly more precarious than others.&lt;/p&gt;


&lt;p&gt;One particular source of precarity is attached to changes of worldview. What if you are wrong about something major? It does happen. What if, in particular, you were wrong about some major source of ethics or value?&lt;/p&gt;


&lt;p&gt;I think conformity to the rules often plays out this way: For people who fit the rules, their self-worth is often tied to the fact that very fact of conformity. This makes it precarious in several major ways:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;The rules can change.&lt;/li&gt;
&lt;li&gt;You can change.&lt;/li&gt;
&lt;li&gt;You can be deemed not "really" conforming.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;The third is particularly scary because actually all social rules are fake and the reality is a much more messy interplay between expectation and social power, so the only thing that is needed to be declared nonconforming is for someone with more social clout than you to want to declare you so. All conformity can buy you is a certain measure of defence against that attack.&lt;/p&gt;


&lt;p&gt;The problem is that as long as you are using conformity as your measure of self-worth, or even just as a way to make your life easier, you &lt;em&gt;really&lt;/em&gt; don't want to be subject to that attack, or otherwise become nonconforming, and so are willing to sink in a lot of effort to reduce your precarity. Because conformance is central to your experience, that precarity feels central, so you end up sinking a lot of time and effort into conforming to the rules, and feeling anxious because you can never reduce the precarity to zero.&lt;/p&gt;


&lt;p&gt;In contrast, nonconformity is often more robust. It's not necessarily &lt;em&gt;better&lt;/em&gt; - often the punishment for nonconformance is quite high - but because you don't have to worry about losing your privileged status you can devote your energies to other things. The bad thing you were worried about has already happened, and there's not much you can do about it other than get on with life.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2020-07-08-14:56.html" rel="alternate"/>
  </entry>
</feed>
