<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
  <id>https://notebook.drmaciver.com/</id>
  <title>DRMacIver's notebook</title>
  <updated>2018-09-08T10:59:00+01:00</updated>
  <author>
    <name>David R. MacIver</name>
    <email>david@drmaciver.com</email>
  </author>
  <link href="https://notebook.drmaciver.com" rel="alternate"/>
  <link href="https://notebook.drmaciver.com/feed.xml" rel="self"/>
  <generator uri="http://lkiesow.github.io/python-feedgen" version="0.7.0">python-feedgen</generator>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-08-10:59.html</id>
    <title>2018-09-08-10:59</title>
    <updated>2018-09-08T10:59:00+01:00</updated>
    <content>

&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-08&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 Terry Tao has an interesting series of posts:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
&lt;a href="https://terrytao.wordpress.com/2009/11/05/the-no-self-defeating-object-argument/"&gt;
   The “no self-defeating object” argument&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://terrytao.wordpress.com/2010/10/18/the-no-self-defeating-object-argument-revisited/"&gt;
   The “no self-defeating object” argument, revisited&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://terrytao.wordpress.com/2010/11/02/the-no-self-defeating-object-argument-and-the-vagueness-paradox/"&gt;
   https://terrytao.wordpress.com/2010/11/02/the-no-self-defeating-object-argument-and-the-vagueness-paradox/&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;


&lt;p&gt;
 The idea of the "no self-defeating object" argument is, roughly, that suppose there were some some object that "defats" all objects,
then it would also defeat itself, and thus cannot exist. It's a specific form of reductio ad absurdum,
and can be applied to many different forms of "object" and notions of "defeat".&lt;/p&gt;


&lt;p&gt;
 Examples:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
  There is no largest number ("defeat" here meaning something like \(\geq n + 1\)).&lt;/li&gt;
&lt;li&gt;
  There is no set of sets ("defeat" meaning \(\in\)).&lt;/li&gt;&lt;/ul&gt;


&lt;p&gt;
 In the second post he outlines how we can almost always turn these arguments instead into "every object is defeated by some other object", and this often works better for people uncomfortable with proof by contradiction (which is most non-mathematicians).&lt;/p&gt;


&lt;p&gt;
 The third post is especially interesting in the light of
 &lt;a href="https://notebook.drmaciver.com/posts/2018-09-08-08:06.html"&gt;
  my recent post about the nature of mathematics&lt;/a&gt;
 ,
in that it observes that an unusual characteristic of mathematics is that mathematical statements are intended to have a precise meaning in a way that natural language statements typically are not.&lt;/p&gt;


&lt;p&gt;
 This suggests the following modified definition:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  Mathematics is the study of unambiguous statements about hypothetical objects&lt;/p&gt;&lt;/blockquote&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-08-10:59.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-08-10:40.html</id>
    <title>2018-09-08-10:40</title>
    <updated>2018-09-08T10:49:21+01:00</updated>
    <content>

&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-08&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 The
 &lt;a href="http://cs.brown.edu/courses/csci0190/2018/laptop-policy.html"&gt;
  laptop policy&lt;/a&gt;
 from Shriram Krishnamurthi's "Accelerated Introduction to Computer Science" class is an interesting collection of resources on laptop usage in class.&lt;/p&gt;


&lt;p&gt;
 I've definitely found that it is true that longhand note taking improves my retention and focus while device usage immediately kills it. The point about device usage distracting
 &lt;em&gt;
  other&lt;/em&gt;
 people around you is particularly interesting though.&lt;/p&gt;


&lt;p&gt;
 I feel like imposing this sort of rule is a deeply unpopular move in my social group,
but I think they're mostly wrong about that.
OTOH this is very much a question of competing access needs and I'm not sure what the best way to resolve it is.`&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-08-10:40.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-08-10:39.html</id>
    <title>2018-09-08-10:39</title>
    <updated>2018-09-08T10:39:50+01:00</updated>
    <content>

&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-08&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
&lt;a href="https://how.complexsystems.fail/"&gt;
  How Complex Systems Fail&lt;/a&gt;
 is very good. A lot of the citations have been on my reading stack for a while,
and given that I'd already deprioritised them I'm now inclined to just not bother now that I've read the TLDR.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-08-10:39.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-08-08:06.html</id>
    <title>2018-09-08-08:06</title>
    <updated>2018-09-08T10:38:49+01:00</updated>
    <content>

&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-08&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 I've been trying to come up with a definition of mathematics that I like and think would be useful in the course of teaching people mathematics.&lt;/p&gt;


&lt;p&gt;
 This is of course a big ask, as
 &lt;a href="https://en.wikipedia.org/wiki/Definitions_of_mathematics"&gt;
  according to Wikipedia there is a great deal of spirited philosophical debate on the subject&lt;/a&gt;
 ,
but on the other hand I think most of those definitions are
 &lt;em&gt;
  terrible&lt;/em&gt;
 , so I don't feel too bad about trying myself.&lt;/p&gt;


&lt;p&gt;
 The one I dislike the least from that list is
 &lt;a href="http://mathworld.wolfram.com/Mathematics.html"&gt;
  Eric Weisstein's&lt;/a&gt;
 :&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  Mathematics is a broad-ranging field of study in which the properties and interactions of idealized objects are examined.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 It's a bit long-winded but mostly captures the sense I want. The phrasing I've been thinking of in preference is something more like:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  Mathematics is the rigorous study of hypothetical objects.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 The idea is that in mathematics we're not really concerned with real life physical objects,
we can just say "Suppose there were objects satisfying the following properties, what can we reliably say about them?"&lt;/p&gt;


&lt;p&gt;
 Sometimes those objects are ones that can easily be realised as real physical objects. For example the
 &lt;a href="https://en.wikipedia.org/wiki/Mathematical_chess_problem"&gt;
  Mathematics of Chess&lt;/a&gt;
 studies hypothetical chess boards,
but those hypothetical chess boards can easily be realised by going out and buying an actual physical chessboard.
However, many of them can not be. There is no way to construct a real physical set of natural numbers,
but from a mathematical point of view that's OK - we can reason about the properties of the hypothetical one perfectly well.&lt;/p&gt;


&lt;p&gt;
 There are a couple axes of variation on which people differ about the nature of mathematics:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  Is informal mathematics legitimate, or should all mathematics be considered a (possibly bad) approximation to an entirely formal set of reasoning rules?&lt;/li&gt;
&lt;li&gt;
  Are some hypothetical objects privileged as the true platonic mathematical objects in a way that others are not?&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 I think this definition is more or less compatible with any combination of answers to these questions:
Formalism is a question of what we count as "rigorous",
and even if there
 &lt;em&gt;
  are&lt;/em&gt;
 platonic mathematical objects, we still must study them
 &lt;em&gt;
  as if&lt;/em&gt;
 they were hypothetical because by its very nature we cannot have access to the platonic realm.&lt;/p&gt;


&lt;p&gt;
 Traditionally the answers to these questions have been correlated more than I think is logically required:
The formalist position is that mathematics doesn't real and that everything is formal manipulation of symbols,
while the platonist position is that we are seeking to discover truths about the ideal platonic realm and the truths are what matter regardless of how we reason about them.&lt;/p&gt;


&lt;p&gt;
 I think there's room for a third position though, which is that formalism is interesting but not strictly required, but the objects we describe have no inherent reality and really are allowed to be purely hypothetical.
I've historically self-described as a formalist, but I think this third position is closer to my true beliefs:
I don't think Platonism is philosophically defensible,
but I do think there is a lot of interesting mathematical content and activity that cannot be adequately captured by the formalist position.&lt;/p&gt;


&lt;p&gt;
 In many ways this third position is that of Lakatos in his "Proofs and Refutations".
Most of the interesting mathematics happens in a fuzzy middle-ground where you are making your definitions precise enough to be defensible.
This could go all the way to formalism, but it doesn't have to.&lt;/p&gt;


&lt;p&gt;
 The mathematics of chess is again an interesting test case here:
Chess is a purely arbitrary set of rules. I think it would be hard to argue that there is a platonic game of chess that is in some essential way different than it would have been if,
say, kings moved like knights or you could win by killing the queen
 &lt;em&gt;
  or&lt;/em&gt;
 the king. These are both perfectly valid games that someone could play,
and there is a perfectly valid mathematics in studying them, but we study the mathematics of chess in preference to them because that is the actual game people play.&lt;/p&gt;


&lt;p&gt;
 Conversely,
there really is a set of true statements about the game of chess (in an informal sense of chess),
and while mechanising and formalising the study of them might be
 &lt;em&gt;
  useful&lt;/em&gt;
 for determining what they are, I think it's fair to say that what actually matters is whether the statement is true of real games of chess,
and the formalisation only matters to the degree that it helps us discover those truths.&lt;/p&gt;


&lt;p&gt;
 I don't think the above definition is enough to fully reconstruct an idea of what mathematics is like,
because it leaves open two big questions:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  How do we select which hypothetical objects to study?&lt;/li&gt;
&lt;li&gt;
  How do we study them?&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 The answer to the first is comparatively easy, which is that it's based on what I think of as "The Three Good Reasons To Do Things":&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  It's useful.&lt;/li&gt;
&lt;li&gt;
  It's interesting.&lt;/li&gt;
&lt;li&gt;
  Some asshole is forcing you to do something useless and boring.&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 (Most people's encounters with mathematics is of type 3, sadly, which is why I always hear "Oh I
 &lt;em&gt;
  hated&lt;/em&gt;
 mathematics at school" when I tell people I did mathematics at university)&lt;/p&gt;


&lt;p&gt;
 Of course, point 2 is slightly subtle, because doing mathematics is much easier if other people have done similar mathematics, so you're constrained not just by what
 &lt;em&gt;
  you&lt;/em&gt;
 think is interesting, but by what you can convince other people is interesting.&lt;/p&gt;


&lt;p&gt;
 The second question is the hard part, and I think we currently do a very poor job of explaining it to people. I need to think further about it.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-08-08:06.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-07-15:47.html</id>
    <title>2018-09-07-15:47</title>
    <updated>2018-09-07T16:29:06+01:00</updated>
    <content>

&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-07&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 The thing I called
 &lt;a href="https://notebook.drmaciver.com/posts/2018-08-30-07:50.html"&gt;
  the Feynmann style&lt;/a&gt;
 relates to Tim Gowers's
 &lt;a href="https://www.dpmms.cam.ac.uk/~wtg10/2cultures.pdf"&gt;
  The Two Cultures of Mathematics&lt;/a&gt;
 ,
where he suggests that there are two cultures of mathematics: Theory building and problem solving. The latter tends to get organised not along the lines of general big ideas and broad theorems,
but instead along heuristics and guiding principles.&lt;/p&gt;


&lt;p&gt;
 Gowers refers to the areas of mathematics that are primarily problem-solving as
 &lt;em&gt;
  combinatorial&lt;/em&gt;
 ,
but I feel like this kind of problem solving is one that it doesn't seem right to refer to as combinatorial - it's more... calculation?&lt;/p&gt;


&lt;p&gt;
 There's a similar sense of being guided by heuristics and general ideas though.&lt;/p&gt;


&lt;p&gt;
 For example, one general idea is "replace annoying terms with integrals over some new variables, then swap out the variable".&lt;/p&gt;


&lt;p&gt;
 Suppose we didn't know what \(\sum\limits_{n = 1}^\infty (-1)^{n - 1} \frac{1}{n}\) was.
How would we deal with this?&lt;/p&gt;


&lt;p&gt;
 (Note: There's all sorts of playing fast and loose with convergence in this post that you can shore up later with some proper calculation but I'm not actually going to do. That's very common in this sort of proof).&lt;/p&gt;


&lt;p&gt;
 Well, that \(\frac{1}{n}\) is an annoying term. Lets get rid of it with.
A classic way of doing this is to replace it with \(\int\limits_0^1 x^{n - 1} dx\).&lt;/p&gt;


&lt;p&gt;
 We can now do the computation as follows:&lt;/p&gt;


&lt;p&gt;
 \begin{align}
\sum\limits_{n = 1}^\infty (-1)^{n - 1} \frac{1}{n} &amp;amp; = \sum\limits_{n = 1}^\infty (-1)^{n - 1} \int\limits_0^1 x^{n - 1} \\
&amp;amp; = \sum\limits_{n = 0}^\infty (-1)^n \int\limits_0^1 x^n \\
&amp;amp; = \int\limits_0^1 \sum\limits_{n = 0}^\infty (-x)^n \\
&amp;amp; = \int\limits_0^1 \frac{1}{1 + x} \\
&amp;amp; = \ln(1 + x) \\
\end{align}&lt;/p&gt;


&lt;p&gt;
 Roughly the steps here are:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  Try replacing tricky terms with integrals over simpler terms&lt;/li&gt;
&lt;li&gt;
  Use standard sums that you already know the answer for&lt;/li&gt;
&lt;li&gt;
  Try swapping sums and integrations&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 Another useful calculational heuristic is "try changing the variable".&lt;/p&gt;


&lt;p&gt;
 e.g. what's the limit as \(n \to \infty\) of \(n \ln (1 + \frac{1}{n})\)?&lt;/p&gt;


&lt;p&gt;
 Well, let \(x = \frac{1}{n}\). This expression is now \(\frac{ln(1 + x)}{x} = \frac{ln(1 + x) - \ln(1)}{x}\) as \(x \to 0\).
i.e. it's the derivative of \(\ln\) at \(1\), i.e. \(1\).&lt;/p&gt;


&lt;p&gt;
 It's hard to explain exactly what the thought process is here. It's like solving a puzzle - you have a bunch of known tricks that you think might work and you try to apply them all.
If you were to mechanize the process then it wuold end up looking like a brute force solver for the problem, but by using intuition you can kinda guide the way.&lt;/p&gt;


&lt;p&gt;
 I think maybe one part of the split between problem-solving and theory building is how much of what you end up building escapes the head of the mathematician building it:
Problem-solving skills are much harder to teach to another person than theory is (once that other person has build the skill of acquiring theory, which is also hard to teach)&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-07-15:47.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-07-15:27.html</id>
    <title>2018-09-07-15:27</title>
    <updated>2018-09-07T15:44:40+01:00</updated>
    <content>

&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-07&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 Compare and contrast:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
&lt;a href="https://www.cambridge.org/core/journals/journal-of-the-american-philosophical-association/article/aristotle-on-trolling/540BB557C82186C33BFFB61E35A0B5B6"&gt;
   "Aristotle" on trolling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://www.drmaciver.com/2014/02/etiquette-for-the-devils-advocates/"&gt;
   Etiquette for the Devil's advocates&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;


&lt;p&gt;
 I think the role the "Aristotle" (AKA
 &lt;a href="http://individual.utoronto.ca/rbarney/Home.html"&gt;
  Rachel Barney&lt;/a&gt;
 ) describes is probably quite a useful one in the right context,
the problem is that the nature of Trolling as defined in that paper is intrinsically that it is done
 &lt;em&gt;
  not&lt;/em&gt;
 in the right context.&lt;/p&gt;


&lt;p&gt;
 There's a thing that happens in Vernor Vinge's "A Deepness in the Sky" where the Evil Overlord ™ is experimenting with different configurations you can put a group mind in.
I sometimes think about this as an analogy for how to construct better modes of group problem solving (in a non-evil-overlord way that in no way involves my using the army of crows that I don't have to impose my will on the unsuspecting masses. Yes) .&lt;/p&gt;


&lt;p&gt;
 In particular, I think it's often actively useful for someone to explicitly take an adversarial role in a group discussion,
and it improves the resulting group's intelligence.
The difficulty is that you need to do this in a context where the group consents to this, and with a fairly explicit discussion in advance of boundaries.
It also helps to be able to ask the adversary to step out of the adversarial role and clarify their position.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-07-15:27.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-07-12:32.html</id>
    <title>When come back bring pie(s)</title>
    <updated>2018-09-07T12:58:38+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;When come back bring pie(s)&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-07&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 There's a metaphor people use: Some people fight for a larger slice of the pie, others see that it's better to enlarge the pie.&lt;/p&gt;


&lt;p&gt;
 I've seen this metaphor used for everything from intersectional feminism to the Patrician of Ankh-Morpork's extremely libertarian brand despotism.
Broadly the point is this: It's better to build a positive sum game where everyone benefits than it is to compete in a zero or negative sum game.&lt;/p&gt;


&lt;p&gt;
 The relationship between this point and the metaphor is interesting.
I agree with the thing that I am claiming to be the underlying point (but then I would), but I think what the actual metaphor demonstrates is also interesting:
People don't understand how pies work.&lt;/p&gt;


&lt;p&gt;
 What happens when you build a bigger pie?&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  You run into scaling issues, limited both by the size of your oven and also (if you build a better oven) the square-cube law (actually I'm not sure if this is the square-cube law at work, as pies tend to be scaled horizontally faster than they are scaled vertically, but either way once your pie gets big enough it's very hard to ensure it's cooked all the way through - you end up with overdone outsides and and underdone middle).&lt;/li&gt;
&lt;li&gt;
  The same people who couldn't eat your smaller pie still can't eat your larger one.6&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 The correct solution is not to enlarge the pie. It's to
 &lt;em&gt;
  bake more pies&lt;/em&gt;
 , and also the provide tasty food that is not pie because not everyone likes pie.&lt;/p&gt;


&lt;p&gt;
 If you've ever tried catering to a diverse group of dietary requirements, at some point you hit the point where you realise that it's much much easier to make multiple dishes than it is to try to create a single dish that can feed everyone.
A vegan gluten free nut free diabetic friendly pie is certainly possible, but it is a pie that basically nobody is going to
 &lt;em&gt;
  want&lt;/em&gt;
 to eat.
In contrast, a wide variety of desserts that can cater to each particular restriction that your group encounters,
without attempting to shoehorn everyone into a one size fits all badly model.&lt;/p&gt;


&lt;p&gt;
 The Unit of Caring has a notion she uses a lot of
 &lt;em&gt;
  competing access needs&lt;/em&gt;.
She
 &lt;a href="https://theunitofcaring.tumblr.com/post/135162290121/hi-i-have-a-quick-question-i-tried-googling-but"&gt;
  explains it well here&lt;/a&gt;
 ,
but the important quote (to save you from Tumblr's giant GDPR screen) is:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  Competing access needs is the idea that some people, in order to be able to participate in a community, need one thing, and other people need a conflicting thing, and instead of figuring out which need is ‘real’ we have to acknowledge that we can’t accommodate all valid needs.
I originally encountered it in disability community conversations: for example, one person might need a space where they can verbally stim, and another person might need a space where there’s never multiple people talking at once. Both of these are valid, but you can’t accommodate them both in the same space.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 Trying to build a space that works for everyone is more or less impossible, and what you will end up with is a space that works badly for everyone.
Instead we need the ability to have multiple spaces which we acknowledge as valid and allow people to freely move between these spaces as long as they are prepared to accept the local rules.&lt;/p&gt;


&lt;p&gt;
 In an interesting coincidence, this came up in a completely different context recently.
A while back
 &lt;a href="https://www.drmaciver.com/2016/05/randomizing-lean-coffee/"&gt;
  I sketched out a way of using randomization to improve the design of Lean Coffee meetups&lt;/a&gt;.
 &lt;a href="https://twitter.com/georgesdubus/status/1037957014599749632"&gt;
  This morning a friend reported&lt;/a&gt;
 :&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  I used to organize David-Style lean coffees at my previous job. (...)
The interesting limitation we ran into is that toward the end, the attendence was two groups with mostly disjoint interests.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 The nice thing about small-scale democratic processes like this is that splitting the union is a completely legitimate move.
If you have two groups with disjoint interests, why not run them as two groups? Ideally at different times so that people who really
 &lt;em&gt;
  are&lt;/em&gt;
 interested in both can attend both.&lt;/p&gt;


&lt;p&gt;
 How to do this sort of thing at a larger scale seems to be one of the great unsolved problems of society.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-07-12:32.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-06-10:14.html</id>
    <title>2018-09-06-10:14</title>
    <updated>2018-09-06T11:07:01+01:00</updated>
    <content>

&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-06&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 Follow on to
 &lt;a href="https://notebook.drmaciver.com/posts/2018-09-05-13:24.html"&gt;
  misc thoughts about voting design for talk scheduling&lt;/a&gt;.&lt;/p&gt;


&lt;p&gt;
 Here's how a system that is much closer to classic STV could work.
Assume everyone has a ranking of all the talks they wish to attend (this isn't actually reasonable to ask for, but you could get people to score talks according to some ordinal scores and then randomly tie break, or tie break in organiser preferred order or something).&lt;/p&gt;


&lt;p&gt;
 The system has the following three parameters:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  The number of time slots.&lt;/li&gt;
&lt;li&gt;
  The number of talks per time slot.&lt;/li&gt;
&lt;li&gt;
  The minimum number of attendees required for a talk to be worthwhile (should be at least one). Callt his the threshold.&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 You also need to pick a quota system. Either the
 &lt;a href="https://en.wikipedia.org/wiki/Comparison_of_the_Hare_and_Droop_quotas"&gt;
  Droop or the Hare quota&lt;/a&gt;
 are the obvious choices.
My natural bias is to use the Hare quota, as it's better for minority interests and I think that's a nice feature to have in your conference talk selection (conferences have a tendency to have the same talks over and over again and I think this would help offset that).&lt;/p&gt;


&lt;p&gt;
 The system could easily be adapted to more complicated constraints in which not all talk/time slot combinations are valid, but I'm going to ignore that.&lt;/p&gt;


&lt;p&gt;
 Conceptually what happens is everyone is given one voting-buck,
and a talk slot "costs" an amount of voting-bucks equal to the quota.
People band together to form buying blocs and each spend the same percentage of their remaining pool of voting money to buy a slot (this is basically how normal STV works too).&lt;/p&gt;


&lt;p&gt;
 The system involves running the following process to a fixed point:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  Set the list of eligible talks to all talks which have at least the threshold number of people voted for them.&lt;/li&gt;
&lt;li&gt;
  Give everyone exactly one vote (note: as the process evolves, people will have fractional votes).&lt;/li&gt;
&lt;li&gt;
  People vote for (talk, slot) pairs, where the slot has not already been filled and the talk is both eligible and not yet scheduled.
   They will vote for a pair if:
  &lt;ol&gt;
&lt;li&gt;
    The talk their highest ranked talk among the available talks.&lt;/li&gt;
&lt;li&gt;
    If there are slots which have no talks they want to see in them, they will only vote for pairs in those slots.
   Otherwise they will vote for pairs where they prefer the talk to the one currently scheduled there.
   Note that a voter can vote for multiple (talk, slot) pairs.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;
  If there are no such pairs, we have scheduled all of the talks we can (even if there still unfilled slots). Stop and report this as the schedule.&lt;/li&gt;
&lt;li&gt;
  If any of the pairs has a total number of votes exceeding the quota, pick the one with the most votes and schedule that.
   For each voter who voted for it, multiply their remaining vote by \(1 - \frac{q}{r}\), where \(q\) is the quota and \(r\) is the total vote for the elected slot
   (i.e. we've removed \(q\) from their total vote and everybody pays it equally).&lt;/li&gt;
&lt;li&gt;
  If no pair was elected, take the talk with the lowest maximum vote over all vote pairs, and remove it from the list of eligible talks.&lt;/li&gt;
&lt;li&gt;
  If a pair was elected, now check if any talks can no longer meet the threshold - i.e. if for every slot you could schedule them in,
   count the number of people for whom that is their favourite talk in that slot. If there are no slots where this exceeds the threshold, remove the talk from the eligible list.&lt;/li&gt;
&lt;li&gt;
  If we removed any talks from the eligible list, reset all of the state except the list of eligible talks and go back to step 2. Otherwise go back to step 3.&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 Most of this is just variant STV, with some of the specific details owing to specific types of STV.
The main difference is that because the same voter may cast their vote for multiple options simultaneously,
we need to be careful not to elect more than one "candidate" at once,
plus the specialised drop-out rule for talks that fail to meet the threshold.&lt;/p&gt;


&lt;p&gt;
 Most of my problems with it are the same as my problems with STV in general: It looks like an iterative optimisation process, but it's not at all clear what it is you are optimising for.
So it might work well, but I'm not really sure how you would measure "well" in this context.
It seems plausibly worth a try though.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-06-10:14.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-05-13:24.html</id>
    <title>Mechanisms for talk scheduling and voting</title>
    <updated>2018-09-06T09:23:39+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;Mechanisms for talk scheduling and voting&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-05&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 I've been thinking about mechanism design for conference scheduling again.
I've
 &lt;a href="https://www.youtube.com/watch?v=OkusHEBOhmQ"&gt;
  previously argued that conference scheduling should be treated as an optimisation problem&lt;/a&gt;
 ,
but I no longer believe that's true.&lt;/p&gt;


&lt;p&gt;
 In particular I think the following hold:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
  If we treat talk selection as a voting problem, we must employ some mechanism of proportional representation&lt;/li&gt;
&lt;li&gt;
  In a multi-track conference, scheduling and selection cannot be separated.&lt;/li&gt;&lt;/ul&gt;


&lt;p&gt;
 Lets see some examples in support of this.&lt;/p&gt;


&lt;p&gt;
 Suppose you're running a Python conference, and 60% of the people attending are web developers and 40% are data scientists.
You put together a set of talk proposals, people vote on them, and you take all of the top voted talks.
What you end up with is of course a conference consisting entirely of web development talks.&lt;/p&gt;


&lt;p&gt;
 (Note: Despite the running Python example, this post is not actually about
 &lt;a href="https://2018.hq.pyconuk.org/schedule/"&gt;
  The PyCon UK Schedule&lt;/a&gt;
 , which I've barely looked at.)&lt;/p&gt;


&lt;p&gt;
 For some contexts maybe that's OK, but given that a lot of the value in conferences is the hallway track, it's nice to be able to put together heterogenous conferences.
You could fix this by artificially selecting for certain subjects, but proportional representation seems like a much better approach because it doesn't require you to know all the ways in which your audience is heterogenous in advance.
So, in the above example, we would have roughly 60% web dev talks and 40% data science talks,
but also if it turned out that about 10% of the audience were really excited about Flask,
we could have about 10% Flask talks.&lt;/p&gt;


&lt;p&gt;
 If the conference is single-track we're more or less done: Pick your favourite (non party-list based, so probably some variant of STV), proportional voting system,
use that to select your talks, and call it a day.&lt;/p&gt;


&lt;p&gt;
 I'd like to pause here by saying that I'm increasingly a fan of single track conferences, so I think "do a single track conference and call it a day" might actually be the correct solution.&lt;/p&gt;


&lt;p&gt;
 But lets suppose you're less on board with that and want a multi-track conference.&lt;/p&gt;


&lt;p&gt;
 For simplicity, lets imagine that our Python conference now has two rooms,
with talks running in the same time slots in each room,
and attendees now have to choose which of the two to attend.
Lets say it's a single day conference and there are five time slots,
so ten talks.&lt;/p&gt;


&lt;p&gt;
 According to our above PR argument, we should run six web dev talks,
but does it really make sense for us to do so?
There are only five time slots,
so (by
 &lt;a href="https://en.wikipedia.org/wiki/Pigeonhole_principle"&gt;
  the pigeonhole principle&lt;/a&gt;
 if you want to get fancy about it) you're inevitably going to put two web dev talks back to back.
That might be OK - maybe you're scheduling a Django and a Flask talk against each other - but maybe there's a strict preference where there are five obviously best web dev talks and the sixth is pretty good (preferable by web devs to any data science talk) but not good enough (will not get any attendees when scheduled against any of the top five talks). What's the point in selecting that talk given that?&lt;/p&gt;


&lt;p&gt;
 In the other direction, lets say we have 20% of the audience who are really interested in random forests,
and so we select two random forests talks,
which we then proceed to schedule in the same time slot.
Now despite 20% representation at the talk level,
they only have 10% representation at the time slot level!&lt;/p&gt;


&lt;p&gt;
 (I want to draw an analogy to
 &lt;a href="https://en.wikipedia.org/wiki/Gerrymandering"&gt;
  gerrymandering&lt;/a&gt;
 here but I don't think it quite works)&lt;/p&gt;


&lt;p&gt;
 So, tracking creates an upper bound on how much proportional representation is worth doing, and also scheduling within those tracks affects the amount of proportionality you actually get.&lt;/p&gt;


&lt;p&gt;
 So what to do about it?&lt;/p&gt;


&lt;p&gt;
 Well, I'm not entirely sure. I started designing a whole complex system in support of this that this note was originally supposed to be about, but I decided I didn't like it very much.&lt;/p&gt;


&lt;p&gt;
 The basic ideas were:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  Give each participant a "voting currency" - everyone starts with an equal amount, and talk slots effectively get auctioned off, with the proceeds distributed among everyone equally (possibly among everyone who still has any interest in attending remaining talks).&lt;/li&gt;
&lt;li&gt;
  Participants will only vote for talks in slots that are strictly better for them than the talks already scheduled in that slot.&lt;/li&gt;
&lt;li&gt;
  Define a threshold of "Minimum number of people required to be worth running a talk". Whenever a talk no longer would meet that requirement (because every slot it could be scheduled in has talks people prefer more), it is immediately excluded and the process restarts from the beginning. This is akin to how exclusions work in
  &lt;a href="https://en.wikipedia.org/wiki/Wright_system"&gt;
   The Wright System of STV&lt;/a&gt;
  , and is designed to avoid "spoiler" talks, where people who preferred them effectively get screened off from voting in the process until the talk is excluded.&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 The details kinda became a weird hybrid of STV and the
 &lt;a href="https://en.wikipedia.org/wiki/Vickrey%E2%80%93Clarke%E2%80%93Groves_mechanism"&gt;
  Vickrey-Clarke-Groves mechanism&lt;/a&gt;
 and the more I looked at it the less convinced I became that it was the right way to do things or that I actually understood how the VCG mechanism plays out in practice.&lt;/p&gt;


&lt;p&gt;
 I do think the above examples are important to consider though.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-05-13:24.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-05-11:08.html</id>
    <title>My parents, Ayn Rand and God</title>
    <updated>2018-09-05T11:20:12+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;My parents, Ayn Rand and God&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-05&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
&lt;a href="https://twitter.com/bazzalisk/status/1037277763219152897"&gt;
  From bazzalisk on Twitter&lt;/a&gt;
 :&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  “You know him better than I” and “You know him better than me” are both grammatically valid but mean different things&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 The former means "You know him better than I do", the latter means "You know him better than you know me".&lt;/p&gt;


&lt;p&gt;
 The title of this note comes from the following probably-apocryphal book dedication,
used as an argument for the oxford comma:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  This book is dedicated to my parents, Ayn Rand and God.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 Without the Oxford comma,
the implication is that the author's parents are Ayn Rand and God,
with the Oxford comma, this is a dedication to four people (the author's parents, and also to Ayn Rand and God).
 &lt;a href="http://mentalfloss.com/article/33637/best-shots-fired-oxford-comma-wars"&gt;
  Mental Floss has a bunch of similar ones&lt;/a&gt;.&lt;/p&gt;


&lt;p&gt;
&lt;a href="http://msgboard.snopes.com/cgi-bin/ultimatebb.cgi?ubb=get_topic;f=95;t=000863;p=0"&gt;
  Snopes think this probably never happened&lt;/a&gt;
 ,
but OTOH the following is part of their argument:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  Since Rand was such an outspoken atheist, I find it hard to believe that anyone would mention both her and God as sources of inspiration.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 And, well, this seems to ignore the existence of Paul Ryan and a significant chunk of the US political right.
Also I'm now amused by the idea of Ayn Rand's atheism being a reaction to God being a deadbeat dad.
Someone should write that fanfic, but it's not going to be me.&lt;/p&gt;


&lt;p&gt;
 There is of course
 &lt;a href="https://amzn.to/2LYsLcz"&gt;
  an entire book about comedic misinterpretations due to bad grammar&lt;/a&gt;
 ,
but that's not exactly what's going on here:
Instead these are interesting grammatically valid examples that are right on the edge of ambiguity.&lt;/p&gt;


&lt;p&gt;
 It's unclear to me whether this actually tells us anything useful.
We could probably derive some normative advice about correct use of grammar from it,
but this sort of thinking about things in terms of their edge cases is a very modern-mathematician view of the world,
which doesn't come very naturally to others.&lt;/p&gt;


&lt;p&gt;
 The general widely deployed solution to linguistic ambiguity is instead that we just guess or ask,
and frankly that probably works better than trying to remove it.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-05-11:08.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-02-21:22.html</id>
    <title>Fiction for Kristian</title>
    <updated>2018-09-02T21:54:40+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;Fiction for Kristian&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-02&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 This is a small collection of fiction I've written that I like enough to actively recommend and think count as "finished".&lt;/p&gt;


&lt;h3&gt;
 Fan fiction&lt;/h3&gt;


&lt;p&gt;
 The two pieces of Stargate fan fiction that I've written and would recommend are
 &lt;a href="https://archiveofourown.org/works/3673335"&gt;
  Stargate Physics 101&lt;/a&gt;
 and
 &lt;a href="https://archiveofourown.org/works/5023654"&gt;
  Interview with a System Lord&lt;/a&gt;.
Both are not only canon-compatible (more or less. Stargate Physics 101 doesn't quite line up with Stargate Universe, but I don't care about Universe),
but are 100% my headcanons of how the universe works.&lt;/p&gt;


&lt;p&gt;
 Completion status: 100% finished standalone pieces. I may write other Stargate fan fiction at some point, and if I do then as part of the universe's canon those will naturally be part of its backstory,
but there will never be sequels per se to these pieces.&lt;/p&gt;


&lt;p&gt;
 Recommendation strength: Stargate Physics 101 is one of my most popular pieces and works even if you have never watched Stargate. If you like any of infrastructure science fiction, software testing, or stargate, it's worth reading.
Interview with a System Lord is worth reading if and only if you like Stargate SG1 (and especially if you like Ba'al) and want a moderately amusing story exploring a weird headcanon. Warning: May cause mild sympathy for the devil.&lt;/p&gt;


&lt;p&gt;
&lt;a href="https://archiveofourown.org/works/4637439/chapters/10575111"&gt;
  The Rules of Wishing&lt;/a&gt;
 is a piece of fan fiction of Disney's Aladdin.
Premise:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  What if people were good at wishing? The Genie's rules have holes you could drive a herd of camels through, but they don't have to. Aladdin and Jafar's wishes are shallow and limited, and lack the foresight that really effective wishing entails, but wouldn't a battle between effective wishers be much more interesting? And while we're at it, why does Jasmine have so little agency and basically act as a prize to be won in a battle between two men when literally the entire point of her narrative is that she's not that?&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 It has been argued to be rational!fic though I'm not sure I agree with the classification.
Jasmine in this is probably my joint favourite character I've ever written.&lt;/p&gt;


&lt;p&gt;
 Completion status: Has a mini non-canon sequel
 &lt;a href="https://archiveofourown.org/works/13523703"&gt;
  The Consequences of Wishing&lt;/a&gt;
 that explains the divergence between this story and the film.
May, but probably won't, spawn another sequel, but the current ending wraps it up entirely to my satisfaction and any sequel would be a new story in the same universe with the same characters rather than a continuation of this story.&lt;/p&gt;


&lt;p&gt;
 Trigger warning: Moderately violent.&lt;/p&gt;


&lt;p&gt;
 Recommendation strength: Honestly, you should read this if you like my fiction at all and are not put off by the trigger warning.&lt;/p&gt;


&lt;p&gt;
&lt;a href="https://archiveofourown.org/works/13354146"&gt;
  Counterparts&lt;/a&gt;
 is a crossover fic between Lucifer (the TV show) and Old Harry's Game (the radio show).&lt;/p&gt;


&lt;p&gt;
 Completion status: Very standalone. It's not impossible I may do a followup involving The Good Place, but it stands on its own regardless of whether I do.&lt;/p&gt;


&lt;p&gt;
 Recommendation strength: Well it amuses
 &lt;em&gt;
  me&lt;/em&gt;. Based on feedback, if you like Lucifer it will probably also amuse you. Familiarity with the Old Harry's Game is helpful but not strictly required.&lt;/p&gt;


&lt;h3&gt;
 Original Fiction&lt;/h3&gt;


&lt;p&gt;
&lt;a href="https://archiveofourown.org/works/9233966/chapters/20941043"&gt;
  Programmer at Large&lt;/a&gt;
 is a story about gender, social anxiety, and legacy code.
It seems to have a lot of fans.&lt;/p&gt;


&lt;p&gt;
 Completion status: Abandoned, but it kinda works that way. It's a series of slice of life chapters, and the protagonist's life is never really "finished". However it definitely has some unsatisfying dangling plot threads that will never be resolved. However most of the strength of this story is at the chapter level anyway - it has some of my best writing in it, but as a whole story I do not feel that it works. I intend at some point to take it apart and refactor and modularise it into several smaller stories. I am fully aware of the irony of saying this about a story about legacy code.&lt;/p&gt;


&lt;p&gt;
 Recommendation strength: Mixed. There's some stuff in there I really like, and a lot of people seem to love it, but like I said I don't feel that it hangs together in its current incarnation.&lt;/p&gt;


&lt;p&gt;
&lt;a href="https://archiveofourown.org/series/754683"&gt;
  The Diaries of Vicky Frankenstein&lt;/a&gt;
 more normally AKA "The Vicky Stories". Series of short stories about Dr Vicky Frankenstein and her adventures in joining a biotech startup run by the vampire Ada Lovelace.&lt;/p&gt;


&lt;p&gt;
 Completion Status: (Hopefully permanently) incomplete in the sense that I fully intend to keep writing Vicky stories (but don't more than about one every six months), but each Vicky story is a complete standalone short story that happens to be set in the same world and use the same characters. There are minimal to no dangling plot threads between the stories.&lt;/p&gt;


&lt;p&gt;
 Recommendation Status: I ♥ writing Vicky and think you should read these. Also, contains a (99% SFW) lesbian sex scene between two amoral monsters that reviewers describe as "ridiculously adorable", so there's that.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-02-21:22.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-02-13:13.html</id>
    <title>2018-09-02-13:13</title>
    <updated>2018-09-02T13:34:22+01:00</updated>
    <content>

&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-02&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 Compare and contrast two interesting links:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
  Siderea's
  &lt;a href="https://siderea.livejournal.com/1230660.html"&gt;
   The Asshole Filter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
  Cormac Herley's
  &lt;a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/WhyFromNigeria.pdf"&gt;
   Why do Nigerian Scammers Say They are from Nigeria?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
  Karl Popper's "The Paradox of Tolerance"&lt;/li&gt;&lt;/ul&gt;


&lt;p&gt;
 (Note that I've not read the latter two and should. I've only read digested versions of them).&lt;/p&gt;


&lt;p&gt;
 In general often the right way to judge an action is not actually on its immediate effects,
but on what long-run effect they will have on the sort of people you will surround yourself with.
This can make seemingly good actions harmful and seemingly bad or nonsensical ones quite useful.&lt;/p&gt;


&lt;p&gt;
 I think about this a bunch in the context of codes of conduct:
Often the benefit of the code of conduct is not whether it is ever enforced,
but that it filters out people who don't like codes of conduct.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-02-13:13.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-01-17:41.html</id>
    <title>Notation for test-case reducers</title>
    <updated>2018-09-01T20:15:35+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;Notation for test-case reducers&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-01&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 A thing I've been noticing recently is that it's really useful to have compact notation for describing things.
Usually this is equivalent to primivitives + some combinators.&lt;/p&gt;


&lt;p&gt;
 One thing that I think it would be useful to have such a notation for is (greedy) test-case reduction passes.
They combine pretty well, and it makes it useful to discuss various things.&lt;/p&gt;


&lt;p&gt;
 For example, if you have reducers \(A\), \(B\), you can define the reducer \(AB\) which runs \(A\), then
runs \(B\) on its result. You can also define the reducer \(A^+\) which runs \(A\) to a fixed point.&lt;/p&gt;


&lt;p&gt;
 Another interesting combinator is \(/\). \(A / B\) runs \(A\), then runs \(B\) if \(A\) didn't do anything..&lt;/p&gt;


&lt;p&gt;
 There are a bunch of really basic algebraic relations that hold, like composition and \(/\) are associative,
and \((A^+)^+ = A^+\), but not a huge amount beyond that.&lt;/p&gt;


&lt;p&gt;
 A bunch of interesting questions about test-case reduction can be compactly expressed in this notation though.
For example, suppose you want to reduce to something that is a fixed point of both \(A\) and \(B\).
You could do \((AB)^+\), but you could also do \((A^+B^+)^+\), and it's quite natural to do this in some contexts.
My suspicion, which I've yet to verify, is that it's almost never the right thing to do.&lt;/p&gt;


&lt;p&gt;
 You can kinda regard the quadratic mode failure of greedy search as an instance of this problem:
If \(\delta_i\) is the operation that deletes the element at position \(i\), the correct pass to run for greedy deletion is \((\delta_0^+ \ldots \delta_n^+)^+\),
but if you start again at the beginning every time you succeed you are running \((\delta_0 / \ldots / \delta_n)^+\).&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-01-17:41.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-01-16:08.html</id>
    <title>Modes of writing</title>
    <updated>2018-09-01T16:11:23+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;Modes of writing&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-01&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 Two posts on writing to contrast:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
&lt;a href="https://blog.malignat.us/2018-05-12/on-the-creative-merits-of-paper"&gt;
   On the creative merits of paper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href="http://devonzuegel.com/post/comparison-of-text-editing-methods"&gt;
   Comparison of text editing methods&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;


&lt;p&gt;
 Devon posted the second on twitter and it reminded me of the first, which I struggled to refind, which is part of why I'm posting it here.&lt;/p&gt;


&lt;p&gt;
 I've been finding having a paper journal very useful, but I'm also finding having this new notebook useful in an entirely different way.
The contrast is very interesting.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-01-16:08.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-01-09:17.html</id>
    <title>Can a machine design?</title>
    <updated>2018-09-01T09:22:46+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;Can a machine design?&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-01&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
&lt;a href="http://echo.iat.sfu.ca/library/cross_01_machine_des.pdf"&gt;
  Can a machine design?&lt;/a&gt;
 by Nigel Cross is an interesting paper about architecture (the real kind!) and its relation to automation.
I found it via Adam Marshall Smith's PhD thesis
 &lt;a href="https://adamsmith.as/papers/mechanizing_exploratory_game_design_book.pdf"&gt;
  Mechanizing exploratory game design&lt;/a&gt;
 (truthfully via
 &lt;a href="https://twitter.com/maxkreminski/status/964923822766833664"&gt;
  this tweet&lt;/a&gt;
 about it from Max Kreminski),
which is an excellent thesis on mechanically assisted creativity (I must admit I skimmed the technical content as less relevant to me - I care about the meta more than I care about game design qua game design).&lt;/p&gt;


&lt;p&gt;
 Most relevant quote for me:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  Despite this apparently
easy pace of interaction, all of the designers reported that they
found the experiments hard work and stressful. They reported that
the main benefit of using the "computer" was increased work
speed, principally by reducing uncertainty (i.e., they relatively
quickly received answers to queries, which they accepted as reliable
information).
I also tried a few variations from my standard experiments. The most interesting was to reverse the normal set of expectations of the functions of the designer and the "computer."
The "computer" was given the job of having to produce a design to the
satisfaction of the observing designer. It immediately was apparent
that, in this situation, there was no stress on the designer—in fact, it
became quite fun—and it was the "computer" that found the experience
to be hard work.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 i.e. it's much more fun to tweak a computer's output than it is to be critiqued by one.
An important observation for people in correctness research I think!&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-01-09:17.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-08-31-09:43.html</id>
    <title>Some free user experience consulting for Google</title>
    <updated>2018-08-31T10:12:30+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;Some free user experience consulting for Google&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-08-31&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 I am not a UX expert. I've worked with people who are, and I'm probably a lot better than my otherwise utter incompetence at front-end work would suggest,
but I'm at best OK.&lt;/p&gt;


&lt;p&gt;
 Nevertheless, as a user I get to see a lot of the sharp edge of the problems, and I'm good enough at UX that I think I can see what the shape of the solution is.&lt;/p&gt;


&lt;p&gt;
 The product I would like to offer Google some free advice on is the following: Google Maps's driving navigation.&lt;/p&gt;


&lt;p&gt;
 On a related note, if you can recommend a good driving navigation app to me (iPhone, sadly), that would be delightful.
It would be especially useful if it were one that understood features of English roads like "has roundabouts" and "is verrah verrah smol" that seem alien to people from the US (although given how much of Google maps is in Zurich,
I'm still surprised by its failure to understand these).&lt;/p&gt;


&lt;p&gt;
 Anyway, free UX consulting.
User stories are cool I hear, so here are my two user stories for Google maps:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  As a driver, I would like to survive my trip.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 and&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  As a driver, I would like to be able to drive without a constant sense of paranoia.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 Currently Google Maps fails both of these so hard that I have conjectured that I have somehow triggered a special murder-mode for ex-Googlers,
because honestly if Google Maps treats most drivers like it treats me then either not many people can be using it or I would have expected a better publicised death toll from it.
I am not actually being hyperbolic here (or even parabolic).&lt;/p&gt;


&lt;p&gt;
 Google maps reliably does everything in its power to destroy my trust in it, which is not ideal in something that I have to use while driving.&lt;/p&gt;


&lt;p&gt;
 As the most basic minimum that would be required to restore my trust, I would like to propose the following feature:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  Google maps should never, under any circumstances, exit navigation without an audible confirmation that it has done so.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 There is what is almost certainly a bug in Google maps where sometimes it just goes "lol, I'm done here" and exits navigation without telling me.
This is
 &lt;em&gt;
  functionally indistinguishable&lt;/em&gt;
 from the sort of confirmation Google maps uses to tell me to just keep going straight.
As a result, whenever Google maps is silent for an extended period of time, I end up feeling a gnawing sense of paranoia that it's just not telling me what to do and I'm going in completely the wrong direction.&lt;/p&gt;


&lt;p&gt;
 Almost all of the time this is not the case and the correct thing to do is to keep going straight (although Google maps's notion of what "keep going straight" is is often very funny and involves amusing interpretations of the word "going straight" that include things like "turning left" - it is not very good at actually knowing where the road markings are, and if the road follows around to the right it will often confuse a left turn with keep going straight. However, I will forgive it data problems, particularly on the weird back country roads I often drive),
but this bug triggers just often enough (last incidence: about an hour ago) that the exceedingly common operation of
 &lt;em&gt;
  driving in a straight line&lt;/em&gt;
 fills me with deep unease whenever I use Google maps for navigation.&lt;/p&gt;


&lt;p&gt;
 Even if this bug were fixed, the damage is done, and I will never believe Google maps is still running if it is silent.&lt;/p&gt;


&lt;p&gt;
 On top of that, I would like to propose the following feature:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  Google maps should never be silent for an extended period of time.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 I'll grant that if the last instructions were "Keep going for 500 miles" it doesn't need to give me a mile counter every five minutes,
but if it could tell me every half hour or so "Yup, everything is cool, keep going" that would be great.
In normal operation,
every five minutes sounds about right.&lt;/p&gt;


&lt;p&gt;
 The second source of paranoia is that Google maps gives absolutely no feedback as to when you have done something wrong.
I know the whole nagging satnav going "Make a U-Turn. Make a U-Turn. Make a- *urk* (noise as satnav is thrown out window)" has a bad reputation,
but there's a happy medium: When you do something Google maps does not expect,
it should say something along the lines of "You missed a turn, I'm going to try to turn you around" or "You missed a turn, finding a new route".&lt;/p&gt;


&lt;p&gt;
 Fun instances where it was very useful to have a second person in the car yesterday:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  When Google maps took me 30 miles up the wrong motorway before eventually turning me around.&lt;/li&gt;
&lt;li&gt;
  When Google maps was very upset that I didn't drive through the traffic cones blocking the route it wanted me to take and insistently tried to turn me around for another go.&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 Feedback that I had done the wrong thing would have been very helpful on the first, because I would have spent a lot of time confused without it.
Feedback on the second that it was taking me around for another pass would also have been very helpful. I would have probably ignored its instructions even without Luke to assist me,
but I would have felt much less certain about it.&lt;/p&gt;


&lt;p&gt;
 Anyway, those is the main sources of paranoia.
Lets talk about the other moderately important feature:
Not dying and/or killing people.&lt;/p&gt;


&lt;p&gt;
 This is a very simple issue:
Google maps literally never gives you enough advance warning.
This is especially true in the following two cases:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
  with motorway driving. If you tell me "In one mile, take the exit" when I am doing 70 mph (yes, um, definitely 70 mph, that's the speed limit after all) in the right hand lane of a motorway,
  you are saying "In the next 30 seconds, merge across three lanes of possibly quite busy traffic". This is a style of advice that will literally kill people and, worse, make them miss their turning.&lt;/li&gt;
&lt;li&gt;
  with roundaboutes and other turnings where there is a lane you need to be in, I need to know what lane that is
  &lt;em&gt;
   before&lt;/em&gt;
  reaching the roundabout. It happens all the time that I either exit a roundabout,
  leave a motorway and Google maps is like "tum ti tum, la la, nothing to see here, oh hey there's a roundabout coming up. Atttt... theeee.... rouuuundabout.... taaaake..... the.... third... exit....".
  Often I am
  &lt;em&gt;
   on the fucking roundabout&lt;/em&gt;
  before it tells me what lane I need to be in.&lt;/li&gt;&lt;/ul&gt;


&lt;p&gt;
 Giving this sort of last minute instruction is deeply unsafe,
and needs to stop.&lt;/p&gt;


&lt;p&gt;
 On top of that there's all sorts of data problems and things where Google maps just clearly doesn't understand UK roads,
but I don't realistically expect those to be fixed, especially with the UK dooming itself to irrelevance next year and the only Google UK presence being in a city where you already have to embrace paranoia and risk loss of life and limb to drive in anyway, so I won't bother venting about those now.&lt;/p&gt;


&lt;p&gt;
 In the meantime, I'm serious about that desire for recommendations of less murdery navigation apps. Please?&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-08-31-09:43.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-08-31-06:57.html</id>
    <title>2018-08-31-06:57</title>
    <updated>2018-08-31T10:57:28+01:00</updated>
    <content>

&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-08-31&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 I'm a big fan of the
 &lt;a href="https://en.wikipedia.org/wiki/Brzozowski_derivative"&gt;
  Brzozowski derivative&lt;/a&gt;
 ,
introduced in "Derivatives of regular expressions" by Janusz A. Brzozowski.&lt;/p&gt;


&lt;p&gt;
 The basic idea is that given some language \(L\) over an alphabet \(A\),
and some string \(u\) over \(L\),
you can define the derivative language \(\partial(L, u) = \{v: uv \in L\}\).
We can extend this further (and it will be useful to do so below).
If \(M\) is some other language, we can define \(\partial(L, M) = \{v: \exists u \in M, uv \in L\}\).
I'm not currently sure if the derivative of a regular language by a regular langauge is regular in general. It is in the case we'll see later,
and I suspect it is in general.&lt;/p&gt;


&lt;p&gt;
 This seems like a pretty trivial observation until you realise the following three things:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  \(u \in L\) if and only if \(\epsilon \in \partial(L, u)\)&lt;/li&gt;
&lt;li&gt;
  \(uv \in L\) if and only if \(v \in \partial(L, u)\)&lt;/li&gt;
&lt;li&gt;
  For most common representations of languages, it's actually pretty easy to calculate a representation of their derivative.&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 Putting these together, you can use the Brzozowski derivative to calculate a deterministic (not necessarily finite!) automaton for almost any language that you can easily represent.
You label states with descriptions of languages,
a state is accepting if it matches the empty string,
and transitions to the states labelled by the derivatives.&lt;/p&gt;


&lt;p&gt;
&lt;a href="http://www.ccs.neu.edu/home/turon/re-deriv.pdf"&gt;
  Regular-expression derivatives reexamined&lt;/a&gt;
 by Owens et al. has some nice practical details of doing this in the context of functional programming.&lt;/p&gt;


&lt;p&gt;
 To see this in action, consider the standard regular expression operators.
These satisfy the following identifies:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  \(\partial(A | B, u) = \partial(A, u) | \partial(B, u)\)&lt;/li&gt;
&lt;li&gt;
  \(\partial(AB, u) = \partial(A, u)B | \nu(A) \partial(B, u)\), where \(\nu(A) = \epsilon\) if \(\epsilon \in A\) or \(\emptyset\) otherwise (i.e. the derivative can skip over \(A\) if and only if \(A\) contains the empty string)&lt;/li&gt;
&lt;li&gt;
  \(\partial(A^*, u) = \partial(A, u) A^*\)&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 A result proved in Brzozowski's original paper (apparently. I can't currently seem to access it, and am going off thecite in "Regular-expression derivatives reexamined) is that a small number of reasonable normalisation rules over the representation of the language is enough to ensure that you only get finitely many states in the state machine generated by partial derivatives of regular expressions.
It's certainly true that you only get finitely many if you have full equivalence for the regular languages labelling the states - the derivative automaton is actually the minimal automaton representing a language.&lt;/p&gt;


&lt;p&gt;
 There are two very nice things about this representation of the language's automaton though:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  It can be done
  &lt;em&gt;
   lazily&lt;/em&gt;. This means that even when your deterministic automaton has exponentially (or infinitely!) many states, you only ever need to explore the states that you walk when matching strings.&lt;/li&gt;
&lt;li&gt;
  It is very easy to extend with new operators.&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 An example of (2) is that regular expressions reexamined actually does it for extended regular expressions with intersection and negation, because might as well right? It's no harder than doing it with the normal ones, even though adding these to your regular expression language can cause exponential blowup in the size of the automata compiled from your regex.&lt;/p&gt;


&lt;p&gt;
 But there are even more interesting ones if you're prepared to go for more esoteric operations!&lt;/p&gt;


&lt;p&gt;
 Have you heard of the
 &lt;a href="https://en.wikipedia.org/wiki/Levenshtein_automaton"&gt;
  Levenshtein automaton&lt;/a&gt;
 ? The set of strings within some finite edit distance of another string is a regular language and you can define a nice automaton matching it.
But in fact, a stronger result is true: For any regular language \(L\) and natural number \(n\), the set \(E(L, n) = \{u: \exists v \in L, d(u, v) \leq n\}\) is a regular language.
Why?&lt;/p&gt;


&lt;p&gt;
 Well, we can calculate its derivative!
The derivative of \(E\) is \(\partial(E(L, n), u) = E(\partial(L, u), n) | E(L, n - 1) | E(\partial(L, \cdot), n - 1) | \partial(E(\partial(L, \cdot), n - 1), u)\).
That is, at each character we can either:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  Continue matching the original language (cost 0).&lt;/li&gt;
&lt;li&gt;
  Insert a new character in front of something in the original language (cost 1)&lt;/li&gt;
&lt;li&gt;
  Replace a character in the original language with \(u\) (cost 1)&lt;/li&gt;
&lt;li&gt;
  Drop a character from the original language and try again (cost 1)&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 In the course of doing this we apply the following rewrite rules:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  \(E(L, 0) = L\)&lt;/li&gt;
&lt;li&gt;
  \(E(\emptyset, n) = \emptyset\)&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 As long as the number of reachable representations for the original languages is finite,
so is the number of reachable states in our Levenshtein construction:
Every state is labelled by a set of languages of the form \(E(\partial(L, U), k)\) where \(U\) is a language defined by \(u_1 \ldots u_m\) with each \(u_i\) either a single character or a \(\cdot\),
and \(m + k \leq n\). There are only finitely many such labels as long as there are only finitely many derivatives of \(L\),
although in principle there may be exponentially many.
Because of the laziness of our construction that often won't matter - you can still determine membership for a string of length \(k\) with only \(O(k)\) state traversals (though calculating those states could in principle require up to \(O(nm)\) work, where \(m\) is the number of states in the original automaton).&lt;/p&gt;


&lt;p&gt;
 You can also use this to determine the minimum edit distance between two regular languages,
because you can test whether \(E(L, n) \cap L' = \emptyset\) by calculating and walking the generated DFA for the left hand side,
so this gives you a decision procedure for \(d(L, L') \leq n\).&lt;/p&gt;


&lt;p&gt;
 Is this a practical algorithm? Not sure. I've played with it a little bit, but I've not really put it to the test,
but I think it's an interesting example of the flexibility of the Brzozowski derivative,
and it was at least mildly surprising to me that the edit ball of a regular language is itself regular.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-08-31-06:57.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-08-30-12:39.html</id>
    <title>Mathjax and Python Markdown</title>
    <updated>2018-08-30T13:01:27+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;Mathjax and Python Markdown&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-08-30&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 I've been having an interesting time of things with this notebook and getting Python markdown and Mathjax to play well with each other.
In particular I have not been enjoying the markdown extension API at
 &lt;em&gt;
  all&lt;/em&gt;.&lt;/p&gt;


&lt;p&gt;
 Anyway, it turns out that it is easy to do what I need, just slightly undocumented and with some annoyingly silent failure modes.&lt;/p&gt;


&lt;p&gt;
 Here is the (slightly simplified) code from this notebook that makes MathJax work correctly:&lt;/p&gt;


&lt;div class="codehilite"&gt;
&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;markdown.inlinepatterns&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;HtmlPattern&lt;/span&gt;

&lt;span class="n"&gt;LATEX_BLOCK&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;r&lt;/span&gt;&lt;span class="s2"&gt;"(&lt;/span&gt;&lt;span class="se"&gt;\\&lt;/span&gt;&lt;span class="s2"&gt;begin{[^}]+}.+?&lt;/span&gt;&lt;span class="se"&gt;\\&lt;/span&gt;&lt;span class="s2"&gt;end{[^}]+})"&lt;/span&gt;
&lt;span class="n"&gt;LATEX_EXPR&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;r&lt;/span&gt;&lt;span class="s2"&gt;"(&lt;/span&gt;&lt;span class="se"&gt;\\&lt;/span&gt;&lt;span class="s2"&gt;\(.+?&lt;/span&gt;&lt;span class="se"&gt;\\&lt;/span&gt;&lt;span class="s2"&gt;\))"&lt;/span&gt;


&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;MathJaxAlignExtension&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;markdown&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Extension&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;extendMarkdown&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;md&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;md_globals&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;# Needs to come before escape so that markdown doesn't break use of \ in LaTeX&lt;/span&gt;
        &lt;span class="n"&gt;md&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;inlinePatterns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'mathjaxblocks'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;HtmlPattern&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;LATEX_BLOCK&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;md&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s1"&gt;'&amp;lt;escape'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;md&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;inlinePatterns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'mathjaxexprs'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;HtmlPattern&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;LATEX_EXPR&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;md&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s1"&gt;'&amp;lt;escape'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;
 The HtmlPattern class takes an expression and treats anything matching that expression as something that the markdown processor should not touch further.&lt;/p&gt;


&lt;p&gt;
 Some caveats to note:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
  Those brackets around the expression? Those are
  &lt;em&gt;
   important&lt;/em&gt;. The way that the regular expression processing works is that it messes with your regex a bit, and then uses capturing group \(2\) as the output (\(1\) will be everything in the current block prior to the start of your regex). This means that if you must use groups in your regex, make them named groups.&lt;/li&gt;
&lt;li&gt;
  For reasons I haven't fully understood and have chosen not to bother understanding because the current behaviour is correct for my needs, despite allegedly being an HTML block, this extension does seem to do entity escaping on the contents of your MathJax.&lt;/li&gt;&lt;/ul&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-08-30-12:39.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-08-30-07:50.html</id>
    <title>2018-08-30-07:50</title>
    <updated>2018-08-30T12:39:05+01:00</updated>
    <content>

&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-08-30&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 I'm going to start trying to port over some contents from
 &lt;a href="https://github.com/DRMacIver/research-notebook"&gt;
  my research notebook&lt;/a&gt;
 into here,
as this is intended long-term to be a replacement for it.
This will require some figuring out in terms of how to present maths.&lt;/p&gt;


&lt;p&gt;
 As a starting point,
here's a theorem:&lt;/p&gt;


&lt;p&gt;
 \(H(m) = \sum\limits_{q = 1}^m {(-1)}^{q - 1} {m \choose q} \frac{1}{q}\)&lt;/p&gt;


&lt;p&gt;
 Where \(H(m)\) is the m'th harmonic number \(H(m) = \sum\limits_{i}^m \frac{1}{i}\).&lt;/p&gt;


&lt;p&gt;
 This came up in "Birthday Paradox, Coupon Collectors, Caching Algorithms and Self-Organizing Search" by Flajolet et al. (which is excellent) where it was stated as "well known". It wasn't well known to
 &lt;em&gt;
  me&lt;/em&gt;
 ,
so I set out to prove it.&lt;/p&gt;


&lt;p&gt;
 The following is my proof:&lt;/p&gt;


&lt;p&gt;
 The main idea is to use a standard tricks of turning sums and integrals into other sums and integrals that happen to be easier to solve.
We use the following standard results:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
  \(\frac{1}{n} = \int\limits_0^1 x^{n - 1}dx\)&lt;/li&gt;
&lt;li&gt;
  \((1 + x)^m = \sum\limits_{q=1}^m {m \choose q} x^q\)&lt;/li&gt;
&lt;li&gt;
  \((1 - x)^{-1} = \sum\limits_{q = 0}^\infty x^q\) for \(|x| &amp;lt; 1\).&lt;/li&gt;&lt;/ul&gt;


&lt;p&gt;
 We then perform the following manipulations (don't worry if some of these are clear as mud. They kinda should be):&lt;/p&gt;


&lt;p&gt;
 \begin{align}
\sum\limits_{q = 1}^m {(-1)}^{q - 1} {m \choose q} \frac{1}{q} &amp;amp;= \sum\limits_{q = 1}^m {(-1)}^{q - 1} {m \choose q} \int\limits_0^1 x^{q - 1} dx\\
&amp;amp;= \int\limits_0^1 \sum\limits_{q = 1}^m {(-1)}^{q - 1} {m \choose q} x^{q - 1} dx\\
&amp;amp;= \int\limits_0^1 -x^{-1} \sum\limits_{q = 1}^m {m \choose q} {(-x)}^q dx\\
&amp;amp;= \int\limits_0^1 -x^{-1} \left( \sum\limits_{q = 0}^m {m \choose q} {(-x)}^q - 1 \right)dx \\
&amp;amp;= \int\limits_0^1 -x^{-1} \left( {(1 - x)}^m - 1 \right)dx \\
&amp;amp;= \int\limits_0^1 {(1 - x)}^{-1} (x^m - 1) dx \\
&amp;amp;= \int\limits_0^1 \sum\limits_{n = 0}^\infty x^n (x^m - 1) dx \\
&amp;amp;= \sum\limits_{n = 0}^\infty \int\limits_0^1 x^n (x^m - 1) \\
&amp;amp;= \sum\limits_{n = 0}^\infty \frac{1}{n + m} - \frac{1}{n} \\
&amp;amp;= \lim\limits_{k \to \infty}  H(m) - \sum\limits_{n = k}^{m + k} \frac{1}{n + m}\\
&amp;amp;= H(m)\\
\end{align}&lt;/p&gt;


&lt;p&gt;
 Notable magic tricks performed:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
  \(\int\limits_0^1 -x^{-1} \left( {(1 - x)}^m - 1 \right)dx  \to \int\limits_0^1 {(1 - x)}^{-1} (x^m - 1) dx \) is a change of variables \(x \to 1 - x\).&lt;/li&gt;
&lt;li&gt;
  \(\sum\limits_{n = 0}^\infty \frac{1}{n + m} - \frac{1}{n} \to \lim\limits_{k \to \infty}  H(m) - \sum\limits_{n = k}^{m + k} \frac{1}{n + m}\) is because you can use a change of variables \(k \to k - m\),
and then group the terms that cancel out.&lt;/li&gt;
&lt;li&gt;
  The final limit is because \(|\sum\limits_{n = k}^{m + k} \frac{1}{n + m}| \leq \frac{m}{k}\).&lt;/li&gt;&lt;/ul&gt;


&lt;p&gt;
 This is a style of calculation I think of as the Feynmann style because
 &lt;del&gt;
  it's very good at seeming more clever than it actually is&lt;/del&gt;
 he was fond of smugly boasting about using this sort of trick in preference to contour integration.
Given its prevalence prior to Feynmann, my only defence of the terminology is that it's not really intended as a compliment.&lt;/p&gt;


&lt;p&gt;
 I find the Feynmann style completely unenlightening to read - the only way to read a Feynmann style proof is to do it yourself, using the original as a guide when you get stuck.&lt;/p&gt;


&lt;p&gt;
 I think that's in some ways its point. It's not a proof technique designed to leverage enlightenment,
but instead it leans heavily on your puzzle solving skills. That can be useful sometimes when you just want to brute force your way through a problem and don't really care about understanding it on any sort of deeper level.&lt;/p&gt;


&lt;p&gt;
 I was exposed to the Feynmann style quite early on,
due to reading Schaum's Outlines of Advanced Calculus (an earlier edition. I'm not sure how early. Brown covered one. I sadly gave away my copy, and the 1974 edition one I ordered doesn't seem to be quite it) prior to going to university.
It has quite a lot of exercises using calculations like this,
and afterwards I realised that this is what Feynmann had been talking about in "Surely you're joking, Mr Feynmann" (I didn't understand what a contour integral was until a few years later).&lt;/p&gt;


&lt;p&gt;
 Somehow despite this the Feynmann style of brute force problem solving never really integrated into my mathematics,
and it's only some years later I've come to appreciate its merits.
I
 &lt;em&gt;
  still&lt;/em&gt;
 prefer to achieve insight and make the problem trivial,
but sometimes the problem isn't worth the insight and you're better off just putting in the hard work and solving it.&lt;/p&gt;


&lt;p&gt;
 Putting in the hard work is also useful because sometimes it leads you to the insight you missed and you can throw away most of the work.
This didn't happen here,
but I think that's OK - it's not that interesting a problem,
so I don't really feel upset by the lack of insight into it.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-08-30-07:50.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-08-29-09:35.html</id>
    <title>Notes on tiling with polyominoes</title>
    <updated>2018-08-29T12:23:11+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;Notes on tiling with polyominoes&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-08-29&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 Gary Fredericks wrote about
 &lt;a href="https://gfredericks.com/gfrlog/99"&gt;
  a backtracking algorithm for tiling a board with polyominoes&lt;/a&gt;.&lt;/p&gt;


&lt;p&gt;
 His solution is roughly "turn the problem into exact cover and then apply a bunch of interesting optimisations in this context to the naive backtracking algorithm".
The paper
 &lt;a href="https://arxiv.org/pdf/cs/0011047.pdf"&gt;
  Dancing Links&lt;/a&gt;
 by Donald E. Knuth in fact studies this exact problem as an application of the exact cover algorithm.&lt;/p&gt;


&lt;p&gt;
 I think some of the optimisations Gary performs are not ones that would be performed by a modern SAT solver because they are actually too expensive to be worth it if you're good at the SAT problem-e.g.
I know modern SAT solvers tend not to bother decomposing problems into independent problems because the cost is too high-but
it's possible they synergise well enough to be worth it. e.g. the number theory optimisation combined with the independent components may well be worth it,
especially with the heuristic of prioritising moves that disconnect the board.&lt;/p&gt;


&lt;p&gt;
 I've been doing a bit of casual reading about this class of problem recently.
I thought I'd use the opportunity of this new notebook to collect some references.
Ideally these would be proper cites,
but I haven't got the citation part of the notebook system working yet.&lt;/p&gt;


&lt;p&gt;
&lt;a href="https://www.jstor.org/stable/pdf/2307321.pdf"&gt;
  Checker Boards and Polyominoes&lt;/a&gt;
 by Solomon W. Golomb is a classic here.
It looks at the question of tiling the chessboard with a single square monomino and 11 tetrominos of various shapes.
In particular it establishes:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
  You can do this with right tetrominoes given any placement of the monomino&lt;/li&gt;
&lt;li&gt;
  There are only four squares where you can place the monomino if you want to do it with straight tetrominoes.&lt;/li&gt;&lt;/ul&gt;


&lt;p&gt;
&lt;a href="http://chalkdustmagazine.com/blog/polyominoes/"&gt;
  How to Tile a Chessboard&lt;/a&gt;
 by Trupti Patel is a nice expository piece on this.&lt;/p&gt;


&lt;p&gt;
 Golomb also wrote
 &lt;a href="http://publisher-connector.core.ac.uk/resourcesync/data/elsevier/pdf/03f/aHR0cDovL2FwaS5lbHNldmllci5jb20vY29udGVudC9hcnRpY2xlL3BpaS9zMDAyMTk4MDA2NjgwMDMzOQ%3D%3D.pdf"&gt;
  Tiling with Polyominoes&lt;/a&gt;
 ,
studying much more general questions of how to tile truncated chessboards with polyominoes.&lt;/p&gt;


&lt;p&gt;
 A classic version of this is what
 &lt;a href="https://en.wikipedia.org/wiki/Mutilated_chessboard_problem"&gt;
  Wikipedia refers to as the mutilated chessboard problem&lt;/a&gt;
 (apparently following Max Black):&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  Suppose a standard 8×8 chessboard has two diagonally opposite corners removed, leaving 62 squares. Is it possible to place 31 dominoes of size 2×1 so as to cover all of these squares?&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 The answer is no. In
 &lt;a href="https://www.tandfonline.com/doi/pdf/10.1080/07468342.2004.11922062"&gt;
  Tiling with Dominoes&lt;/a&gt;
 , N. S. Mendelsohn discusses two proofs:&lt;/p&gt;


&lt;blockquote&gt;
&lt;h3&gt;
  First solution&lt;/h3&gt;
&lt;p&gt;
  From the checkerboard diagram, the region contains 30 black cells and 32 white cells.
Since each domino covers 1 black and 1 white cell, tiling is impossible.&lt;/p&gt;
&lt;h3&gt;
  Second solution&lt;/h3&gt;
&lt;p&gt;
  When I was first shown the problem many years ago, it did not occur to me to colour
the cells. The region itself had seven cells in the top and bottom rows and eight cells in
the remaining rows. The same held for the columns. I proceeded to obtain information
on how many dominoes pointed horizontally and how many vertically. The first count
dealt with the vertical dominoes. If the region is tiled, the horizontal dominoes in the
top row occupies an even number of cells. Hence, the cells in the top row that are not
occupied by horizontal dominoes are odd in number. Thus there are an odd number of
vertical dominoes between the first and second rows. Since the second row has eight
cells, and an odd number are occupied by vertical dominoes coming down from the
first row, there remain an odd number of cells in the second row. The same argument
now shows there is an odd number of vertical dominoes from the second row to the
third. Continuing this way, we see that there is an odd number of vertical dominoes
between any pair of consecutive rows. Hence the total number of vertical dominoes is
the sum of seven odd numbers, which is odd. In the same way, using columns instead
of rows, there is an odd number of horizontal dominoes. Hence the total number of
dominoes is even. Since there are 62 cells to cover, the number of dominoes required
is 31, an odd number. Therefore, tiling is impossible.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 He goes on to say:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  Why do I produce two solutions to the puzzle? It is because I am interested in
the question of which is the better solution. At first glance, it appears that the first
solution is the better. It is much shorter and is easily understood by many people with
virtually no knowledge of mathematics. But are there considerations that might judge
the second solution to be the better one?&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 He then discusses whether the second one is better because it generalises better,
when setting out to prove Gomory's theorem (which I've not been able to find a copy of the original of so far, but I haven't looked very hard):
If you remove two squares of the same colour, you can always tiling the remainder with dominoes.
The proof involves the construction of a hamiltonian circuit on the adjacency graph,
and seems fiddly but interesting.
I've only skimmed it and would like to digest it further.&lt;/p&gt;


&lt;p&gt;
 However note that we saw a generalisation in a different direction in the first paper linked! Golomb's proof of the impossibility tiling with straight tetrominoes unless the monomino was in a very specific location was
 &lt;em&gt;
  also&lt;/em&gt;
 a colouring argument.&lt;/p&gt;


&lt;p&gt;
 The wikipedia page references "Across the board: the mathematics of chessboard problems" by John J. Watkins.
I should probably look up a copy.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-08-29-09:35.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-08-28-08:14.html</id>
    <title>First!</title>
    <updated>2018-08-28T14:18:34+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;First!&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-08-28&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 This is an experimental new blog intended for notes, thoughts, and whatever else I want to put here.
It will likely be biased towards short notes rather than longform essays.
It's loosely inspired by
 &lt;a href="https://shitpost.plover.com/"&gt;
  Mark Jason Dominus's shitposting blog&lt;/a&gt;
 and by my frustrations with WordPress, but I'm not really sure where it's going yet.&lt;/p&gt;


&lt;p&gt;
 It's also a place where I'll be experimenting with notation,
and generally trying to find a low friction way to express myself in a manner that I like.
As such it's all a bit cobbled together out of spit, bailing wire, and Python.&lt;/p&gt;


&lt;h3&gt;
 Notational Highlights&lt;/h3&gt;


&lt;p&gt;
 I kinda hate LaTeX, but it's the best typesetting language for mathematics that I know of,
so this notebook supports it using
 &lt;a href="https://www.mathjax.org/"&gt;
  mathjax&lt;/a&gt;.&lt;/p&gt;


&lt;p&gt;
 Testing: \(e^{i\pi} = -1\)&lt;/p&gt;


&lt;p&gt;
 A test of code highlighting.&lt;/p&gt;


&lt;div class="codehilite"&gt;
&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;SomeClass&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;""""A python class"""&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;method&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;"""A method definition"""&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;
 As you've probably noticed, I'm using
 &lt;a href="https://edwardtufte.github.io/tufte-css/"&gt;
  Tufte CSS&lt;/a&gt;.
I'm not sure it's exactly what I want, but it's a lot closer to what I want than most other things I've tried.
I will likely be messing aroudn with this further.&lt;/p&gt;


&lt;p&gt;
 I'm also using
 &lt;a href="http://www.makotemplates.org"&gt;
  mako templates&lt;/a&gt;
 ,
and fully intend to define a metric tonne of macros to make this usable.&lt;/p&gt;


&lt;p&gt;
 In general I expect the actual source code for this site to be totally unusable to anyone who is not me.
If anything,
if it's
 &lt;em&gt;
  not&lt;/em&gt;
 then I probably haven't done enough customization for my brain.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-08-28-08:14.html" rel="alternate"/>
  </entry>
</feed>
