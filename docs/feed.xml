<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
  <id>https://notebook.drmaciver.com/</id>
  <title>DRMacIver's notebook</title>
  <updated>2018-09-24T08:27:00+01:00</updated>
  <author>
    <name>David R. MacIver</name>
    <email>david@drmaciver.com</email>
  </author>
  <link href="https://notebook.drmaciver.com" rel="alternate"/>
  <link href="https://notebook.drmaciver.com/feed.xml" rel="self"/>
  <generator uri="http://lkiesow.github.io/python-feedgen" version="0.7.0">python-feedgen</generator>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-24-08:27.html</id>
    <title>2018-09-24-08:27</title>
    <updated>2018-09-24T08:27:00+01:00</updated>
    <content>

&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-24&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 A thing I've been noticing a lot recently in how I think about problems is what an essential role switching between different models of the system has.&lt;/p&gt;


&lt;p&gt;
 For example, when thinking about groups of people, it's important to think about the systems - what incentives are at play, how does the group response to events, etc.
You treat the group as an abstracted object that is not made up of complex individuals but instead has a few very simple variables in play.&lt;/p&gt;


&lt;p&gt;
 It's
 &lt;em&gt;
  also&lt;/em&gt;
 important, both ethically and practically, to think about the group as a collection of individual people. People are complex and will surprise you, and if you neglect their individual needs then you will usually treat people badly.&lt;/p&gt;


&lt;p&gt;
 It might be tempting to think that the ideal is a single unified view of the system which accounts for everything, but realistically that's almost always impossible, and switching between multiple very distinct models can often work nearly as well.&lt;/p&gt;


&lt;p&gt;
 One thing this does is it combats the problem of legibility - the thing where the easiest way to understand something simply is to make it simple enough to understand, destroying much of its essential complexity and causing massive damage - but this seems to be true even without that. e.g. in mathematics it is often useful to switch between different representations because they make different features more salient.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-24-08:27.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-21-08:46.html</id>
    <title>2018-09-21-08:46</title>
    <updated>2018-09-21T08:48:53+01:00</updated>
    <content>

&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-21&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 I just read Richard Gabriel's
 &lt;a href="https://www.dreamsongs.com/Files/Incommensurability.pdf"&gt;
  The Structure of a Programming Language Revolution&lt;/a&gt;.&lt;/p&gt;


&lt;p&gt;
 I don't think I have enough grounding in either lisp or the philosophy of science to fully understand it, and want to do a second and closer read with citation chasing,
but one point really stood out for me:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  I believe that, in general, this view of engineering and science is false: I believe engineering and science are intertwined, and for programming languages and software creation techniques, it’s often the case that engineering precedes science—and it’s very easy to see it.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;...&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  One good example is the steam engine. Engineers began its development while scientists were making their way from the phlogiston theory of combustion to the caloric theory of heat, both today considered hilarious.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 I think this observation is
 &lt;em&gt;
  obviously true&lt;/em&gt;
 , and I'm kicking myself for the fact that I didn't think it was obviously true until it was pointed out to me.&lt;/p&gt;


&lt;p&gt;
 This is also interesting in the context of the way pure and applied maths work. Often physicists are doing interesting mathematical things that are "completely wrong" until a pure mathematician comes along and provides a theory of how they could work.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-21-08:46.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-21-07:04.html</id>
    <title>Some of my favourite PyCon UK talks</title>
    <updated>2018-09-21T08:44:16+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;Some of my favourite PyCon UK talks&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-21&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 The PyCon UK team are amazingly fast at uploading their videos,
which means
 &lt;a href="https://www.youtube.com/channel/UChA9XP_feY1-1oSy2L7acog"&gt;
  the entire conference is now online on youtube&lt;/a&gt;
 (There was some problem with one video but I'm not sure whether that's been resolved, so maybe the entire conference bar one talk).&lt;/p&gt;


&lt;p&gt;
 If I'm being honest, I don't go to PyCon UK for the talks - I go because it's an amazing community. In general I don't get a huge amount out of talks in most conferences I go to.
However I thought there were some especially high quality talks this year,
including some that I not just watched but am going to
 &lt;em&gt;
  rewatch&lt;/em&gt;.&lt;/p&gt;


&lt;p&gt;
 So, here are some of my favourite talks that I would actively recommend.&lt;/p&gt;


&lt;p&gt;
 The two talks that were so good that I intend to rewatch them (mostly to mine for citations and talking points) are:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
&lt;a href="https://youtu.be/2xI42pfz5Ec"&gt;
   Sue Sentance - Teaching programming: What's in a teacher's toolkit&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://www.youtube.com/watch?v=yQo8C_ZHOM8&amp;amp;t=5s"&gt;
   Hannah Hazi - The Knowledge in the Code&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;


&lt;p&gt;
 Sue Sentance's keynote basically made me go "Welp, I need to redesign all my workshops". Hannah's talk had a lot of interesting material on reading code, and I want to follow the references to read more about it - I don't currently need most of the specific advice on legacy code, but reading code is still a very useful skill, especially given Sue's emphasis on its importance for education!&lt;/p&gt;


&lt;p&gt;
 Daniele also gave an impromptu talk about documentation that is going to significantly impact how I write documentation in future.
It was not recorded, but I believe it was a variation on
 &lt;a href="https://www.youtube.com/watch?v=t4vKPhjcMZg"&gt;
  this talk at PyCon Australia&lt;/a&gt;
 (or possibly
 &lt;a href="https://www.youtube.com/watch?v=azf6yzuJt54"&gt;
  this one at PyCon US&lt;/a&gt;
 ).&lt;/p&gt;


&lt;p&gt;
 Talks I would recommend but was already too much of a member of the choir to get that much out of (all of these are by people I'd consider friends or at least friendly acquaintances. This probably isn't coincidental but wasn't deliberate in my selection except in the sense that I always go to friends' talks if they don't clash with anything else that grabs me):&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
  Alex Chan's talks on trust and user safety. His keynote was on
  &lt;a href="https://www.youtube.com/watch?v=B3XxPnbehqQ"&gt;
   Building Trust&lt;/a&gt;
  , and he followed up with another talk
  &lt;a href="https://www.youtube.com/watch?v=B3XxPnbehqQ"&gt;
   Assume Worst Intent&lt;/a&gt;. Alex and I have already talked about some of these issues before, and have broadly similar opinions on them, so I didn't personally get a huge amount out of them, but they're good material and Alex gave great talks on them.&lt;/li&gt;
&lt;li&gt;
  Nikoleta Glynatsi's keynote,
  &lt;a href="https://www.youtube.com/watch?v=z8tL7iqGvnw"&gt;
   Why does a smile make a difference?&lt;/a&gt;
  was a lot of fun. She discussed her research on game theory, and why bats are awesome.&lt;/li&gt;
&lt;li&gt;
  Kristian Glass on
  &lt;a href="https://www.youtube.com/watch?v=AtJ4p27e1r8"&gt;
   How to screw up hiring&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
  Sean Sabbage on
  &lt;a href="https://www.youtube.com/watch?v=U07aAQciHx0"&gt;
   Coming to a shared understanding&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;


&lt;p&gt;
 Misc talks I enjoyed and got something out of but that don't have any particularly insightful categorisation of&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
&lt;a href="https://www.youtube.com/watch?v=R-6n-WGMOU8"&gt;
   The Story of a 53 year old database&lt;/a&gt;
  - I don't think I got anything out of this in the sense of things I will now do differently, but I enjoyed hearing this story. Pairs well with Hannah Hazi's talk.&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://www.youtube.com/watch?v=NvRSDV4edY8"&gt;
   Coding as a Second Career&lt;/a&gt;
  was a fairly personal story but one I think it is helpful to hear.&lt;/li&gt;&lt;/ul&gt;


&lt;p&gt;
 I also thought the lightning talks this year were excellent:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
&lt;a href="https://www.youtube.com/watch?v=hp-1plTKOqc"&gt;
   Saturday lightning talks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://www.youtube.com/watch?v=7w_qgGZM4ao"&gt;
   Sunday lightning talks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://www.youtube.com/watch?v=9j2AhPmjtOQ"&gt;
   Monday lightning talks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://www.youtube.com/watch?v=F5jSUJVymXk"&gt;
   Tuesday lightning talks&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;


&lt;p&gt;
 If you have a burning urge to see me speak (which I'm mostly not doing this year), I gave
 &lt;a href="https://youtu.be/9j2AhPmjtOQ?t=133"&gt;
  a talk about voting system&lt;/a&gt;. I'm mostly pretty happy with how this turned out.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-21-07:04.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-20-13:09.html</id>
    <title>Notes on Tweeting Too Much At Conferences</title>
    <updated>2018-09-20T19:53:10+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;Notes on Tweeting Too Much At Conferences&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-20&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 Well,
 &lt;a href="https://2018.hq.pyconuk.org/"&gt;
  PyCon UK&lt;/a&gt;
 , the best conference, is over for another year. Sad face.&lt;/p&gt;


&lt;p&gt;
 This year I ended up doing something with a surprising amount of impact on my and others' experience of the conference:
I tweeted a
 &lt;em&gt;
  lot&lt;/em&gt;. Yes, I know, even by my standards. I essentially became the unofficial scribe of the conference.
I won't even attempt to embed them, but
 &lt;a href="https://twitter.com/search?f=tweets&amp;amp;vertical=default&amp;amp;q=%23PyConUK%20from%3ADRMacIver%20since%3A2018-09-13%20until%3A2018-09-20&amp;amp;src=typd"&gt;
  here's a search query that will give you everything I tweeted on the conference hash tag for this conference&lt;/a&gt;.&lt;/p&gt;


&lt;p&gt;
 Each day:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
&lt;a href="https://twitter.com/DRMacIver/status/1040497560652271616"&gt;
   Yay! It's time for the annual week of visiting Brodie's to begin. Oh and #PyConUK is on too.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://twitter.com/DRMacIver/status/1041238166806700032"&gt;
   It is with Brodies alone I set my mind in motion. #PyConUK day two begins! Get ready for more fun-filled and eclectic thread of conference highlights.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://twitter.com/DRMacIver/status/1041590037002022912"&gt;
   I pledge allegiance to the coffee of #PyConUK, and to the community for which it stands, one nation undivided under Brodies. Day three begins!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://twitter.com/DRMacIver/status/1041962704444030976"&gt;
   #PyConUK day four. Yr hmbl crspndt is nursing a splitting headache (not a hangover, honest!) and sadly Brodies won't sell me coffee by the pint. Fortunately I'm sure @NikoletaGlyn's keynote will be nice and gentle and contain no advanced mathematics.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://twitter.com/DRMacIver/status/1042324826306879488"&gt;
   Good morning #PyConUK day 5! Is everyone hyped and enthus-[Error. Insufficient coffee. Insert Brodies provided latte to continue. Error. Error. Errrroooooorrrrrrrrr...]-iastic for the sprints today?!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://twitter.com/DRMacIver/status/1042683288693993473"&gt;
   #PyConUK day... six? Wait, there is no #PyConUK day 6. That must mean #PyConUK is... over? I don't understand. What will I live tweet now? ... Maybe some coffee from Brodies will help.&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;


&lt;p&gt;
 Why? Well,
 &lt;a href="https://twitter.com/DRMacIver/status/1040497560652271616"&gt;
  I'd been talking recently about how conference organisers put up with a lot&lt;/a&gt;
 and a point that got made in response to this is that a really helpful thing for attendees to do is tweet about the conference - it helps get more sponsors next year, promotes the ideas of the conference, and generally raises its profile.
This seemed an easy enough thing to do, so I decided to give it a try and got a little bit carried away.&lt;/p&gt;


&lt;p&gt;
 People seemed to
 &lt;em&gt;
  really&lt;/em&gt;
 like me doing this. Especially the organisers - I heard from a lot of them that the running commentary helped them feel more in touch with the conference. So if this achieved nothing else then I'm happy with it.
It also was appreciated by people who weren't able to make the conference, and in a few cases to those who would never have come because they weren't even programmers (though I of course still think they should come)!&lt;/p&gt;


&lt;p&gt;
 People have asked me how I did it, but it's not really complicated: I had a laptop, I touchtype really fast, and I've wasted far too much of my life on Twitter. I had not previously thought the latter was a professional skill, but apparently.&lt;/p&gt;


&lt;p&gt;
 I did have a couple of problems with doing it:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
  Twitter threading is awful. I'm not sure how much it helped people. I think I will probably not bother threading this the next time I do it, and I screwed up the threading in a bunch of places.&lt;/li&gt;
&lt;li&gt;
  Quoting people in real time is basically impossible. I am not a STTR. I ended up paraphrasing a lot and I'm not sure I was clear enough about that.&lt;/li&gt;
&lt;li&gt;
  I tried to distinguish where I was reporting what the speaker was saying versus when I was commenting. I did not always remember to do this.&lt;/li&gt;
&lt;li&gt;
  I would like other people to do this too next year. I'm concerned that this gave people a very DRMacIver-flavoured view of the conference. This is especially relevant because I think for a variety of reasons (mostly that I rarely go to technical talks) I missed out on a lot of first-time speakers.&lt;/li&gt;&lt;/ul&gt;


&lt;p&gt;
 On the whole though, this level of live-tweeting seems to have been popular, and I will probably do it again at future conferences I attend.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-20-13:09.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-20-09:17.html</id>
    <title>Lean Coffee at PyCon UK</title>
    <updated>2018-09-20T12:02:12+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;Lean Coffee at PyCon UK&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-20&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 As part of the PyCon UK sprints I ran a variant lean coffee. It worked really well - we had a bit of an initial slow start, peaked at more people than the group could really handle,
and gradually tapered down to a group of four by the end of the day. This was split over three sessions, during which we discussed 23 different cards.&lt;/p&gt;


&lt;p&gt;
 The variant we ran was based on
 &lt;a href="https://www.drmaciver.com/2016/05/randomizing-lean-coffee/"&gt;
  a previous proposal of mine to randomize lean coffee&lt;/a&gt;. Several people had reported that they ran lean coffees this was after my post, and thought that it worked much better, but I'd never actually got around to trying it, and I thought this was a good opportunity.&lt;/p&gt;


&lt;p&gt;
 In my entirely unbiased opinion, I can confirm that it works much better.
People seemed to really enjoy the format, and many of them reported that they would take it away and try to run it at work.
For the third session I was basically wiped out (scribing, moderating,
 &lt;em&gt;
  and&lt;/em&gt;
 discussing at the same time was something I could
 &lt;em&gt;
  do&lt;/em&gt;
 , but it was very high energy),
so I passed on the duties - one person took up moderating, another took up scribing, and there were no problems with doing so, so the system seems to be easy enough to transmit to other people, which is a win.&lt;/p&gt;


&lt;h3&gt;
 The Conversation&lt;/h3&gt;


&lt;p&gt;
 The point of the system is to provide a structured conversation about a large range of topics in a very short space of time.
We select a card (more on that below). This has a discussion prompt (often a question) and the name of the person who proposed it.
At this point anyone may veto discussing the card. People shouldn't veto cards just because they're uninterested, the veto system exists for topics that would make you unhappy or uncomfortable to have discussed.
This never actually came up in practice. I don't know if that is because people didn't feel empowered to veto or because it was never necessary - I
 &lt;em&gt;
  think&lt;/em&gt;
 it is the latter,
but I don't feel like people would have necessarily been willing to veto if they needed to.&lt;/p&gt;


&lt;p&gt;
 The proposer gets a (short!) opportunity to elaborate on the theme, then the group votes on whether they want to discuss it.
If a strict majority raise their hands, a 5 minute clock is started, and the group discusses it until the time runs out.
At that point, the group votes whether they want to continue it. If a strict majority does, a new 5 minute timer is started,
and the discussion continues.
The subject may not be extended a second time.&lt;/p&gt;


&lt;h3&gt;
 Selecting the Cards&lt;/h3&gt;


&lt;p&gt;
 At the beginning everyone writes down as many cards as they like and these are put in a central pile.
These are shuffled, and cards are selected by drawing from the top of the pile.
Anyone can insert a new card at any time they like, at which point the deck is reshuffled.&lt;/p&gt;


&lt;p&gt;
 We adopted a system that I like in principle and think worked reasonably well but maybe ended up a bit too complicated - in order to ensure everyone got a good opportunity to seed the conversation,
we deprioritised cards from people who had recently had their topic discussed.&lt;/p&gt;


&lt;p&gt;
 The way this worked was that when a card had been discussed we put it face up on the table.
If a card came up from someone whose name was already on the table, we put it aside. Once we had been through the whole deck,
we stacked the cards that were face up so that they were no longer visible,
shuffled the cards that had been put aside, and started the process again.&lt;/p&gt;


&lt;h3&gt;
 Details&lt;/h3&gt;


&lt;ul&gt;
&lt;li&gt;
  I found it very easy to get cards confused, so I started marking cards that we had completed with a cross or a tick on the back so that we didn't mix them up.&lt;/li&gt;
&lt;li&gt;
  One person ended up dominating the conversation a bit (he acknowledged this and welcomed the feedback). We adopted a convention that I would just start waving at him when I thought he'd been talking too long. I actually think we should have adopted this as a universal convention right at the beginning, with everyone feeling empowered to do it - there were almost certainly one or two times when someone should have been waving at
  &lt;em&gt;
   me&lt;/em&gt;. Honestly I want to adopt this convention for all conversations, lean coffee or not, because I definitely have some friends who it would be useful for (in a constructive way! I think all of the people I have in mind would love this convention).&lt;/li&gt;
&lt;li&gt;
  I tended to interrupt people mid-sentence when the time came up, but I should probably have started waving at them and then cut them off if they didn't wrap up within a sentence or two.&lt;/li&gt;
&lt;li&gt;
  A nice thing about this format was that it was really easy for people to drop in and out. This created the question of what we should do when a card whose author has left comes up. We initially said we should just discard them, but then decided to vote on them anyway, but we never actually voted in favour of discussion, so I think we were probably right the first time.&lt;/li&gt;
&lt;li&gt;
  I did note-taking in a Google doc for most of it, passing over to one of the other attendees for the third session until he left, at which point I took over again. It was
  &lt;em&gt;
   much&lt;/em&gt;
  easier taking notes when I wasn't also moderating, and I would rather omit the note taking activity altogether than try to combine it with moderation duties in future (Note: Be careful when asking for volunteers to be note-taker. This is one of those things that instantly gets gendered, and a woman will probably end up doing it by default if you ask for volunteers, so it's best to either assign the role or do it by lot or something. That being said our volunteer note-taker in the third round was a man. On the third tentacle, PyCon UK attendees are lovely and are probably less prone to this failure mode).&lt;/li&gt;
&lt;li&gt;
  We wrote down everyone's email addresses on a card and I'm going to email the notes around to give people an opportunity to sanitize (I already carefully omitted a few things that I didn't think should be public) and then I'll publish the notes publicly.&lt;/li&gt;
&lt;li&gt;
  We didn't clarify the meaning of the voting system until quite late, but an important distinction is that you should raise your hand if you
  &lt;em&gt;
   want&lt;/em&gt;
  to discuss the topic, not just if you're
  &lt;em&gt;
   happy&lt;/em&gt;
  to discuss the topic.&lt;/li&gt;&lt;/ul&gt;


&lt;h3&gt;
 Things that didn't quite work&lt;/h3&gt;


&lt;ul&gt;
&lt;li&gt;
  I wasn't a fan of the show of hands system. I would like simultaneous, and maybe anonymous, voting - there was a lot of social pressure to conform I think, with people looking at other people before deciding what to vote. I would also like it to be easier to count, as it turns out that I am bad at counting majority voting in a group that is constantly changing and includes me.&lt;/li&gt;
&lt;li&gt;
  I thought people were too nice early on - we had a lot of unanimous votes in favour of discussion. Some of these were legitimately high quality topics, but I feel like the unanimity was implausible for some of them. I'm going to think about mechanisms for offsetting this, but I think simultaneous voting might be enough.&lt;/li&gt;
&lt;li&gt;
  There is definitely a size limit on how large the group can get before this gets a bit unwieldy. Four people was viable but maybe a bit too small. Once we were past ten it was definitely too large. The sweet spot is probably somewhere in the five to eight range.&lt;/li&gt;
&lt;li&gt;
  I'd like a way to encourage some of the more quiet members of the group to speak as well as to encourage the louder members not to - there were some people in the group (mostly women) who I was pretty sure had interesting things to say but didn't feel able to (possibly due to being unable to get a word in edgewise). They may also just have been enjoying listening, I don't know - I know some people explicitly came just to listen in. Unfortunately they had to leave midway through, so I wasn't able to ask them. I'll do so when I email them.&lt;/li&gt;
&lt;li&gt;
  We had a veto system - anyone was allowed to veto a card if they didn't want it discussed. This was introduced halfway through when&lt;/li&gt;&lt;/ul&gt;


&lt;h3&gt;
 In Future&lt;/h3&gt;


&lt;p&gt;
 A lot of people came away from this going "This was great, I need to run some of these". Including me! Despite the fact that several people have used my variations on lean coffee before, this is actually the first time
 &lt;em&gt;
  I&lt;/em&gt;
 have. I'd already been thinking I'd like to run one of these at Imperial, and now I'm even more sure I would like to do that.&lt;/p&gt;


&lt;p&gt;
 We also talked about maybe running some of these earlier in PyCon UK next year. They were a great generator of high insight conversations, and I think provided some really nice social connections with people that it would have been great to form more than six hours before we had to say "Well, see you in a year I guess!".&lt;/p&gt;


&lt;p&gt;
 In general, a lot of the things we talked about involved things that might be nice for the conference next year (not criticisms! Almost all of the form "PyCon UK is great, but here's an idea that might make it
 &lt;em&gt;
  even greater&lt;/em&gt;
 ). I'm probably going to (finally) get involved in the organisation of PyCon UK next year and once people have decompressed a bit and are ready to receive feedback,
I'm going to write a summary of what those were and circulate it.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-20-09:17.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-13-13:07.html</id>
    <title>2018-09-13-13:07</title>
    <updated>2018-09-14T16:38:31+01:00</updated>
    <content>

&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-13&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 This is a fairly involved example which I don't expect to convince anyone,
and is just the result of me thinking through some things.&lt;/p&gt;


&lt;p&gt;
 Suppose we have a bunch of propositions \(A_1, \ldots, A_n\).
We know a priori that \(A_i \implies A_j\) is false for \(i &amp;gt; j\),
but do not know whether there are any forwards implications.
We have an "implication oracle" which acts as follows:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  It has access to a number of "primitive implications" of the form \(A_i \implies A_j\).
   These implications are considered to be unreliable: They are true with probability \(1 - \epsilon\),
   but with probability \(\epsilon\) they provide no information (i.e. the proposition may be true, we just don't know that).
   These errors are independent.&lt;/li&gt;
&lt;li&gt;
  We may query the proof oracle with any pair \(A_i, A_j\) and it tells us the probability of there being a valid proof of \(A_i \implies A_j\) given only a true set of primitive implications.&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 We also have a "plausibility oracle" that gives us our prior probabilities of \(p_i = A_i\) being true.&lt;/p&gt;


&lt;p&gt;
 Suppose we want to define an agent that chooses between these propositions, with a reward if the proposition chosen is true.&lt;/p&gt;


&lt;p&gt;
 We can define a Bayesian agent that picks whichever of \(k \in \{i, j\}\) has the highest posterior probability\((1 - \epsilon) P(A_k | A_i \implies A_j) + \epsilon p_i\).&lt;/p&gt;


&lt;p&gt;
 The problem with this agent is that it is not transitive!&lt;/p&gt;


&lt;p&gt;
 Consider the following example: Let \(\epsilon = 0.11\),
and suppose we have the primitive implications \(A_1 \implies A_2\), \(A_2 \implies A_3\) and the prior probabilities \(p_1 = 0.2\), \(p_2 = p_3 = 0.01\).&lt;/p&gt;


&lt;p&gt;
 Some boring computation that I can't be bothered to carry over to text results in the above agent preferring \(A_2\) to \(A_1\), \(A_3\) to \(A_2\) and \(A_1\) to \(A_3\).
The reason is that the strength of the implication \(A_1 \implies A_3\) is weaker than that of either the individual implications, as it is \(1 - (1 - \epsilon)^2 \approx 0.21\).
Thus even though we still "believe" this implication, the weaker strength of it makes our prior probabilities overwhelm it.&lt;/p&gt;


&lt;p&gt;
 Now, this paradox goes away if we have access to the inner workings of the implication oracle:
If we know all of the primitive implications a priori then we can just calculate the "true" posterior probabilities across all possible combinations of whether the implications are valid or not,
and pick the answer with the highest posterior,
but this effectively requires us to know the entire space of propositions in advance.&lt;/p&gt;


&lt;p&gt;
 I think that
 &lt;em&gt;
  no&lt;/em&gt;
 strategy which has to decide based only on the answer of those two oracles on the current pair can dominate this strategy,
because this is the dominant strategy for the case where there are only two propositions and the oracles are exactly correct about the probabilities,
but I haven't checked the details of this argument.&lt;/p&gt;


&lt;p&gt;
 So what this means in practice is that if some elements of your reasoning are "screened off" from you as black boxes,
and you do not have full knowledge in advance of the set of available options,
even a fully VNM-rational Bayesian reasoner will necessarily exhibit intransitive preferences.&lt;/p&gt;


&lt;p&gt;
 However! Note that
 &lt;em&gt;
  this does not mean that they can be Dutch Booked&lt;/em&gt;.
The reason for this is that the proper Bayesian reasoner will update their posteriors about propositions as they are forced to make choices.
This may in fact mean that the time varying preferences they make are actually transitive, at least in the limit, while their instantaneous preferences are not.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-13-13:07.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-13-11:02.html</id>
    <title>Notes from reading "Rigour and Structure"</title>
    <updated>2018-09-13T11:02:00+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;Notes from reading "Rigour and Structure"&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-13&lt;/dd&gt;
&lt;/dl&gt;


&lt;blockquote&gt;
&lt;p&gt;
  The distinctive definition-theorem-proof format of professional publications is the single most conspicuous feature of mathematical practice.&lt;/p&gt;
&lt;p&gt;
  The quality whose presence in a purported proof makes it a genuine proof by present-day journal standards, and whose absence makes the proof spurious in a way that if discovered will call for retraction, is called rigor.&lt;/p&gt;
&lt;p&gt;
  The assessment of purported proofs for rigor is generally not the topic of a separate course.&lt;/p&gt;
&lt;p&gt;
  Mathematicians’ views on the nature of rigor and proof may more often be expressed in aphorisms and epigrams, in anecdotes and jokes, for instance, of the common ‘an engineer, a physicist, and a mathematician…’ genre, than in formal theoretical pronouncements.&lt;/p&gt;
&lt;p&gt;
  contrary to the dictum that a proof is what convinces, not everything that convinces is a proof&lt;/p&gt;
&lt;p&gt;
  such methods, and other aspects of early modern mathematics, also exemplify what I will call reliance on generic reasoning. By this I mean performing calculations or manipulations that usually or generally work but sometimes or exceptionally fail, treating as universally applicable techniques that are — and may be known to be — only applicable in favorable cases, in the hope and belief that the case in which one is interested is one of the favorable ones, but without any rigorous justification for supposing this to be so.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 On uniform continuity:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  The distinction is a matter of the order of quantifiers (all-all-exists vs all-exists-all, or in logicians’ notation \(\forall\forall\exists\) and \(\forall\exists\forall\) cannot be made unless the quantifiers have been made explicit and not left implicit in expressions like ‘close as desired’ or ‘close enough’.&lt;/p&gt;
&lt;p&gt;
  Proofs depending on calculations, in particular, are especially likely to go wrong if the calculations are long and complicated enough.&lt;/p&gt;
&lt;p&gt;
  Rigorism imposes no restriction on definitions other than rigor, and leaves one perfectly free to explore definitions that may at first seem complicated and unnatural, if there are grounds for hoping they will be useful and fruitful.&lt;/p&gt;
&lt;p&gt;
  Owing to the freedom to introduce useful new notions regardless of simplicity or naturalness, so long only as they are rigorously defined, nothing need be lost.&lt;/p&gt;
&lt;p&gt;
  Time and again during the early twentieth century non-rigorous but useful methods introduced by physicists or engineers were found to have rigorous counterparts, the development of which at the very least clarified the scope and limits of the techniques, and more often than not had other side benefits as well.&lt;/p&gt;
&lt;p&gt;
  Brouwer’s mysticism led him to believe that mathematics is largely an incommunicable mental activity, not to say an ineffable meditative practice, and as a result the rules of intuitionist game were never clearly articulated&lt;/p&gt;
&lt;p&gt;
  Deduction and Deducibility. Here one must confront the fact that if one looks to logic textbooks, though one will find an agreed characterization of logical consequence, which I have already discussed, one finds no agreed characterization of logical deduction.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 The point being that logic has more to say about the process that determines what the true statements are than how to actually determine the true statements. This is analagous to the enumeration vs predicate view of a set.&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  [Mathematical logic] resembles mathematical physics and mathematical economics in that its models are highly idealized. In particular, as I have been emphasizing, it gives a quite good model of mathematical deducibility, but a much poorer model of mathematical deduction.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 The point being that formal logic is a kind of "spherical cow in a vacuum" version of actual logic performed by real mathematicians.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-13-11:02.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-10-13:14.html</id>
    <title>2018-09-10-13:14</title>
    <updated>2018-09-10T13:18:33+01:00</updated>
    <content>

&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-10&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 (Lightly edited)
 &lt;a href="https://twitter.com/DRMacIver/status/1039106038425903104"&gt;
  exchange from Twitter&lt;/a&gt;&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  Me: These days I think I'm in favour of a hung parliament. *checks dictionary* Oh that's not what it means. Never mind.&lt;/p&gt;
&lt;p&gt;
  Jack: Are you fishing for "hanged parliament"?&lt;/p&gt;
&lt;p&gt;
  Me: No, people are hanged.
  &lt;em&gt;
   Animals&lt;/em&gt;
  are hung.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 I don't actually ascribe to this worldview (I believe very strongly that dehumanizing your opponents is morally indefensible no matter how evil you think they are),
and there are literally dozens of MPs who I would be sad if they were hanged,
but sometimes my inner evil overlord just insists on coming out to play.&lt;/p&gt;


&lt;p&gt;
 Also I really want to use this line in a story now.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-10-13:14.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-10-09:52.html</id>
    <title>What might a continuous rational agent look like?</title>
    <updated>2018-09-10T10:32:35+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;What might a continuous rational agent look like?&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-10&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 In a
 &lt;a href="https://notebook.drmaciver.com/posts/2018-09-09-21:02.html"&gt;
  previous post&lt;/a&gt;
 I said I didn't care much about this problem,
which obviously nerd-sniped me into thinking about it.&lt;/p&gt;


&lt;p&gt;
 So, the question is: We have a "rational" agent which is making choices over pairs of lotteries \(\mathcal{L}\),
and it does this in terms of a function \(\tau : \mathcal{L}^2 \to [0, 1]\) where \(\tau(u, v)\) means "the probability of choosing \(u\) in preference to \(v\).&lt;/p&gt;


&lt;p&gt;
 We had the nice (ish) VNM theory for physically impossible discontinuous rational agents,
but what should the axioms for a continuous rational agent look like?&lt;/p&gt;


&lt;p&gt;
 The following seem like they should obviously hold:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  \(\tau(L, M) = 1 - \tau(M, L)\).&lt;/li&gt;
&lt;li&gt;
  If we define \(L \prec M\) as meaning \(\tau(L, M) = 1\) then \(\preceq\) should be a partial order.&lt;/li&gt;
&lt;li&gt;
  If we define \(L \tilde M\) as meaning \(\tau(L, M) = \frac{1}{2}\) then whenever \(L \tilde L', M \tilde M'\) we have \(\tau(L, M) = \tau(L', M')\).&lt;/li&gt;
&lt;li&gt;
  If \(\tau(L, pL + (1 - p) M)\) should be monotonic in \(p\), and whenever it is non-constant that monotonicity should be strict.&lt;/li&gt;
&lt;li&gt;
  For any pure lotteries (that is, lotteries which take a single outcome with probability \(1\)) \(\tau(L, M) \in \{0, 1, \frac{1}{2}\). i.e. for any concrete outcomes the agent either has a strict preference or is indifferent between them.&lt;/li&gt;
&lt;li&gt;
  \(\tau(L, pM + (1 - p)N) \geq \min \tau(L, M), \tau(L, N)\)&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 Together with the continuity requirement, these give us roughly the equivalence of the first four
 &lt;a href="https://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Morgenstern_utility_theorem"&gt;
  VNM axioms in Wikipedia's ordering&lt;/a&gt;.&lt;/p&gt;


&lt;p&gt;
 In contrast, the independence requirement obviously doesn't and can not hold in any meaningful sense for such an agent.
Pick two lotteries with \(L \prec M\). Consider \(\tau(pL + (1 - p)N, pM + (1 - p)N)\).
This is a continuous function of \(p\), and when \(p = 0\) it is equal to \(\frac{1}{2}\),
therefore for any \(\epsilon &amp;gt; 0\) there must be some \(0 &amp;lt; p &amp;lt; 1\) we must have \(\tau(pL + (1 - p)N, pM + (1 - p)N) &amp;lt; \epsilon\),
which breaks independence in a very strong way.&lt;/p&gt;


&lt;p&gt;
 I think this lack of independence is in some sense the "essential difference" between a continuous and a discrete rational agent.&lt;/p&gt;


&lt;p&gt;
 I'm not sure the above are the full set of axioms required. They feel a bit weak - I think more may need to be said about the relationships between \(\tau\) values over convex combinations of lotteries.&lt;/p&gt;


&lt;p&gt;
 However,
the following two examples might be illuminating in terms of things that obviously
 &lt;em&gt;
  should&lt;/em&gt;
 be considered rational agents:&lt;/p&gt;


&lt;p&gt;
 Let \(\mu\) be some utility function over outcomes and let \(\alpha: [0, \infty) \to [0, 1]\) be monotonic decreasing with \(\alpha(0) = 1\) and \(\alpha(x) \to 0\) as \(x \to \infty\).
If \(E(\mu(L)) &amp;gt; E(\mu(M))\) then let \(\tau(L, M) = \frac{1 - \alpha(E(\mu(L)) - E(\mu(M)))}{2}\).
Otherwise extend according to the requirement that \(\tau(L, M) = 1 - \tau(M, L)\).&lt;/p&gt;


&lt;p&gt;
 The idea is basically that \(\alpha\) acts as a decision procedure about whether it's worth finding out more information - it represents the probability of giving up and flipping a coin. You run this procedure by observing to increasingly high precision until you either know that alpha is large enough that you should give up (based on a non-deterministic choice of doing so) or which side of the border you're on.&lt;/p&gt;


&lt;p&gt;
 Another procedure that I think can not be realised as an instance of that but should still be considered rational is how a logically omniscient Bayesian agent who is only able to access the lotteries through sampling might behave.
You start with some prior distribution over lotteries (maybe an improper one) and query the sampler for each, with some cost function \(\alpha: \mathbb{N} \to [0, \infty)\) for how expensive it is to evaluate \(n\) samples (probably \(\alpha\) is a linear function). You stop and choose as soon as you hit a point where your expected value (under your posterior distributions) of acquiring more information is strictly less than the expected value of choosing one of the outcomes.&lt;/p&gt;


&lt;p&gt;
 I don't want to suggest that either of the two above are the
 &lt;em&gt;
  only&lt;/em&gt;
 possible rational agents in such circumstances.
I suspect in fact that there's a much broader diversity of behaviour possible than for VNM rational agents,
which might make any axiomatic classification hard.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-10-09:52.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-10-08:45.html</id>
    <title>Programming vs Mathematics</title>
    <updated>2018-09-10T09:52:44+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;Programming vs Mathematics&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-10&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 Programming: "Custom operators and single letter variable names? Why so terse? Bytes are cheap! Suspish. Not sure if want. Code should be optimised for reading, not writing!"&lt;/p&gt;


&lt;p&gt;
 Mathematics: "Let \(\alpha, \gamma, \beta\) be as in theorem 17.1. If \(\gamma \wedge \beta\) is a normal R-domain, then \(\mu(\alpha \oplus \gamma) \dagger \beta\) is quasi-uniform."&lt;/p&gt;


&lt;p&gt;
 (No, that's not an actual quote and those terms don't really mean anything)&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-10-08:45.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-09-21:02.html</id>
    <title>Physical and Topological Limitations to Rational Choice</title>
    <updated>2018-09-09T22:28:23+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;Physical and Topological Limitations to Rational Choice&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-09&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 Epistemic status: Confident.&lt;/p&gt;


&lt;p&gt;
 Attention conservation notice: So much inside baseball.&lt;/p&gt;


&lt;p&gt;
 Context: This is something I've known about for a while but couldn't find a concise write-up of that I had previously written and still liked,
so I thought I'd just rewrite it here.&lt;/p&gt;


&lt;hr/&gt;


&lt;p&gt;
 The
 &lt;a href="https://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Morgenstern_utility_theorem"&gt;
  Von-Neumann-Morgenstern utility theorem&lt;/a&gt;
 states that if you ask people to choose between finite lotteries over outcomes,
any "rational" behaviour looks like picking based on whichever gives the greatest expected utility according to some utility function over the outcomes.&lt;/p&gt;


&lt;p&gt;
 I have a number of objections to this idea,
but my main one is this:
Regardless of the axioms you choose for rationality,
it's physically impossible to implement an agent that can express the sort of total order over lotteries that VNM rationality is a theorem about,
even if you grant the existence of logically omniscient agents (you can do it if you grant the existence of
 &lt;em&gt;
  actually&lt;/em&gt;
 omniscient agents).&lt;/p&gt;


&lt;p&gt;
 Why?&lt;/p&gt;


&lt;p&gt;
 Well, suppose we have some total preorder \(\preceq \subseteq \mathcal{L}^2\), where \(\mathcal{L}\) is the set of lotteries over some finite set of outcomes.
Take this total order and define the choice function \(\tau : \mathcal{L}^2 \to \{-1, 0, 1\}\) where \(\tau(u, v) = 0\) if \(u \preceq v\) and \(v \preceq u\),
else if \(u \prec v\) then \(\tau(u, v) = -1 = -\tau(v, u)\). i.e. \(\tau\) is a function determining whether we strictly prefer one or are indifferent between the two.&lt;/p&gt;


&lt;p&gt;
 Any choice that a physical agent makes must be based on a finite (but not necessarily bounded up front) set of observations.
Each of those observations can only give you information about the world up to some non-zero (but potentially arbitrarily small) tolerance.
In particular, if we have lotteries \(u_1 \preceq u_2\), there is some \(\epsilon &amp;gt; 0\) such that if \(d((u_1, u_2), (v_1, v_2) &amp;lt; \epsilon\),
we must have \(\tau(v_1, v_2) = \tau(u_1, u_2)\), because we only ever looked at \(u_1, u_2\) up to some finite precision.&lt;/p&gt;


&lt;p&gt;
 In particular this means that \(\tau: \mathcal{L}^2 \to \{-1, 0, 1\}\) is a continuous function!&lt;/p&gt;


&lt;p&gt;
 Unfortunately, \(\mathcal{L}^2\) is a connected topological space and \(\{-1, 0, 1\}\) is totally disconnected.
Thus any continuous function must be constant. We know that \(\tau(u, u) = 0\), so we must have \(\tau(u, v) = 0\) for all \(u, v\).
i.e. the only physically possible total preorder that we can express is the one that is totally indifferent between lotteries.&lt;/p&gt;


&lt;p&gt;
 If the above argument makes no sense to you, another way to look at it is that you need to know \(u\) and \(v\) to infinite precision at the boundary.
If you are on a boundary point where \(\tau(u, v) = 0\), moving slightly in the direction of \(u \prec v\) immediately forces your hand,
so you cannot satisfy that continuity property at the boundary.&lt;/p&gt;


&lt;p&gt;
 This problem can be made to go away by removing the indifferent set from the set of lotteries you consider - it's perfectly physically possible to distinguish the lotteries if you know a priori that you will definitely have a preference for one of them.
Unfortunately there are several problems with this:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  Where does that a priori knowledge come from? It's obviously not true in general - you have to somehow avoid ever being asked to choose between a lottery and itself.&lt;/li&gt;
&lt;li&gt;
  The VNM axioms rely crucially on the use of indifference in the continuity axiom.&lt;/li&gt;
&lt;li&gt;
  The implementation of such a choice function is still physically fraught, because as you approach the boundary the amount of precision you require to decide tends to infinity.&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 It is possible that there is some cunning workaround that lets you rescue VNM choice theory, but I find it very implausible that this is the case.
The basic requirement that you construct a discrete function of the world is intrinsically aphysical, and it seems very hard to rescue that.&lt;/p&gt;


&lt;p&gt;
 I have yet to sit down and think through exactly what I would like in its place in any great depth, mostly because nobody except me cares about this problem and I don't care enough to pursue it solo,
but my preferred primitive is to replace the choice function with a continuously varying choice probability, so instead you have a function  \(\tau: \mathcal{L}^2 \to [0, 1]\), where \(\tau(u, v)\) is the probability of choosing \(u\) over \(v\),
and \(\tau(v, u) = 1 - \tau(u, v)\).
This neatly side steps all of the problems with using a discrete choice function, because you don't need to know the outcome probabilities with infinite precision in order to make your choice, and \([0, 1]\) is a connected topological space so, unlike discrete choices, it's perfectly possible to construct such functions.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-09-21:02.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-09-19:26.html</id>
    <title>2018-09-09-19:26</title>
    <updated>2018-09-09T19:48:39+01:00</updated>
    <content>

&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-09&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 I previously wrote
 &lt;a href="https://www.drmaciver.com/2014/10/order-dependence-in-preference-elicitation/"&gt;
  a post about NP-hardness in decision theory&lt;/a&gt;.
On rereading it, I think its tone really doesn't help its point at all, so I thought I'd quickly write up a more formal version.&lt;/p&gt;


&lt;p&gt;
 The basic point is this: If you don't assume computation is free, NP-hard problems prove an interesting barrier to decision making that satisfies the classical "rationality" axioms.&lt;/p&gt;


&lt;p&gt;
 Suppose you have an NP-hard problem (say a SAT instance), \(S\), and are offered a choice between the following three options:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  A certain reward \(R_1\).&lt;/li&gt;
&lt;li&gt;
  A reward \(R_2 &amp;gt; R_1\) if a particular solution \(x\) witnesses that \(S\) is satisfiable.&lt;/li&gt;
&lt;li&gt;
  A reward \(R_3 &amp;gt; R_2\) if \(S\) is satisfiable.&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 Arrange the values such that \(\alpha_2 \ll R_2 - R_1 &amp;lt; R_3 - R_1 &amp;lt; \alpha_3\),
where \(\alpha_i\) is the cost of solving the computational problem that would allow you to determine the pay off of these choices.
i.e. the difference in reward is big enough that it is worth evaluating one solution, but small enough that it's not worth solving the problem.&lt;/p&gt;


&lt;p&gt;
 You should always strictly prefer \(3\) to \(2\),
because under every circumstance where \(2\) pays anything, \(3\) pays a larger amount.&lt;/p&gt;


&lt;p&gt;
 Additionally, you should prefer \(2\) to \(1\) if and only if \(x\)
 &lt;em&gt;
  is&lt;/em&gt;
 a witness - because it's cheap enough to check,
you just acquire the information and be done with it (if you want to quibble about expected payoffs, assume that \(\alpha_2\) is really really small).&lt;/p&gt;


&lt;p&gt;
 However, you should also prefer \(1\) to \(3\),
because the possible reward you can gain by solving the problem is not worth the cost,
so you should take the certain reward instead.&lt;/p&gt;


&lt;p&gt;
 This means that if \(x\) is chosen so that it
 &lt;em&gt;
  is&lt;/em&gt;
 a witness,
you have an intransitive preference \(2 &amp;gt; 3 &amp;gt; 2 &amp;gt; 1\).&lt;/p&gt;


&lt;p&gt;
 Another way of thinking about this is that the choices over this problem are not
 &lt;em&gt;
  subset consistent&lt;/em&gt;.
The choice you make from \(\{1, 2, 3\}\) in the case that \(x\) is a solution is either \(3\) - evaluating \(2\) tells you that it's worth choosing \(3\) over \(1\),
so you can skip paying the cost and just choose the good option. In contrast, your choice when picking from \(\{1, 3\}\) would be \(2\) - removing a value that was not the chosen answer has caused your opinion to flip.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-09-19:26.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-08-10:59.html</id>
    <title>2018-09-08-10:59</title>
    <updated>2018-09-08T11:34:11+01:00</updated>
    <content>

&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-08&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 Terry Tao has an interesting series of posts:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
&lt;a href="https://terrytao.wordpress.com/2009/11/05/the-no-self-defeating-object-argument/"&gt;
   The “no self-defeating object” argument&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://terrytao.wordpress.com/2010/10/18/the-no-self-defeating-object-argument-revisited/"&gt;
   The “no self-defeating object” argument, revisited&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://terrytao.wordpress.com/2010/11/02/the-no-self-defeating-object-argument-and-the-vagueness-paradox/"&gt;
   The “no self-defeating object” argument, and the vagueness paradox&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;


&lt;p&gt;
 The idea of the "no self-defeating object" argument is, roughly, that suppose there were some some object that "defats" all objects,
then it would also defeat itself, and thus cannot exist. It's a specific form of reductio ad absurdum,
and can be applied to many different forms of "object" and notions of "defeat".&lt;/p&gt;


&lt;p&gt;
 Examples:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
  There is no largest number ("defeat" here meaning something like \(\geq n + 1\)).&lt;/li&gt;
&lt;li&gt;
  There is no set of sets ("defeat" meaning \(\in\)).&lt;/li&gt;&lt;/ul&gt;


&lt;p&gt;
 In the second post he outlines how we can almost always turn these arguments instead into "every object is defeated by some other object", and this often works better for people uncomfortable with proof by contradiction (which is most non-mathematicians).&lt;/p&gt;


&lt;p&gt;
 The third post is especially interesting in the light of
 &lt;a href="https://notebook.drmaciver.com/posts/2018-09-08-08:06.html"&gt;
  my recent post about the nature of mathematics&lt;/a&gt;
 ,
in that it observes that an unusual characteristic of mathematics is that mathematical statements are intended to have a precise meaning in a way that natural language statements typically are not.&lt;/p&gt;


&lt;p&gt;
 This suggests the following modified definition:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  Mathematics is the study of unambiguous statements about hypothetical objects&lt;/p&gt;&lt;/blockquote&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-08-10:59.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-08-10:40.html</id>
    <title>2018-09-08-10:40</title>
    <updated>2018-09-08T10:49:21+01:00</updated>
    <content>

&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-08&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 The
 &lt;a href="http://cs.brown.edu/courses/csci0190/2018/laptop-policy.html"&gt;
  laptop policy&lt;/a&gt;
 from Shriram Krishnamurthi's "Accelerated Introduction to Computer Science" class is an interesting collection of resources on laptop usage in class.&lt;/p&gt;


&lt;p&gt;
 I've definitely found that it is true that longhand note taking improves my retention and focus while device usage immediately kills it. The point about device usage distracting
 &lt;em&gt;
  other&lt;/em&gt;
 people around you is particularly interesting though.&lt;/p&gt;


&lt;p&gt;
 I feel like imposing this sort of rule is a deeply unpopular move in my social group,
but I think they're mostly wrong about that.
OTOH this is very much a question of competing access needs and I'm not sure what the best way to resolve it is.`&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-08-10:40.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-08-10:39.html</id>
    <title>2018-09-08-10:39</title>
    <updated>2018-09-08T10:39:50+01:00</updated>
    <content>

&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-08&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
&lt;a href="https://how.complexsystems.fail/"&gt;
  How Complex Systems Fail&lt;/a&gt;
 is very good. A lot of the citations have been on my reading stack for a while,
and given that I'd already deprioritised them I'm now inclined to just not bother now that I've read the TLDR.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-08-10:39.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-08-08:06.html</id>
    <title>2018-09-08-08:06</title>
    <updated>2018-09-08T10:38:49+01:00</updated>
    <content>

&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-08&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 I've been trying to come up with a definition of mathematics that I like and think would be useful in the course of teaching people mathematics.&lt;/p&gt;


&lt;p&gt;
 This is of course a big ask, as
 &lt;a href="https://en.wikipedia.org/wiki/Definitions_of_mathematics"&gt;
  according to Wikipedia there is a great deal of spirited philosophical debate on the subject&lt;/a&gt;
 ,
but on the other hand I think most of those definitions are
 &lt;em&gt;
  terrible&lt;/em&gt;
 , so I don't feel too bad about trying myself.&lt;/p&gt;


&lt;p&gt;
 The one I dislike the least from that list is
 &lt;a href="http://mathworld.wolfram.com/Mathematics.html"&gt;
  Eric Weisstein's&lt;/a&gt;
 :&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  Mathematics is a broad-ranging field of study in which the properties and interactions of idealized objects are examined.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 It's a bit long-winded but mostly captures the sense I want. The phrasing I've been thinking of in preference is something more like:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  Mathematics is the rigorous study of hypothetical objects.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 The idea is that in mathematics we're not really concerned with real life physical objects,
we can just say "Suppose there were objects satisfying the following properties, what can we reliably say about them?"&lt;/p&gt;


&lt;p&gt;
 Sometimes those objects are ones that can easily be realised as real physical objects. For example the
 &lt;a href="https://en.wikipedia.org/wiki/Mathematical_chess_problem"&gt;
  Mathematics of Chess&lt;/a&gt;
 studies hypothetical chess boards,
but those hypothetical chess boards can easily be realised by going out and buying an actual physical chessboard.
However, many of them can not be. There is no way to construct a real physical set of natural numbers,
but from a mathematical point of view that's OK - we can reason about the properties of the hypothetical one perfectly well.&lt;/p&gt;


&lt;p&gt;
 There are a couple axes of variation on which people differ about the nature of mathematics:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  Is informal mathematics legitimate, or should all mathematics be considered a (possibly bad) approximation to an entirely formal set of reasoning rules?&lt;/li&gt;
&lt;li&gt;
  Are some hypothetical objects privileged as the true platonic mathematical objects in a way that others are not?&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 I think this definition is more or less compatible with any combination of answers to these questions:
Formalism is a question of what we count as "rigorous",
and even if there
 &lt;em&gt;
  are&lt;/em&gt;
 platonic mathematical objects, we still must study them
 &lt;em&gt;
  as if&lt;/em&gt;
 they were hypothetical because by its very nature we cannot have access to the platonic realm.&lt;/p&gt;


&lt;p&gt;
 Traditionally the answers to these questions have been correlated more than I think is logically required:
The formalist position is that mathematics doesn't real and that everything is formal manipulation of symbols,
while the platonist position is that we are seeking to discover truths about the ideal platonic realm and the truths are what matter regardless of how we reason about them.&lt;/p&gt;


&lt;p&gt;
 I think there's room for a third position though, which is that formalism is interesting but not strictly required, but the objects we describe have no inherent reality and really are allowed to be purely hypothetical.
I've historically self-described as a formalist, but I think this third position is closer to my true beliefs:
I don't think Platonism is philosophically defensible,
but I do think there is a lot of interesting mathematical content and activity that cannot be adequately captured by the formalist position.&lt;/p&gt;


&lt;p&gt;
 In many ways this third position is that of Lakatos in his "Proofs and Refutations".
Most of the interesting mathematics happens in a fuzzy middle-ground where you are making your definitions precise enough to be defensible.
This could go all the way to formalism, but it doesn't have to.&lt;/p&gt;


&lt;p&gt;
 The mathematics of chess is again an interesting test case here:
Chess is a purely arbitrary set of rules. I think it would be hard to argue that there is a platonic game of chess that is in some essential way different than it would have been if,
say, kings moved like knights or you could win by killing the queen
 &lt;em&gt;
  or&lt;/em&gt;
 the king. These are both perfectly valid games that someone could play,
and there is a perfectly valid mathematics in studying them, but we study the mathematics of chess in preference to them because that is the actual game people play.&lt;/p&gt;


&lt;p&gt;
 Conversely,
there really is a set of true statements about the game of chess (in an informal sense of chess),
and while mechanising and formalising the study of them might be
 &lt;em&gt;
  useful&lt;/em&gt;
 for determining what they are, I think it's fair to say that what actually matters is whether the statement is true of real games of chess,
and the formalisation only matters to the degree that it helps us discover those truths.&lt;/p&gt;


&lt;p&gt;
 I don't think the above definition is enough to fully reconstruct an idea of what mathematics is like,
because it leaves open two big questions:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  How do we select which hypothetical objects to study?&lt;/li&gt;
&lt;li&gt;
  How do we study them?&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 The answer to the first is comparatively easy, which is that it's based on what I think of as "The Three Good Reasons To Do Things":&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  It's useful.&lt;/li&gt;
&lt;li&gt;
  It's interesting.&lt;/li&gt;
&lt;li&gt;
  Some asshole is forcing you to do something useless and boring.&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 (Most people's encounters with mathematics is of type 3, sadly, which is why I always hear "Oh I
 &lt;em&gt;
  hated&lt;/em&gt;
 mathematics at school" when I tell people I did mathematics at university)&lt;/p&gt;


&lt;p&gt;
 Of course, point 2 is slightly subtle, because doing mathematics is much easier if other people have done similar mathematics, so you're constrained not just by what
 &lt;em&gt;
  you&lt;/em&gt;
 think is interesting, but by what you can convince other people is interesting.&lt;/p&gt;


&lt;p&gt;
 The second question is the hard part, and I think we currently do a very poor job of explaining it to people. I need to think further about it.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-08-08:06.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-07-15:47.html</id>
    <title>2018-09-07-15:47</title>
    <updated>2018-09-07T16:29:06+01:00</updated>
    <content>

&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-07&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 The thing I called
 &lt;a href="https://notebook.drmaciver.com/posts/2018-08-30-07:50.html"&gt;
  the Feynmann style&lt;/a&gt;
 relates to Tim Gowers's
 &lt;a href="https://www.dpmms.cam.ac.uk/~wtg10/2cultures.pdf"&gt;
  The Two Cultures of Mathematics&lt;/a&gt;
 ,
where he suggests that there are two cultures of mathematics: Theory building and problem solving. The latter tends to get organised not along the lines of general big ideas and broad theorems,
but instead along heuristics and guiding principles.&lt;/p&gt;


&lt;p&gt;
 Gowers refers to the areas of mathematics that are primarily problem-solving as
 &lt;em&gt;
  combinatorial&lt;/em&gt;
 ,
but I feel like this kind of problem solving is one that it doesn't seem right to refer to as combinatorial - it's more... calculation?&lt;/p&gt;


&lt;p&gt;
 There's a similar sense of being guided by heuristics and general ideas though.&lt;/p&gt;


&lt;p&gt;
 For example, one general idea is "replace annoying terms with integrals over some new variables, then swap out the variable".&lt;/p&gt;


&lt;p&gt;
 Suppose we didn't know what \(\sum\limits_{n = 1}^\infty (-1)^{n - 1} \frac{1}{n}\) was.
How would we deal with this?&lt;/p&gt;


&lt;p&gt;
 (Note: There's all sorts of playing fast and loose with convergence in this post that you can shore up later with some proper calculation but I'm not actually going to do. That's very common in this sort of proof).&lt;/p&gt;


&lt;p&gt;
 Well, that \(\frac{1}{n}\) is an annoying term. Lets get rid of it with.
A classic way of doing this is to replace it with \(\int\limits_0^1 x^{n - 1} dx\).&lt;/p&gt;


&lt;p&gt;
 We can now do the computation as follows:&lt;/p&gt;


&lt;p&gt;
 \begin{align}
\sum\limits_{n = 1}^\infty (-1)^{n - 1} \frac{1}{n} &amp;amp; = \sum\limits_{n = 1}^\infty (-1)^{n - 1} \int\limits_0^1 x^{n - 1} \\
&amp;amp; = \sum\limits_{n = 0}^\infty (-1)^n \int\limits_0^1 x^n \\
&amp;amp; = \int\limits_0^1 \sum\limits_{n = 0}^\infty (-x)^n \\
&amp;amp; = \int\limits_0^1 \frac{1}{1 + x} \\
&amp;amp; = \ln(1 + x) \\
\end{align}&lt;/p&gt;


&lt;p&gt;
 Roughly the steps here are:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  Try replacing tricky terms with integrals over simpler terms&lt;/li&gt;
&lt;li&gt;
  Use standard sums that you already know the answer for&lt;/li&gt;
&lt;li&gt;
  Try swapping sums and integrations&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 Another useful calculational heuristic is "try changing the variable".&lt;/p&gt;


&lt;p&gt;
 e.g. what's the limit as \(n \to \infty\) of \(n \ln (1 + \frac{1}{n})\)?&lt;/p&gt;


&lt;p&gt;
 Well, let \(x = \frac{1}{n}\). This expression is now \(\frac{ln(1 + x)}{x} = \frac{ln(1 + x) - \ln(1)}{x}\) as \(x \to 0\).
i.e. it's the derivative of \(\ln\) at \(1\), i.e. \(1\).&lt;/p&gt;


&lt;p&gt;
 It's hard to explain exactly what the thought process is here. It's like solving a puzzle - you have a bunch of known tricks that you think might work and you try to apply them all.
If you were to mechanize the process then it wuold end up looking like a brute force solver for the problem, but by using intuition you can kinda guide the way.&lt;/p&gt;


&lt;p&gt;
 I think maybe one part of the split between problem-solving and theory building is how much of what you end up building escapes the head of the mathematician building it:
Problem-solving skills are much harder to teach to another person than theory is (once that other person has build the skill of acquiring theory, which is also hard to teach)&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-07-15:47.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-07-15:27.html</id>
    <title>2018-09-07-15:27</title>
    <updated>2018-09-07T15:44:40+01:00</updated>
    <content>

&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-07&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 Compare and contrast:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
&lt;a href="https://www.cambridge.org/core/journals/journal-of-the-american-philosophical-association/article/aristotle-on-trolling/540BB557C82186C33BFFB61E35A0B5B6"&gt;
   "Aristotle" on trolling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://www.drmaciver.com/2014/02/etiquette-for-the-devils-advocates/"&gt;
   Etiquette for the Devil's advocates&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;


&lt;p&gt;
 I think the role the "Aristotle" (AKA
 &lt;a href="http://individual.utoronto.ca/rbarney/Home.html"&gt;
  Rachel Barney&lt;/a&gt;
 ) describes is probably quite a useful one in the right context,
the problem is that the nature of Trolling as defined in that paper is intrinsically that it is done
 &lt;em&gt;
  not&lt;/em&gt;
 in the right context.&lt;/p&gt;


&lt;p&gt;
 There's a thing that happens in Vernor Vinge's "A Deepness in the Sky" where the Evil Overlord ™ is experimenting with different configurations you can put a group mind in.
I sometimes think about this as an analogy for how to construct better modes of group problem solving (in a non-evil-overlord way that in no way involves my using the army of crows that I don't have to impose my will on the unsuspecting masses. Yes) .&lt;/p&gt;


&lt;p&gt;
 In particular, I think it's often actively useful for someone to explicitly take an adversarial role in a group discussion,
and it improves the resulting group's intelligence.
The difficulty is that you need to do this in a context where the group consents to this, and with a fairly explicit discussion in advance of boundaries.
It also helps to be able to ask the adversary to step out of the adversarial role and clarify their position.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-07-15:27.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-07-12:32.html</id>
    <title>When come back bring pie(s)</title>
    <updated>2018-09-07T12:58:38+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;When come back bring pie(s)&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-07&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 There's a metaphor people use: Some people fight for a larger slice of the pie, others see that it's better to enlarge the pie.&lt;/p&gt;


&lt;p&gt;
 I've seen this metaphor used for everything from intersectional feminism to the Patrician of Ankh-Morpork's extremely libertarian brand despotism.
Broadly the point is this: It's better to build a positive sum game where everyone benefits than it is to compete in a zero or negative sum game.&lt;/p&gt;


&lt;p&gt;
 The relationship between this point and the metaphor is interesting.
I agree with the thing that I am claiming to be the underlying point (but then I would), but I think what the actual metaphor demonstrates is also interesting:
People don't understand how pies work.&lt;/p&gt;


&lt;p&gt;
 What happens when you build a bigger pie?&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  You run into scaling issues, limited both by the size of your oven and also (if you build a better oven) the square-cube law (actually I'm not sure if this is the square-cube law at work, as pies tend to be scaled horizontally faster than they are scaled vertically, but either way once your pie gets big enough it's very hard to ensure it's cooked all the way through - you end up with overdone outsides and and underdone middle).&lt;/li&gt;
&lt;li&gt;
  The same people who couldn't eat your smaller pie still can't eat your larger one.6&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 The correct solution is not to enlarge the pie. It's to
 &lt;em&gt;
  bake more pies&lt;/em&gt;
 , and also the provide tasty food that is not pie because not everyone likes pie.&lt;/p&gt;


&lt;p&gt;
 If you've ever tried catering to a diverse group of dietary requirements, at some point you hit the point where you realise that it's much much easier to make multiple dishes than it is to try to create a single dish that can feed everyone.
A vegan gluten free nut free diabetic friendly pie is certainly possible, but it is a pie that basically nobody is going to
 &lt;em&gt;
  want&lt;/em&gt;
 to eat.
In contrast, a wide variety of desserts that can cater to each particular restriction that your group encounters,
without attempting to shoehorn everyone into a one size fits all badly model.&lt;/p&gt;


&lt;p&gt;
 The Unit of Caring has a notion she uses a lot of
 &lt;em&gt;
  competing access needs&lt;/em&gt;.
She
 &lt;a href="https://theunitofcaring.tumblr.com/post/135162290121/hi-i-have-a-quick-question-i-tried-googling-but"&gt;
  explains it well here&lt;/a&gt;
 ,
but the important quote (to save you from Tumblr's giant GDPR screen) is:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  Competing access needs is the idea that some people, in order to be able to participate in a community, need one thing, and other people need a conflicting thing, and instead of figuring out which need is ‘real’ we have to acknowledge that we can’t accommodate all valid needs.
I originally encountered it in disability community conversations: for example, one person might need a space where they can verbally stim, and another person might need a space where there’s never multiple people talking at once. Both of these are valid, but you can’t accommodate them both in the same space.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 Trying to build a space that works for everyone is more or less impossible, and what you will end up with is a space that works badly for everyone.
Instead we need the ability to have multiple spaces which we acknowledge as valid and allow people to freely move between these spaces as long as they are prepared to accept the local rules.&lt;/p&gt;


&lt;p&gt;
 In an interesting coincidence, this came up in a completely different context recently.
A while back
 &lt;a href="https://www.drmaciver.com/2016/05/randomizing-lean-coffee/"&gt;
  I sketched out a way of using randomization to improve the design of Lean Coffee meetups&lt;/a&gt;.
 &lt;a href="https://twitter.com/georgesdubus/status/1037957014599749632"&gt;
  This morning a friend reported&lt;/a&gt;
 :&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  I used to organize David-Style lean coffees at my previous job. (...)
The interesting limitation we ran into is that toward the end, the attendence was two groups with mostly disjoint interests.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 The nice thing about small-scale democratic processes like this is that splitting the union is a completely legitimate move.
If you have two groups with disjoint interests, why not run them as two groups? Ideally at different times so that people who really
 &lt;em&gt;
  are&lt;/em&gt;
 interested in both can attend both.&lt;/p&gt;


&lt;p&gt;
 How to do this sort of thing at a larger scale seems to be one of the great unsolved problems of society.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-07-12:32.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-06-10:14.html</id>
    <title>2018-09-06-10:14</title>
    <updated>2018-09-06T11:07:01+01:00</updated>
    <content>

&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-06&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 Follow on to
 &lt;a href="https://notebook.drmaciver.com/posts/2018-09-05-13:24.html"&gt;
  misc thoughts about voting design for talk scheduling&lt;/a&gt;.&lt;/p&gt;


&lt;p&gt;
 Here's how a system that is much closer to classic STV could work.
Assume everyone has a ranking of all the talks they wish to attend (this isn't actually reasonable to ask for, but you could get people to score talks according to some ordinal scores and then randomly tie break, or tie break in organiser preferred order or something).&lt;/p&gt;


&lt;p&gt;
 The system has the following three parameters:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  The number of time slots.&lt;/li&gt;
&lt;li&gt;
  The number of talks per time slot.&lt;/li&gt;
&lt;li&gt;
  The minimum number of attendees required for a talk to be worthwhile (should be at least one). Callt his the threshold.&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 You also need to pick a quota system. Either the
 &lt;a href="https://en.wikipedia.org/wiki/Comparison_of_the_Hare_and_Droop_quotas"&gt;
  Droop or the Hare quota&lt;/a&gt;
 are the obvious choices.
My natural bias is to use the Hare quota, as it's better for minority interests and I think that's a nice feature to have in your conference talk selection (conferences have a tendency to have the same talks over and over again and I think this would help offset that).&lt;/p&gt;


&lt;p&gt;
 The system could easily be adapted to more complicated constraints in which not all talk/time slot combinations are valid, but I'm going to ignore that.&lt;/p&gt;


&lt;p&gt;
 Conceptually what happens is everyone is given one voting-buck,
and a talk slot "costs" an amount of voting-bucks equal to the quota.
People band together to form buying blocs and each spend the same percentage of their remaining pool of voting money to buy a slot (this is basically how normal STV works too).&lt;/p&gt;


&lt;p&gt;
 The system involves running the following process to a fixed point:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  Set the list of eligible talks to all talks which have at least the threshold number of people voted for them.&lt;/li&gt;
&lt;li&gt;
  Give everyone exactly one vote (note: as the process evolves, people will have fractional votes).&lt;/li&gt;
&lt;li&gt;
  People vote for (talk, slot) pairs, where the slot has not already been filled and the talk is both eligible and not yet scheduled.
   They will vote for a pair if:
  &lt;ol&gt;
&lt;li&gt;
    The talk their highest ranked talk among the available talks.&lt;/li&gt;
&lt;li&gt;
    If there are slots which have no talks they want to see in them, they will only vote for pairs in those slots.
   Otherwise they will vote for pairs where they prefer the talk to the one currently scheduled there.
   Note that a voter can vote for multiple (talk, slot) pairs.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;
  If there are no such pairs, we have scheduled all of the talks we can (even if there still unfilled slots). Stop and report this as the schedule.&lt;/li&gt;
&lt;li&gt;
  If any of the pairs has a total number of votes exceeding the quota, pick the one with the most votes and schedule that.
   For each voter who voted for it, multiply their remaining vote by \(1 - \frac{q}{r}\), where \(q\) is the quota and \(r\) is the total vote for the elected slot
   (i.e. we've removed \(q\) from their total vote and everybody pays it equally).&lt;/li&gt;
&lt;li&gt;
  If no pair was elected, take the talk with the lowest maximum vote over all vote pairs, and remove it from the list of eligible talks.&lt;/li&gt;
&lt;li&gt;
  If a pair was elected, now check if any talks can no longer meet the threshold - i.e. if for every slot you could schedule them in,
   count the number of people for whom that is their favourite talk in that slot. If there are no slots where this exceeds the threshold, remove the talk from the eligible list.&lt;/li&gt;
&lt;li&gt;
  If we removed any talks from the eligible list, reset all of the state except the list of eligible talks and go back to step 2. Otherwise go back to step 3.&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 Most of this is just variant STV, with some of the specific details owing to specific types of STV.
The main difference is that because the same voter may cast their vote for multiple options simultaneously,
we need to be careful not to elect more than one "candidate" at once,
plus the specialised drop-out rule for talks that fail to meet the threshold.&lt;/p&gt;


&lt;p&gt;
 Most of my problems with it are the same as my problems with STV in general: It looks like an iterative optimisation process, but it's not at all clear what it is you are optimising for.
So it might work well, but I'm not really sure how you would measure "well" in this context.
It seems plausibly worth a try though.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-06-10:14.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-05-13:24.html</id>
    <title>Mechanisms for talk scheduling and voting</title>
    <updated>2018-09-06T09:23:39+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;Mechanisms for talk scheduling and voting&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-05&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 I've been thinking about mechanism design for conference scheduling again.
I've
 &lt;a href="https://www.youtube.com/watch?v=OkusHEBOhmQ"&gt;
  previously argued that conference scheduling should be treated as an optimisation problem&lt;/a&gt;
 ,
but I no longer believe that's true.&lt;/p&gt;


&lt;p&gt;
 In particular I think the following hold:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
  If we treat talk selection as a voting problem, we must employ some mechanism of proportional representation&lt;/li&gt;
&lt;li&gt;
  In a multi-track conference, scheduling and selection cannot be separated.&lt;/li&gt;&lt;/ul&gt;


&lt;p&gt;
 Lets see some examples in support of this.&lt;/p&gt;


&lt;p&gt;
 Suppose you're running a Python conference, and 60% of the people attending are web developers and 40% are data scientists.
You put together a set of talk proposals, people vote on them, and you take all of the top voted talks.
What you end up with is of course a conference consisting entirely of web development talks.&lt;/p&gt;


&lt;p&gt;
 (Note: Despite the running Python example, this post is not actually about
 &lt;a href="https://2018.hq.pyconuk.org/schedule/"&gt;
  The PyCon UK Schedule&lt;/a&gt;
 , which I've barely looked at.)&lt;/p&gt;


&lt;p&gt;
 For some contexts maybe that's OK, but given that a lot of the value in conferences is the hallway track, it's nice to be able to put together heterogenous conferences.
You could fix this by artificially selecting for certain subjects, but proportional representation seems like a much better approach because it doesn't require you to know all the ways in which your audience is heterogenous in advance.
So, in the above example, we would have roughly 60% web dev talks and 40% data science talks,
but also if it turned out that about 10% of the audience were really excited about Flask,
we could have about 10% Flask talks.&lt;/p&gt;


&lt;p&gt;
 If the conference is single-track we're more or less done: Pick your favourite (non party-list based, so probably some variant of STV), proportional voting system,
use that to select your talks, and call it a day.&lt;/p&gt;


&lt;p&gt;
 I'd like to pause here by saying that I'm increasingly a fan of single track conferences, so I think "do a single track conference and call it a day" might actually be the correct solution.&lt;/p&gt;


&lt;p&gt;
 But lets suppose you're less on board with that and want a multi-track conference.&lt;/p&gt;


&lt;p&gt;
 For simplicity, lets imagine that our Python conference now has two rooms,
with talks running in the same time slots in each room,
and attendees now have to choose which of the two to attend.
Lets say it's a single day conference and there are five time slots,
so ten talks.&lt;/p&gt;


&lt;p&gt;
 According to our above PR argument, we should run six web dev talks,
but does it really make sense for us to do so?
There are only five time slots,
so (by
 &lt;a href="https://en.wikipedia.org/wiki/Pigeonhole_principle"&gt;
  the pigeonhole principle&lt;/a&gt;
 if you want to get fancy about it) you're inevitably going to put two web dev talks back to back.
That might be OK - maybe you're scheduling a Django and a Flask talk against each other - but maybe there's a strict preference where there are five obviously best web dev talks and the sixth is pretty good (preferable by web devs to any data science talk) but not good enough (will not get any attendees when scheduled against any of the top five talks). What's the point in selecting that talk given that?&lt;/p&gt;


&lt;p&gt;
 In the other direction, lets say we have 20% of the audience who are really interested in random forests,
and so we select two random forests talks,
which we then proceed to schedule in the same time slot.
Now despite 20% representation at the talk level,
they only have 10% representation at the time slot level!&lt;/p&gt;


&lt;p&gt;
 (I want to draw an analogy to
 &lt;a href="https://en.wikipedia.org/wiki/Gerrymandering"&gt;
  gerrymandering&lt;/a&gt;
 here but I don't think it quite works)&lt;/p&gt;


&lt;p&gt;
 So, tracking creates an upper bound on how much proportional representation is worth doing, and also scheduling within those tracks affects the amount of proportionality you actually get.&lt;/p&gt;


&lt;p&gt;
 So what to do about it?&lt;/p&gt;


&lt;p&gt;
 Well, I'm not entirely sure. I started designing a whole complex system in support of this that this note was originally supposed to be about, but I decided I didn't like it very much.&lt;/p&gt;


&lt;p&gt;
 The basic ideas were:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  Give each participant a "voting currency" - everyone starts with an equal amount, and talk slots effectively get auctioned off, with the proceeds distributed among everyone equally (possibly among everyone who still has any interest in attending remaining talks).&lt;/li&gt;
&lt;li&gt;
  Participants will only vote for talks in slots that are strictly better for them than the talks already scheduled in that slot.&lt;/li&gt;
&lt;li&gt;
  Define a threshold of "Minimum number of people required to be worth running a talk". Whenever a talk no longer would meet that requirement (because every slot it could be scheduled in has talks people prefer more), it is immediately excluded and the process restarts from the beginning. This is akin to how exclusions work in
  &lt;a href="https://en.wikipedia.org/wiki/Wright_system"&gt;
   The Wright System of STV&lt;/a&gt;
  , and is designed to avoid "spoiler" talks, where people who preferred them effectively get screened off from voting in the process until the talk is excluded.&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 The details kinda became a weird hybrid of STV and the
 &lt;a href="https://en.wikipedia.org/wiki/Vickrey%E2%80%93Clarke%E2%80%93Groves_mechanism"&gt;
  Vickrey-Clarke-Groves mechanism&lt;/a&gt;
 and the more I looked at it the less convinced I became that it was the right way to do things or that I actually understood how the VCG mechanism plays out in practice.&lt;/p&gt;


&lt;p&gt;
 I do think the above examples are important to consider though.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-05-13:24.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-05-11:08.html</id>
    <title>My parents, Ayn Rand and God</title>
    <updated>2018-09-05T11:20:12+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;My parents, Ayn Rand and God&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-05&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
&lt;a href="https://twitter.com/bazzalisk/status/1037277763219152897"&gt;
  From bazzalisk on Twitter&lt;/a&gt;
 :&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  “You know him better than I” and “You know him better than me” are both grammatically valid but mean different things&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 The former means "You know him better than I do", the latter means "You know him better than you know me".&lt;/p&gt;


&lt;p&gt;
 The title of this note comes from the following probably-apocryphal book dedication,
used as an argument for the oxford comma:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  This book is dedicated to my parents, Ayn Rand and God.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 Without the Oxford comma,
the implication is that the author's parents are Ayn Rand and God,
with the Oxford comma, this is a dedication to four people (the author's parents, and also to Ayn Rand and God).
 &lt;a href="http://mentalfloss.com/article/33637/best-shots-fired-oxford-comma-wars"&gt;
  Mental Floss has a bunch of similar ones&lt;/a&gt;.&lt;/p&gt;


&lt;p&gt;
&lt;a href="http://msgboard.snopes.com/cgi-bin/ultimatebb.cgi?ubb=get_topic;f=95;t=000863;p=0"&gt;
  Snopes think this probably never happened&lt;/a&gt;
 ,
but OTOH the following is part of their argument:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  Since Rand was such an outspoken atheist, I find it hard to believe that anyone would mention both her and God as sources of inspiration.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 And, well, this seems to ignore the existence of Paul Ryan and a significant chunk of the US political right.
Also I'm now amused by the idea of Ayn Rand's atheism being a reaction to God being a deadbeat dad.
Someone should write that fanfic, but it's not going to be me.&lt;/p&gt;


&lt;p&gt;
 There is of course
 &lt;a href="https://amzn.to/2LYsLcz"&gt;
  an entire book about comedic misinterpretations due to bad grammar&lt;/a&gt;
 ,
but that's not exactly what's going on here:
Instead these are interesting grammatically valid examples that are right on the edge of ambiguity.&lt;/p&gt;


&lt;p&gt;
 It's unclear to me whether this actually tells us anything useful.
We could probably derive some normative advice about correct use of grammar from it,
but this sort of thinking about things in terms of their edge cases is a very modern-mathematician view of the world,
which doesn't come very naturally to others.&lt;/p&gt;


&lt;p&gt;
 The general widely deployed solution to linguistic ambiguity is instead that we just guess or ask,
and frankly that probably works better than trying to remove it.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-05-11:08.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-02-21:22.html</id>
    <title>Fiction for Kristian</title>
    <updated>2018-09-02T21:54:40+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;Fiction for Kristian&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-02&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 This is a small collection of fiction I've written that I like enough to actively recommend and think count as "finished".&lt;/p&gt;


&lt;h3&gt;
 Fan fiction&lt;/h3&gt;


&lt;p&gt;
 The two pieces of Stargate fan fiction that I've written and would recommend are
 &lt;a href="https://archiveofourown.org/works/3673335"&gt;
  Stargate Physics 101&lt;/a&gt;
 and
 &lt;a href="https://archiveofourown.org/works/5023654"&gt;
  Interview with a System Lord&lt;/a&gt;.
Both are not only canon-compatible (more or less. Stargate Physics 101 doesn't quite line up with Stargate Universe, but I don't care about Universe),
but are 100% my headcanons of how the universe works.&lt;/p&gt;


&lt;p&gt;
 Completion status: 100% finished standalone pieces. I may write other Stargate fan fiction at some point, and if I do then as part of the universe's canon those will naturally be part of its backstory,
but there will never be sequels per se to these pieces.&lt;/p&gt;


&lt;p&gt;
 Recommendation strength: Stargate Physics 101 is one of my most popular pieces and works even if you have never watched Stargate. If you like any of infrastructure science fiction, software testing, or stargate, it's worth reading.
Interview with a System Lord is worth reading if and only if you like Stargate SG1 (and especially if you like Ba'al) and want a moderately amusing story exploring a weird headcanon. Warning: May cause mild sympathy for the devil.&lt;/p&gt;


&lt;p&gt;
&lt;a href="https://archiveofourown.org/works/4637439/chapters/10575111"&gt;
  The Rules of Wishing&lt;/a&gt;
 is a piece of fan fiction of Disney's Aladdin.
Premise:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  What if people were good at wishing? The Genie's rules have holes you could drive a herd of camels through, but they don't have to. Aladdin and Jafar's wishes are shallow and limited, and lack the foresight that really effective wishing entails, but wouldn't a battle between effective wishers be much more interesting? And while we're at it, why does Jasmine have so little agency and basically act as a prize to be won in a battle between two men when literally the entire point of her narrative is that she's not that?&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 It has been argued to be rational!fic though I'm not sure I agree with the classification.
Jasmine in this is probably my joint favourite character I've ever written.&lt;/p&gt;


&lt;p&gt;
 Completion status: Has a mini non-canon sequel
 &lt;a href="https://archiveofourown.org/works/13523703"&gt;
  The Consequences of Wishing&lt;/a&gt;
 that explains the divergence between this story and the film.
May, but probably won't, spawn another sequel, but the current ending wraps it up entirely to my satisfaction and any sequel would be a new story in the same universe with the same characters rather than a continuation of this story.&lt;/p&gt;


&lt;p&gt;
 Trigger warning: Moderately violent.&lt;/p&gt;


&lt;p&gt;
 Recommendation strength: Honestly, you should read this if you like my fiction at all and are not put off by the trigger warning.&lt;/p&gt;


&lt;p&gt;
&lt;a href="https://archiveofourown.org/works/13354146"&gt;
  Counterparts&lt;/a&gt;
 is a crossover fic between Lucifer (the TV show) and Old Harry's Game (the radio show).&lt;/p&gt;


&lt;p&gt;
 Completion status: Very standalone. It's not impossible I may do a followup involving The Good Place, but it stands on its own regardless of whether I do.&lt;/p&gt;


&lt;p&gt;
 Recommendation strength: Well it amuses
 &lt;em&gt;
  me&lt;/em&gt;. Based on feedback, if you like Lucifer it will probably also amuse you. Familiarity with the Old Harry's Game is helpful but not strictly required.&lt;/p&gt;


&lt;h3&gt;
 Original Fiction&lt;/h3&gt;


&lt;p&gt;
&lt;a href="https://archiveofourown.org/works/9233966/chapters/20941043"&gt;
  Programmer at Large&lt;/a&gt;
 is a story about gender, social anxiety, and legacy code.
It seems to have a lot of fans.&lt;/p&gt;


&lt;p&gt;
 Completion status: Abandoned, but it kinda works that way. It's a series of slice of life chapters, and the protagonist's life is never really "finished". However it definitely has some unsatisfying dangling plot threads that will never be resolved. However most of the strength of this story is at the chapter level anyway - it has some of my best writing in it, but as a whole story I do not feel that it works. I intend at some point to take it apart and refactor and modularise it into several smaller stories. I am fully aware of the irony of saying this about a story about legacy code.&lt;/p&gt;


&lt;p&gt;
 Recommendation strength: Mixed. There's some stuff in there I really like, and a lot of people seem to love it, but like I said I don't feel that it hangs together in its current incarnation.&lt;/p&gt;


&lt;p&gt;
&lt;a href="https://archiveofourown.org/series/754683"&gt;
  The Diaries of Vicky Frankenstein&lt;/a&gt;
 more normally AKA "The Vicky Stories". Series of short stories about Dr Vicky Frankenstein and her adventures in joining a biotech startup run by the vampire Ada Lovelace.&lt;/p&gt;


&lt;p&gt;
 Completion Status: (Hopefully permanently) incomplete in the sense that I fully intend to keep writing Vicky stories (but don't more than about one every six months), but each Vicky story is a complete standalone short story that happens to be set in the same world and use the same characters. There are minimal to no dangling plot threads between the stories.&lt;/p&gt;


&lt;p&gt;
 Recommendation Status: I ♥ writing Vicky and think you should read these. Also, contains a (99% SFW) lesbian sex scene between two amoral monsters that reviewers describe as "ridiculously adorable", so there's that.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-02-21:22.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-02-13:13.html</id>
    <title>2018-09-02-13:13</title>
    <updated>2018-09-02T13:34:22+01:00</updated>
    <content>

&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-02&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 Compare and contrast two interesting links:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
  Siderea's
  &lt;a href="https://siderea.livejournal.com/1230660.html"&gt;
   The Asshole Filter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
  Cormac Herley's
  &lt;a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/WhyFromNigeria.pdf"&gt;
   Why do Nigerian Scammers Say They are from Nigeria?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
  Karl Popper's "The Paradox of Tolerance"&lt;/li&gt;&lt;/ul&gt;


&lt;p&gt;
 (Note that I've not read the latter two and should. I've only read digested versions of them).&lt;/p&gt;


&lt;p&gt;
 In general often the right way to judge an action is not actually on its immediate effects,
but on what long-run effect they will have on the sort of people you will surround yourself with.
This can make seemingly good actions harmful and seemingly bad or nonsensical ones quite useful.&lt;/p&gt;


&lt;p&gt;
 I think about this a bunch in the context of codes of conduct:
Often the benefit of the code of conduct is not whether it is ever enforced,
but that it filters out people who don't like codes of conduct.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-02-13:13.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-01-17:41.html</id>
    <title>Notation for test-case reducers</title>
    <updated>2018-09-01T20:15:35+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;Notation for test-case reducers&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-01&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 A thing I've been noticing recently is that it's really useful to have compact notation for describing things.
Usually this is equivalent to primivitives + some combinators.&lt;/p&gt;


&lt;p&gt;
 One thing that I think it would be useful to have such a notation for is (greedy) test-case reduction passes.
They combine pretty well, and it makes it useful to discuss various things.&lt;/p&gt;


&lt;p&gt;
 For example, if you have reducers \(A\), \(B\), you can define the reducer \(AB\) which runs \(A\), then
runs \(B\) on its result. You can also define the reducer \(A^+\) which runs \(A\) to a fixed point.&lt;/p&gt;


&lt;p&gt;
 Another interesting combinator is \(/\). \(A / B\) runs \(A\), then runs \(B\) if \(A\) didn't do anything..&lt;/p&gt;


&lt;p&gt;
 There are a bunch of really basic algebraic relations that hold, like composition and \(/\) are associative,
and \((A^+)^+ = A^+\), but not a huge amount beyond that.&lt;/p&gt;


&lt;p&gt;
 A bunch of interesting questions about test-case reduction can be compactly expressed in this notation though.
For example, suppose you want to reduce to something that is a fixed point of both \(A\) and \(B\).
You could do \((AB)^+\), but you could also do \((A^+B^+)^+\), and it's quite natural to do this in some contexts.
My suspicion, which I've yet to verify, is that it's almost never the right thing to do.&lt;/p&gt;


&lt;p&gt;
 You can kinda regard the quadratic mode failure of greedy search as an instance of this problem:
If \(\delta_i\) is the operation that deletes the element at position \(i\), the correct pass to run for greedy deletion is \((\delta_0^+ \ldots \delta_n^+)^+\),
but if you start again at the beginning every time you succeed you are running \((\delta_0 / \ldots / \delta_n)^+\).&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-01-17:41.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-01-16:08.html</id>
    <title>Modes of writing</title>
    <updated>2018-09-01T16:11:23+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;Modes of writing&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-01&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 Two posts on writing to contrast:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
&lt;a href="https://blog.malignat.us/2018-05-12/on-the-creative-merits-of-paper"&gt;
   On the creative merits of paper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href="http://devonzuegel.com/post/comparison-of-text-editing-methods"&gt;
   Comparison of text editing methods&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;


&lt;p&gt;
 Devon posted the second on twitter and it reminded me of the first, which I struggled to refind, which is part of why I'm posting it here.&lt;/p&gt;


&lt;p&gt;
 I've been finding having a paper journal very useful, but I'm also finding having this new notebook useful in an entirely different way.
The contrast is very interesting.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-01-16:08.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-09-01-09:17.html</id>
    <title>Can a machine design?</title>
    <updated>2018-09-01T09:22:46+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;Can a machine design?&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-09-01&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
&lt;a href="http://echo.iat.sfu.ca/library/cross_01_machine_des.pdf"&gt;
  Can a machine design?&lt;/a&gt;
 by Nigel Cross is an interesting paper about architecture (the real kind!) and its relation to automation.
I found it via Adam Marshall Smith's PhD thesis
 &lt;a href="https://adamsmith.as/papers/mechanizing_exploratory_game_design_book.pdf"&gt;
  Mechanizing exploratory game design&lt;/a&gt;
 (truthfully via
 &lt;a href="https://twitter.com/maxkreminski/status/964923822766833664"&gt;
  this tweet&lt;/a&gt;
 about it from Max Kreminski),
which is an excellent thesis on mechanically assisted creativity (I must admit I skimmed the technical content as less relevant to me - I care about the meta more than I care about game design qua game design).&lt;/p&gt;


&lt;p&gt;
 Most relevant quote for me:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  Despite this apparently
easy pace of interaction, all of the designers reported that they
found the experiments hard work and stressful. They reported that
the main benefit of using the "computer" was increased work
speed, principally by reducing uncertainty (i.e., they relatively
quickly received answers to queries, which they accepted as reliable
information).
I also tried a few variations from my standard experiments. The most interesting was to reverse the normal set of expectations of the functions of the designer and the "computer."
The "computer" was given the job of having to produce a design to the
satisfaction of the observing designer. It immediately was apparent
that, in this situation, there was no stress on the designer—in fact, it
became quite fun—and it was the "computer" that found the experience
to be hard work.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 i.e. it's much more fun to tweak a computer's output than it is to be critiqued by one.
An important observation for people in correctness research I think!&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-09-01-09:17.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-08-31-09:43.html</id>
    <title>Some free user experience consulting for Google</title>
    <updated>2018-08-31T10:12:30+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;Some free user experience consulting for Google&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-08-31&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 I am not a UX expert. I've worked with people who are, and I'm probably a lot better than my otherwise utter incompetence at front-end work would suggest,
but I'm at best OK.&lt;/p&gt;


&lt;p&gt;
 Nevertheless, as a user I get to see a lot of the sharp edge of the problems, and I'm good enough at UX that I think I can see what the shape of the solution is.&lt;/p&gt;


&lt;p&gt;
 The product I would like to offer Google some free advice on is the following: Google Maps's driving navigation.&lt;/p&gt;


&lt;p&gt;
 On a related note, if you can recommend a good driving navigation app to me (iPhone, sadly), that would be delightful.
It would be especially useful if it were one that understood features of English roads like "has roundabouts" and "is verrah verrah smol" that seem alien to people from the US (although given how much of Google maps is in Zurich,
I'm still surprised by its failure to understand these).&lt;/p&gt;


&lt;p&gt;
 Anyway, free UX consulting.
User stories are cool I hear, so here are my two user stories for Google maps:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  As a driver, I would like to survive my trip.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 and&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  As a driver, I would like to be able to drive without a constant sense of paranoia.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 Currently Google Maps fails both of these so hard that I have conjectured that I have somehow triggered a special murder-mode for ex-Googlers,
because honestly if Google Maps treats most drivers like it treats me then either not many people can be using it or I would have expected a better publicised death toll from it.
I am not actually being hyperbolic here (or even parabolic).&lt;/p&gt;


&lt;p&gt;
 Google maps reliably does everything in its power to destroy my trust in it, which is not ideal in something that I have to use while driving.&lt;/p&gt;


&lt;p&gt;
 As the most basic minimum that would be required to restore my trust, I would like to propose the following feature:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  Google maps should never, under any circumstances, exit navigation without an audible confirmation that it has done so.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 There is what is almost certainly a bug in Google maps where sometimes it just goes "lol, I'm done here" and exits navigation without telling me.
This is
 &lt;em&gt;
  functionally indistinguishable&lt;/em&gt;
 from the sort of confirmation Google maps uses to tell me to just keep going straight.
As a result, whenever Google maps is silent for an extended period of time, I end up feeling a gnawing sense of paranoia that it's just not telling me what to do and I'm going in completely the wrong direction.&lt;/p&gt;


&lt;p&gt;
 Almost all of the time this is not the case and the correct thing to do is to keep going straight (although Google maps's notion of what "keep going straight" is is often very funny and involves amusing interpretations of the word "going straight" that include things like "turning left" - it is not very good at actually knowing where the road markings are, and if the road follows around to the right it will often confuse a left turn with keep going straight. However, I will forgive it data problems, particularly on the weird back country roads I often drive),
but this bug triggers just often enough (last incidence: about an hour ago) that the exceedingly common operation of
 &lt;em&gt;
  driving in a straight line&lt;/em&gt;
 fills me with deep unease whenever I use Google maps for navigation.&lt;/p&gt;


&lt;p&gt;
 Even if this bug were fixed, the damage is done, and I will never believe Google maps is still running if it is silent.&lt;/p&gt;


&lt;p&gt;
 On top of that, I would like to propose the following feature:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  Google maps should never be silent for an extended period of time.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 I'll grant that if the last instructions were "Keep going for 500 miles" it doesn't need to give me a mile counter every five minutes,
but if it could tell me every half hour or so "Yup, everything is cool, keep going" that would be great.
In normal operation,
every five minutes sounds about right.&lt;/p&gt;


&lt;p&gt;
 The second source of paranoia is that Google maps gives absolutely no feedback as to when you have done something wrong.
I know the whole nagging satnav going "Make a U-Turn. Make a U-Turn. Make a- *urk* (noise as satnav is thrown out window)" has a bad reputation,
but there's a happy medium: When you do something Google maps does not expect,
it should say something along the lines of "You missed a turn, I'm going to try to turn you around" or "You missed a turn, finding a new route".&lt;/p&gt;


&lt;p&gt;
 Fun instances where it was very useful to have a second person in the car yesterday:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  When Google maps took me 30 miles up the wrong motorway before eventually turning me around.&lt;/li&gt;
&lt;li&gt;
  When Google maps was very upset that I didn't drive through the traffic cones blocking the route it wanted me to take and insistently tried to turn me around for another go.&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 Feedback that I had done the wrong thing would have been very helpful on the first, because I would have spent a lot of time confused without it.
Feedback on the second that it was taking me around for another pass would also have been very helpful. I would have probably ignored its instructions even without Luke to assist me,
but I would have felt much less certain about it.&lt;/p&gt;


&lt;p&gt;
 Anyway, those is the main sources of paranoia.
Lets talk about the other moderately important feature:
Not dying and/or killing people.&lt;/p&gt;


&lt;p&gt;
 This is a very simple issue:
Google maps literally never gives you enough advance warning.
This is especially true in the following two cases:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
  with motorway driving. If you tell me "In one mile, take the exit" when I am doing 70 mph (yes, um, definitely 70 mph, that's the speed limit after all) in the right hand lane of a motorway,
  you are saying "In the next 30 seconds, merge across three lanes of possibly quite busy traffic". This is a style of advice that will literally kill people and, worse, make them miss their turning.&lt;/li&gt;
&lt;li&gt;
  with roundaboutes and other turnings where there is a lane you need to be in, I need to know what lane that is
  &lt;em&gt;
   before&lt;/em&gt;
  reaching the roundabout. It happens all the time that I either exit a roundabout,
  leave a motorway and Google maps is like "tum ti tum, la la, nothing to see here, oh hey there's a roundabout coming up. Atttt... theeee.... rouuuundabout.... taaaake..... the.... third... exit....".
  Often I am
  &lt;em&gt;
   on the fucking roundabout&lt;/em&gt;
  before it tells me what lane I need to be in.&lt;/li&gt;&lt;/ul&gt;


&lt;p&gt;
 Giving this sort of last minute instruction is deeply unsafe,
and needs to stop.&lt;/p&gt;


&lt;p&gt;
 On top of that there's all sorts of data problems and things where Google maps just clearly doesn't understand UK roads,
but I don't realistically expect those to be fixed, especially with the UK dooming itself to irrelevance next year and the only Google UK presence being in a city where you already have to embrace paranoia and risk loss of life and limb to drive in anyway, so I won't bother venting about those now.&lt;/p&gt;


&lt;p&gt;
 In the meantime, I'm serious about that desire for recommendations of less murdery navigation apps. Please?&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-08-31-09:43.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-08-31-06:57.html</id>
    <title>2018-08-31-06:57</title>
    <updated>2018-08-31T10:57:28+01:00</updated>
    <content>

&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-08-31&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 I'm a big fan of the
 &lt;a href="https://en.wikipedia.org/wiki/Brzozowski_derivative"&gt;
  Brzozowski derivative&lt;/a&gt;
 ,
introduced in "Derivatives of regular expressions" by Janusz A. Brzozowski.&lt;/p&gt;


&lt;p&gt;
 The basic idea is that given some language \(L\) over an alphabet \(A\),
and some string \(u\) over \(L\),
you can define the derivative language \(\partial(L, u) = \{v: uv \in L\}\).
We can extend this further (and it will be useful to do so below).
If \(M\) is some other language, we can define \(\partial(L, M) = \{v: \exists u \in M, uv \in L\}\).
I'm not currently sure if the derivative of a regular language by a regular langauge is regular in general. It is in the case we'll see later,
and I suspect it is in general.&lt;/p&gt;


&lt;p&gt;
 This seems like a pretty trivial observation until you realise the following three things:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  \(u \in L\) if and only if \(\epsilon \in \partial(L, u)\)&lt;/li&gt;
&lt;li&gt;
  \(uv \in L\) if and only if \(v \in \partial(L, u)\)&lt;/li&gt;
&lt;li&gt;
  For most common representations of languages, it's actually pretty easy to calculate a representation of their derivative.&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 Putting these together, you can use the Brzozowski derivative to calculate a deterministic (not necessarily finite!) automaton for almost any language that you can easily represent.
You label states with descriptions of languages,
a state is accepting if it matches the empty string,
and transitions to the states labelled by the derivatives.&lt;/p&gt;


&lt;p&gt;
&lt;a href="http://www.ccs.neu.edu/home/turon/re-deriv.pdf"&gt;
  Regular-expression derivatives reexamined&lt;/a&gt;
 by Owens et al. has some nice practical details of doing this in the context of functional programming.&lt;/p&gt;


&lt;p&gt;
 To see this in action, consider the standard regular expression operators.
These satisfy the following identifies:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  \(\partial(A | B, u) = \partial(A, u) | \partial(B, u)\)&lt;/li&gt;
&lt;li&gt;
  \(\partial(AB, u) = \partial(A, u)B | \nu(A) \partial(B, u)\), where \(\nu(A) = \epsilon\) if \(\epsilon \in A\) or \(\emptyset\) otherwise (i.e. the derivative can skip over \(A\) if and only if \(A\) contains the empty string)&lt;/li&gt;
&lt;li&gt;
  \(\partial(A^*, u) = \partial(A, u) A^*\)&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 A result proved in Brzozowski's original paper (apparently. I can't currently seem to access it, and am going off thecite in "Regular-expression derivatives reexamined) is that a small number of reasonable normalisation rules over the representation of the language is enough to ensure that you only get finitely many states in the state machine generated by partial derivatives of regular expressions.
It's certainly true that you only get finitely many if you have full equivalence for the regular languages labelling the states - the derivative automaton is actually the minimal automaton representing a language.&lt;/p&gt;


&lt;p&gt;
 There are two very nice things about this representation of the language's automaton though:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  It can be done
  &lt;em&gt;
   lazily&lt;/em&gt;. This means that even when your deterministic automaton has exponentially (or infinitely!) many states, you only ever need to explore the states that you walk when matching strings.&lt;/li&gt;
&lt;li&gt;
  It is very easy to extend with new operators.&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 An example of (2) is that regular expressions reexamined actually does it for extended regular expressions with intersection and negation, because might as well right? It's no harder than doing it with the normal ones, even though adding these to your regular expression language can cause exponential blowup in the size of the automata compiled from your regex.&lt;/p&gt;


&lt;p&gt;
 But there are even more interesting ones if you're prepared to go for more esoteric operations!&lt;/p&gt;


&lt;p&gt;
 Have you heard of the
 &lt;a href="https://en.wikipedia.org/wiki/Levenshtein_automaton"&gt;
  Levenshtein automaton&lt;/a&gt;
 ? The set of strings within some finite edit distance of another string is a regular language and you can define a nice automaton matching it.
But in fact, a stronger result is true: For any regular language \(L\) and natural number \(n\), the set \(E(L, n) = \{u: \exists v \in L, d(u, v) \leq n\}\) is a regular language.
Why?&lt;/p&gt;


&lt;p&gt;
 Well, we can calculate its derivative!
The derivative of \(E\) is \(\partial(E(L, n), u) = E(\partial(L, u), n) | E(L, n - 1) | E(\partial(L, \cdot), n - 1) | \partial(E(\partial(L, \cdot), n - 1), u)\).
That is, at each character we can either:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  Continue matching the original language (cost 0).&lt;/li&gt;
&lt;li&gt;
  Insert a new character in front of something in the original language (cost 1)&lt;/li&gt;
&lt;li&gt;
  Replace a character in the original language with \(u\) (cost 1)&lt;/li&gt;
&lt;li&gt;
  Drop a character from the original language and try again (cost 1)&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 In the course of doing this we apply the following rewrite rules:&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
  \(E(L, 0) = L\)&lt;/li&gt;
&lt;li&gt;
  \(E(\emptyset, n) = \emptyset\)&lt;/li&gt;&lt;/ol&gt;


&lt;p&gt;
 As long as the number of reachable representations for the original languages is finite,
so is the number of reachable states in our Levenshtein construction:
Every state is labelled by a set of languages of the form \(E(\partial(L, U), k)\) where \(U\) is a language defined by \(u_1 \ldots u_m\) with each \(u_i\) either a single character or a \(\cdot\),
and \(m + k \leq n\). There are only finitely many such labels as long as there are only finitely many derivatives of \(L\),
although in principle there may be exponentially many.
Because of the laziness of our construction that often won't matter - you can still determine membership for a string of length \(k\) with only \(O(k)\) state traversals (though calculating those states could in principle require up to \(O(nm)\) work, where \(m\) is the number of states in the original automaton).&lt;/p&gt;


&lt;p&gt;
 You can also use this to determine the minimum edit distance between two regular languages,
because you can test whether \(E(L, n) \cap L' = \emptyset\) by calculating and walking the generated DFA for the left hand side,
so this gives you a decision procedure for \(d(L, L') \leq n\).&lt;/p&gt;


&lt;p&gt;
 Is this a practical algorithm? Not sure. I've played with it a little bit, but I've not really put it to the test,
but I think it's an interesting example of the flexibility of the Brzozowski derivative,
and it was at least mildly surprising to me that the edit ball of a regular language is itself regular.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-08-31-06:57.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-08-30-12:39.html</id>
    <title>Mathjax and Python Markdown</title>
    <updated>2018-08-30T13:01:27+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;Mathjax and Python Markdown&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-08-30&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 I've been having an interesting time of things with this notebook and getting Python markdown and Mathjax to play well with each other.
In particular I have not been enjoying the markdown extension API at
 &lt;em&gt;
  all&lt;/em&gt;.&lt;/p&gt;


&lt;p&gt;
 Anyway, it turns out that it is easy to do what I need, just slightly undocumented and with some annoyingly silent failure modes.&lt;/p&gt;


&lt;p&gt;
 Here is the (slightly simplified) code from this notebook that makes MathJax work correctly:&lt;/p&gt;


&lt;div class="codehilite"&gt;
&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;markdown.inlinepatterns&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;HtmlPattern&lt;/span&gt;

&lt;span class="n"&gt;LATEX_BLOCK&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;r&lt;/span&gt;&lt;span class="s2"&gt;"(&lt;/span&gt;&lt;span class="se"&gt;\\&lt;/span&gt;&lt;span class="s2"&gt;begin{[^}]+}.+?&lt;/span&gt;&lt;span class="se"&gt;\\&lt;/span&gt;&lt;span class="s2"&gt;end{[^}]+})"&lt;/span&gt;
&lt;span class="n"&gt;LATEX_EXPR&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;r&lt;/span&gt;&lt;span class="s2"&gt;"(&lt;/span&gt;&lt;span class="se"&gt;\\&lt;/span&gt;&lt;span class="s2"&gt;\(.+?&lt;/span&gt;&lt;span class="se"&gt;\\&lt;/span&gt;&lt;span class="s2"&gt;\))"&lt;/span&gt;


&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;MathJaxAlignExtension&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;markdown&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Extension&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;extendMarkdown&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;md&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;md_globals&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;# Needs to come before escape so that markdown doesn't break use of \ in LaTeX&lt;/span&gt;
        &lt;span class="n"&gt;md&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;inlinePatterns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'mathjaxblocks'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;HtmlPattern&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;LATEX_BLOCK&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;md&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s1"&gt;'&amp;lt;escape'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;md&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;inlinePatterns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'mathjaxexprs'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;HtmlPattern&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;LATEX_EXPR&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;md&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s1"&gt;'&amp;lt;escape'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;
 The HtmlPattern class takes an expression and treats anything matching that expression as something that the markdown processor should not touch further.&lt;/p&gt;


&lt;p&gt;
 Some caveats to note:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
  Those brackets around the expression? Those are
  &lt;em&gt;
   important&lt;/em&gt;. The way that the regular expression processing works is that it messes with your regex a bit, and then uses capturing group \(2\) as the output (\(1\) will be everything in the current block prior to the start of your regex). This means that if you must use groups in your regex, make them named groups.&lt;/li&gt;
&lt;li&gt;
  For reasons I haven't fully understood and have chosen not to bother understanding because the current behaviour is correct for my needs, despite allegedly being an HTML block, this extension does seem to do entity escaping on the contents of your MathJax.&lt;/li&gt;&lt;/ul&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-08-30-12:39.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-08-30-07:50.html</id>
    <title>2018-08-30-07:50</title>
    <updated>2018-08-30T12:39:05+01:00</updated>
    <content>

&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-08-30&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 I'm going to start trying to port over some contents from
 &lt;a href="https://github.com/DRMacIver/research-notebook"&gt;
  my research notebook&lt;/a&gt;
 into here,
as this is intended long-term to be a replacement for it.
This will require some figuring out in terms of how to present maths.&lt;/p&gt;


&lt;p&gt;
 As a starting point,
here's a theorem:&lt;/p&gt;


&lt;p&gt;
 \(H(m) = \sum\limits_{q = 1}^m {(-1)}^{q - 1} {m \choose q} \frac{1}{q}\)&lt;/p&gt;


&lt;p&gt;
 Where \(H(m)\) is the m'th harmonic number \(H(m) = \sum\limits_{i}^m \frac{1}{i}\).&lt;/p&gt;


&lt;p&gt;
 This came up in "Birthday Paradox, Coupon Collectors, Caching Algorithms and Self-Organizing Search" by Flajolet et al. (which is excellent) where it was stated as "well known". It wasn't well known to
 &lt;em&gt;
  me&lt;/em&gt;
 ,
so I set out to prove it.&lt;/p&gt;


&lt;p&gt;
 The following is my proof:&lt;/p&gt;


&lt;p&gt;
 The main idea is to use a standard tricks of turning sums and integrals into other sums and integrals that happen to be easier to solve.
We use the following standard results:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
  \(\frac{1}{n} = \int\limits_0^1 x^{n - 1}dx\)&lt;/li&gt;
&lt;li&gt;
  \((1 + x)^m = \sum\limits_{q=1}^m {m \choose q} x^q\)&lt;/li&gt;
&lt;li&gt;
  \((1 - x)^{-1} = \sum\limits_{q = 0}^\infty x^q\) for \(|x| &amp;lt; 1\).&lt;/li&gt;&lt;/ul&gt;


&lt;p&gt;
 We then perform the following manipulations (don't worry if some of these are clear as mud. They kinda should be):&lt;/p&gt;


&lt;p&gt;
 \begin{align}
\sum\limits_{q = 1}^m {(-1)}^{q - 1} {m \choose q} \frac{1}{q} &amp;amp;= \sum\limits_{q = 1}^m {(-1)}^{q - 1} {m \choose q} \int\limits_0^1 x^{q - 1} dx\\
&amp;amp;= \int\limits_0^1 \sum\limits_{q = 1}^m {(-1)}^{q - 1} {m \choose q} x^{q - 1} dx\\
&amp;amp;= \int\limits_0^1 -x^{-1} \sum\limits_{q = 1}^m {m \choose q} {(-x)}^q dx\\
&amp;amp;= \int\limits_0^1 -x^{-1} \left( \sum\limits_{q = 0}^m {m \choose q} {(-x)}^q - 1 \right)dx \\
&amp;amp;= \int\limits_0^1 -x^{-1} \left( {(1 - x)}^m - 1 \right)dx \\
&amp;amp;= \int\limits_0^1 {(1 - x)}^{-1} (x^m - 1) dx \\
&amp;amp;= \int\limits_0^1 \sum\limits_{n = 0}^\infty x^n (x^m - 1) dx \\
&amp;amp;= \sum\limits_{n = 0}^\infty \int\limits_0^1 x^n (x^m - 1) \\
&amp;amp;= \sum\limits_{n = 0}^\infty \frac{1}{n + m} - \frac{1}{n} \\
&amp;amp;= \lim\limits_{k \to \infty}  H(m) - \sum\limits_{n = k}^{m + k} \frac{1}{n + m}\\
&amp;amp;= H(m)\\
\end{align}&lt;/p&gt;


&lt;p&gt;
 Notable magic tricks performed:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
  \(\int\limits_0^1 -x^{-1} \left( {(1 - x)}^m - 1 \right)dx  \to \int\limits_0^1 {(1 - x)}^{-1} (x^m - 1) dx \) is a change of variables \(x \to 1 - x\).&lt;/li&gt;
&lt;li&gt;
  \(\sum\limits_{n = 0}^\infty \frac{1}{n + m} - \frac{1}{n} \to \lim\limits_{k \to \infty}  H(m) - \sum\limits_{n = k}^{m + k} \frac{1}{n + m}\) is because you can use a change of variables \(k \to k - m\),
and then group the terms that cancel out.&lt;/li&gt;
&lt;li&gt;
  The final limit is because \(|\sum\limits_{n = k}^{m + k} \frac{1}{n + m}| \leq \frac{m}{k}\).&lt;/li&gt;&lt;/ul&gt;


&lt;p&gt;
 This is a style of calculation I think of as the Feynmann style because
 &lt;del&gt;
  it's very good at seeming more clever than it actually is&lt;/del&gt;
 he was fond of smugly boasting about using this sort of trick in preference to contour integration.
Given its prevalence prior to Feynmann, my only defence of the terminology is that it's not really intended as a compliment.&lt;/p&gt;


&lt;p&gt;
 I find the Feynmann style completely unenlightening to read - the only way to read a Feynmann style proof is to do it yourself, using the original as a guide when you get stuck.&lt;/p&gt;


&lt;p&gt;
 I think that's in some ways its point. It's not a proof technique designed to leverage enlightenment,
but instead it leans heavily on your puzzle solving skills. That can be useful sometimes when you just want to brute force your way through a problem and don't really care about understanding it on any sort of deeper level.&lt;/p&gt;


&lt;p&gt;
 I was exposed to the Feynmann style quite early on,
due to reading Schaum's Outlines of Advanced Calculus (an earlier edition. I'm not sure how early. Brown covered one. I sadly gave away my copy, and the 1974 edition one I ordered doesn't seem to be quite it) prior to going to university.
It has quite a lot of exercises using calculations like this,
and afterwards I realised that this is what Feynmann had been talking about in "Surely you're joking, Mr Feynmann" (I didn't understand what a contour integral was until a few years later).&lt;/p&gt;


&lt;p&gt;
 Somehow despite this the Feynmann style of brute force problem solving never really integrated into my mathematics,
and it's only some years later I've come to appreciate its merits.
I
 &lt;em&gt;
  still&lt;/em&gt;
 prefer to achieve insight and make the problem trivial,
but sometimes the problem isn't worth the insight and you're better off just putting in the hard work and solving it.&lt;/p&gt;


&lt;p&gt;
 Putting in the hard work is also useful because sometimes it leads you to the insight you missed and you can throw away most of the work.
This didn't happen here,
but I think that's OK - it's not that interesting a problem,
so I don't really feel upset by the lack of insight into it.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-08-30-07:50.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-08-29-09:35.html</id>
    <title>Notes on tiling with polyominoes</title>
    <updated>2018-08-29T12:23:11+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;Notes on tiling with polyominoes&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-08-29&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 Gary Fredericks wrote about
 &lt;a href="https://gfredericks.com/gfrlog/99"&gt;
  a backtracking algorithm for tiling a board with polyominoes&lt;/a&gt;.&lt;/p&gt;


&lt;p&gt;
 His solution is roughly "turn the problem into exact cover and then apply a bunch of interesting optimisations in this context to the naive backtracking algorithm".
The paper
 &lt;a href="https://arxiv.org/pdf/cs/0011047.pdf"&gt;
  Dancing Links&lt;/a&gt;
 by Donald E. Knuth in fact studies this exact problem as an application of the exact cover algorithm.&lt;/p&gt;


&lt;p&gt;
 I think some of the optimisations Gary performs are not ones that would be performed by a modern SAT solver because they are actually too expensive to be worth it if you're good at the SAT problem-e.g.
I know modern SAT solvers tend not to bother decomposing problems into independent problems because the cost is too high-but
it's possible they synergise well enough to be worth it. e.g. the number theory optimisation combined with the independent components may well be worth it,
especially with the heuristic of prioritising moves that disconnect the board.&lt;/p&gt;


&lt;p&gt;
 I've been doing a bit of casual reading about this class of problem recently.
I thought I'd use the opportunity of this new notebook to collect some references.
Ideally these would be proper cites,
but I haven't got the citation part of the notebook system working yet.&lt;/p&gt;


&lt;p&gt;
&lt;a href="https://www.jstor.org/stable/pdf/2307321.pdf"&gt;
  Checker Boards and Polyominoes&lt;/a&gt;
 by Solomon W. Golomb is a classic here.
It looks at the question of tiling the chessboard with a single square monomino and 11 tetrominos of various shapes.
In particular it establishes:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
  You can do this with right tetrominoes given any placement of the monomino&lt;/li&gt;
&lt;li&gt;
  There are only four squares where you can place the monomino if you want to do it with straight tetrominoes.&lt;/li&gt;&lt;/ul&gt;


&lt;p&gt;
&lt;a href="http://chalkdustmagazine.com/blog/polyominoes/"&gt;
  How to Tile a Chessboard&lt;/a&gt;
 by Trupti Patel is a nice expository piece on this.&lt;/p&gt;


&lt;p&gt;
 Golomb also wrote
 &lt;a href="http://publisher-connector.core.ac.uk/resourcesync/data/elsevier/pdf/03f/aHR0cDovL2FwaS5lbHNldmllci5jb20vY29udGVudC9hcnRpY2xlL3BpaS9zMDAyMTk4MDA2NjgwMDMzOQ%3D%3D.pdf"&gt;
  Tiling with Polyominoes&lt;/a&gt;
 ,
studying much more general questions of how to tile truncated chessboards with polyominoes.&lt;/p&gt;


&lt;p&gt;
 A classic version of this is what
 &lt;a href="https://en.wikipedia.org/wiki/Mutilated_chessboard_problem"&gt;
  Wikipedia refers to as the mutilated chessboard problem&lt;/a&gt;
 (apparently following Max Black):&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  Suppose a standard 8×8 chessboard has two diagonally opposite corners removed, leaving 62 squares. Is it possible to place 31 dominoes of size 2×1 so as to cover all of these squares?&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 The answer is no. In
 &lt;a href="https://www.tandfonline.com/doi/pdf/10.1080/07468342.2004.11922062"&gt;
  Tiling with Dominoes&lt;/a&gt;
 , N. S. Mendelsohn discusses two proofs:&lt;/p&gt;


&lt;blockquote&gt;
&lt;h3&gt;
  First solution&lt;/h3&gt;
&lt;p&gt;
  From the checkerboard diagram, the region contains 30 black cells and 32 white cells.
Since each domino covers 1 black and 1 white cell, tiling is impossible.&lt;/p&gt;
&lt;h3&gt;
  Second solution&lt;/h3&gt;
&lt;p&gt;
  When I was first shown the problem many years ago, it did not occur to me to colour
the cells. The region itself had seven cells in the top and bottom rows and eight cells in
the remaining rows. The same held for the columns. I proceeded to obtain information
on how many dominoes pointed horizontally and how many vertically. The first count
dealt with the vertical dominoes. If the region is tiled, the horizontal dominoes in the
top row occupies an even number of cells. Hence, the cells in the top row that are not
occupied by horizontal dominoes are odd in number. Thus there are an odd number of
vertical dominoes between the first and second rows. Since the second row has eight
cells, and an odd number are occupied by vertical dominoes coming down from the
first row, there remain an odd number of cells in the second row. The same argument
now shows there is an odd number of vertical dominoes from the second row to the
third. Continuing this way, we see that there is an odd number of vertical dominoes
between any pair of consecutive rows. Hence the total number of vertical dominoes is
the sum of seven odd numbers, which is odd. In the same way, using columns instead
of rows, there is an odd number of horizontal dominoes. Hence the total number of
dominoes is even. Since there are 62 cells to cover, the number of dominoes required
is 31, an odd number. Therefore, tiling is impossible.&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 He goes on to say:&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;
  Why do I produce two solutions to the puzzle? It is because I am interested in
the question of which is the better solution. At first glance, it appears that the first
solution is the better. It is much shorter and is easily understood by many people with
virtually no knowledge of mathematics. But are there considerations that might judge
the second solution to be the better one?&lt;/p&gt;&lt;/blockquote&gt;


&lt;p&gt;
 He then discusses whether the second one is better because it generalises better,
when setting out to prove Gomory's theorem (which I've not been able to find a copy of the original of so far, but I haven't looked very hard):
If you remove two squares of the same colour, you can always tiling the remainder with dominoes.
The proof involves the construction of a hamiltonian circuit on the adjacency graph,
and seems fiddly but interesting.
I've only skimmed it and would like to digest it further.&lt;/p&gt;


&lt;p&gt;
 However note that we saw a generalisation in a different direction in the first paper linked! Golomb's proof of the impossibility tiling with straight tetrominoes unless the monomino was in a very specific location was
 &lt;em&gt;
  also&lt;/em&gt;
 a colouring argument.&lt;/p&gt;


&lt;p&gt;
 The wikipedia page references "Across the board: the mathematics of chessboard problems" by John J. Watkins.
I should probably look up a copy.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-08-29-09:35.html" rel="alternate"/>
  </entry>
  <entry>
    <id>https://notebook.drmaciver.com/posts/2018-08-28-08:14.html</id>
    <title>First!</title>
    <updated>2018-08-28T14:18:34+01:00</updated>
    <content>

&lt;p class="subtitle"&gt;First!&lt;/p&gt;


&lt;dl class="metadata"&gt;
&lt;dt&gt;Published&lt;/dt&gt;
&lt;dd class="post-date"&gt;2018-08-28&lt;/dd&gt;
&lt;/dl&gt;


&lt;p&gt;
 This is an experimental new blog intended for notes, thoughts, and whatever else I want to put here.
It will likely be biased towards short notes rather than longform essays.
It's loosely inspired by
 &lt;a href="https://shitpost.plover.com/"&gt;
  Mark Jason Dominus's shitposting blog&lt;/a&gt;
 and by my frustrations with WordPress, but I'm not really sure where it's going yet.&lt;/p&gt;


&lt;p&gt;
 It's also a place where I'll be experimenting with notation,
and generally trying to find a low friction way to express myself in a manner that I like.
As such it's all a bit cobbled together out of spit, bailing wire, and Python.&lt;/p&gt;


&lt;h3&gt;
 Notational Highlights&lt;/h3&gt;


&lt;p&gt;
 I kinda hate LaTeX, but it's the best typesetting language for mathematics that I know of,
so this notebook supports it using
 &lt;a href="https://www.mathjax.org/"&gt;
  mathjax&lt;/a&gt;.&lt;/p&gt;


&lt;p&gt;
 Testing: \(e^{i\pi} = -1\)&lt;/p&gt;


&lt;p&gt;
 A test of code highlighting.&lt;/p&gt;


&lt;div class="codehilite"&gt;
&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;SomeClass&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;""""A python class"""&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;method&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;"""A method definition"""&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;
 As you've probably noticed, I'm using
 &lt;a href="https://edwardtufte.github.io/tufte-css/"&gt;
  Tufte CSS&lt;/a&gt;.
I'm not sure it's exactly what I want, but it's a lot closer to what I want than most other things I've tried.
I will likely be messing aroudn with this further.&lt;/p&gt;


&lt;p&gt;
 I'm also using
 &lt;a href="http://www.makotemplates.org"&gt;
  mako templates&lt;/a&gt;
 ,
and fully intend to define a metric tonne of macros to make this usable.&lt;/p&gt;


&lt;p&gt;
 In general I expect the actual source code for this site to be totally unusable to anyone who is not me.
If anything,
if it's
 &lt;em&gt;
  not&lt;/em&gt;
 then I probably haven't done enough customization for my brain.&lt;/p&gt;

</content>
    <link href="https://notebook.drmaciver.com/posts/2018-08-28-08:14.html" rel="alternate"/>
  </entry>
</feed>
