<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
    <title>
DRMacIver's Notebook: What is a neural network?
    </title>
    <link rel="stylesheet" href="/pygments.css"/>
    <link rel="stylesheet" href="/tufte.css"/>
    <link rel="stylesheet" href="/latex.css"/>
    <link rel="stylesheet" href="/drmnotes.css"/>
    <link rel="alternate" type="application/atom+xml" title="Atom Feed" href="/feed.xml" />

    <meta name="viewport" content="width=device-width, initial-scale=1">

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(', '\\)']]},
  multiLine: true,
  "HTML-CSS": { 
       linebreaks: { automatic: true }
  },
  SVG: { 
       linebreaks: { automatic: true } 
  }
});
</script>

  </head>

  <body>
    <article>
        <h1><a href="/">DRMacIver's Notebook</a></h1>
        <p class=subtitle>What is a neural network?</p>

        

<section id="the-post">
<p class=subtitle>What is a neural network?</p>
<dl class=metadata>
<dt>Published</dt>
<dd class="post-date">2018-09-28</dd>
</dl>
<p>
 These are some notes I put together in response to the question "How would you explain neural networks to business people?"</p>
<p>
 The following are the most important things to understand about neural networks:</p>
<ul>
 <li>
  Neural networks are an interesting implementation technique for a well studied set of problems.</li>
 <li>
  Neural networks do not allow a machine to "think" in any general sense - they are mostly useful for implementing simple decision procedures and predictive models, but they do not do any general reasoning or planning (they may be used as components in systems that do though).</li>
 <li>
  Neural networks are only as good as the data you give them.</li></ul>
<h3>
 What do neural networks do?</h3>
<p>
 The general problem that neural networks solve is called
 <em>
  machine learning</em>. This is a somewhat misleading term because how machines "learn" in this sense doesn't map that well to how humans learn.
A less catchy but more accurate term might be "statistics done with more computers and less rigour", but you get less VC investment if you say that so people mostly call it machine learning.
There are many ways to do machine learning, and any given instance of it is a particular
 <em>
  algorithm</em>
 , a precise set of rules that describe how the computer "learns" in this particular problem.</p>
<p>
 Any machine learning always starts with some set of data that we "train" on.
Typically we present this to the machine learning algorithm as a collection of
 <em>
  features</em>. These might be, say, raw pixel data from an image, or they might be properties like "age", "gender", "country of birth". Whatever they are, they are some abstracted view of the picture that allows us to represent the data as a collection of numbers.
Sometimes the data is presented entirely up front, and sometimes the algorithm is designed so that it can learn as you go. I believe the former is much more common, especially with neural networks.</p>
<p>
 One important difference between machine and human learning is that machine learning tends to need a lot more data than you would expect. Often we train our machine learning algorithms on hundreds of thousands, or millions of data points, where you might expect a human to learn after only a few. It takes a lot longer for most machine learning approaches to learn what a picture of a dog looks like than it does a toddler. Some of this is probably because of the generality of these approaches (a toddler will take much longer to learn to predict life expectancy accurately), with humans having a lot of visual processing stuff "baked in", while some of it is probably due to genuine limitations of the approaches we use.
This is where "big data" comes in. There are a lot of arguments as to what should count as big data, but a good rule of thumb is "if you can fit it on a single computer then it's not big data". Given how large computers can affordably get these days, most things that people call big data probably aren't.</p>
<p>
 Anyway, given a set of input data, there are roughly three types of commonly studied machine learning that we can do with it:</p>
<ul>
 <li>
  Supervised learning, which takes some input data and some labels or scores for it, and tries to learn how to predict those labels or scores for other similar data. For example, you might want to classify an email as "spam" or "not spam", or you might want to predict the life expectancy of someone given a set of data about their health.</li>
 <li>
  Reinforcement learning, where you have a bunch of input data and you want to make decisions about it. Based on the outcome of the decision, you feed back into the process with either a "reward" or a "punishment" (I want to emphasise again that this is a metaphor and the algorithm is not in any meaningful sense thinking), and the algorithm adjusts its decision making process to favour decisions that look like ones that have rewarded it and to avoid ones that ook like ones that have punished it. e.g. you might use this for stock picking, and reward the algorithm for picking stocks that do well and punish it for picking stocks that do badly.</li>
 <li>
  Unsupervised, which builds a model of the "shape" of the data. I won't talk about this too much, but if you've seen those deep dream pictures or "I trained a bot on this corpus of text and this is what I got" articles, that's what's goign on here: The system has built a predictive model of the data and is used to randomly generate something that matches that model.</li></ul>
<p>
 Almost all applications of machine learning you hear about are one of these three things, possibly with some additional logic layered on top.
For example AlphaGo, Google's Go playing AI, is roughly a combination of all three in a rules based system that describes the rules of Go, and uses the output of the machine learning to choose moves.</p>
<p>
 There are a very large number of different approaches you can take to these problems, of which neural networks are only one of them.
An easy to understand and classic approach to machine learning is the use of decision trees: Simple rules of the form "If (this feature has this range of values) then (do this) else (do this other thing)".
These are very easy to learn - you pick some feature that splits the data set well,
break the data set into two parts based on that, and then try again on the smaller parts. If nothing works particularly well, you add a rule that says "Predict (most common outcome)" (I am eliding a lot of details here that don't matter to you unless you want to actually implement these ideas).</p>
<p>
 One classic limitations that machine learning struggles with is in learning patterns that require understanding complex aspects of the data that are not easily understood from a small number of features.
If you imagine image processing, to the computer a small image is just a list of a couple hundred thousand numbers.
A human would struggle to get anything useful from that too!</p>
<p>
 Neural networks attempt to overcome this by learning in
 <em>
  layers</em>.
Each layer consists of something that looks a bit like unsupervised learning and a bit like supervised learning, where each layer "learns" to extract high level features from the one below.
In the image case you start with the bottom layer that looks at the raw pixel data, and then it might e.g. try to identify patterns of lines in that data.
Each layer is essentially a new set of features that takes the overly detailed previous layer's features and tries to turn it into a representation that it can more easily work with.
This allows us to combine a very simple learning technique (the "neurons" that are really just a very simple bit of machine learning that tries to turn a set of features into a score between zero and one) into a much more complex one that is able to handle high level features of the data.
This is where the "deep" in "deep learning" comes from - a deep neural network is one with many layers.</p>
<p>
 What this means in practice is that decisions that are "obvious" given the right representation of the data but completely non-obvious given the original representation of the data may be tractable to neural networks but insoluble for machine learning techniques that are in some sense "shallower".
Some times these higher level representations will be ones that are obvious to humans (e.g. lines in images), but often they will not be, especially (e.g. they capture some strategic aspect of the Go board).</p>
<h3>
 Why are neural networks cool right now?</h3>
<p>
 Neural networks are not at all new technology, but are recently seeing a revival for a number of reasons:</p>
<ul>
 <li>
  We have a lot more data now, which allows us to paper over any limitations by just training it more.</li>
 <li>
  We have much faster computers now, particularly as a lot of neural network training can be made highly parallel (that means that you can break it up into small chunks that can be run at the same time without waiting for each other, then combine the results).</li>
 <li>
  We have made a number of incremental improvements to the algorithms that allow us to speed up our training and improve the quality of results.</li></ul>
<p>
 This has allowed us to apply them to problems where it was previously infeasible, which is the main source of all of the current progress in this field.</p>
<h3>
 What is going to go wrong when I use neural networks?</h3>
<p>
 This is important to understand, because things
 <em>
  will</em>
 go wrong.
The main things that it is important to understand about this are:</p>
<ol>
 <li>
  It is much more important to have good input data than good algorithms, and gathering good input data is expensive. Machine learning is only as good as its training, and if your input data is biased or missing important examples, your machine learning will perform badly. e.g. A classic failure mode here is that if you train image recognition only on white people, it will often fail to see people of colour.</li>
 <li>
  Compared to a human decision maker, neural networks are
  <em>
   fragile</em>. There is an entire class of things called "adversarial examples" where trivial changes that a human wouldn't even notice cause the neural network to output an entirely different answer.</li>
 <li>
  Even without adversaries, machine learning algorithm
  <em>
   will</em>
  make stupid goofs that are obvious to a human decision maker. It will do this even if it is on average better than a human decision maker. This is simply because different things are obvious to machines and humans. Depending on how visible these decisions are, this will probably make you look silly when it happens.</li></ol>
<h3>
 When should I use neural networks?</h3>
<p>
 First off, you should not be making a decision about whether to use neural networks if this article is teaching you new things.
You should be making a decision on whether to use
 <em>
  machine learning</em>. Leave the decision of what type you should be using to an expert - there is a good chance they will choose neural networks (tech people are very trend driven),
but there might be something simpler and better suited for your problem.</p>
<p>
 Roughly the following rules of thumb should help you decide whether to use machine learning:</p>
<ol>
 <li>
  Is this a problem that would benefit from being able to make lots of fairly constrained decisions very fast? If no, then
  <em>
   maybe</em>
  talk to an expert (some problems don't look like this on the face of it but can still benefit - e.g. translation isn't obviously of this form, but it can benefit from machine learning), but you're probably out of luck and even if you're not this is going to be a huge and expensive research project.</li>
 <li>
  If you had an averagely intelligent training human with maybe a couple of days of on the job training and enough background knowledge to understand the problem making those decisions, would their answers be good enough? If no, you're really going to struggle to get your machine learning to be good enough.</li>
 <li>
  Think through the failure modes of the previous section. Do you have a plan in place to avoid them, or to mitigate them when they occur? Is the cost of that plan worth the benefits of using machine learning?</li>
 <li>
  Reflect on the following question: When someone in the media says "Why did you use a machine rather than a person here?" and your answer is "It was cheaper", how is it going to play out and are you happy with that outcome? If no, your problem is probably politically a poor fit for machine learning.</li></ol>
<p>
 If your problem passed all of those tests, it might well be amenable to machine learning. Go talk to an expert about it.</p>
</section>

    </article>
<footer>
Copyright David R. MacIver.

CSS mostly due to <a href="https://edwardtufte.github.io/tufte-css/">Tufte CSS</a> by Dave Liepmann.
</footer>
  </body>
</html>
