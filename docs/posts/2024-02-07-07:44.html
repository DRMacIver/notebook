<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
    <title>
DRMacIver's Notebook: The obligation to be who you are
    </title>

    <meta property="og:title" content="The obligation to be who you are">

    <meta property="og:url" content="https://notebook.drmaciver.com/posts/2024-02-07-07:44.html" />
    <link rel="canonical" href="https://notebook.drmaciver.com/posts/2024-02-07-07:44.html" />
    <script src="https://hypothes.is/embed.js" async></script>


    <meta name="twitter:card" content="summary" />

    <meta property="og:creator" content="@DRMacIver">

    <link rel="stylesheet" href="/pandoc.css"/>
    <link rel="stylesheet" href="/pygments.css"/>
    <link rel="stylesheet" href="/tufte.css"/>
    <link rel="stylesheet" href="/latex.css"/>
    <link rel="stylesheet" href="/drmnotes.css"/>
    <link rel="alternate" type="application/atom+xml" title="Atom Feed" href="/feed.xml" />

    <meta name="viewport" content="width=device-width, initial-scale=1">

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['\\(', '\\)']]},
  multiLine: true,
  "HTML-CSS": { 
       linebreaks: { automatic: true }
  },
  SVG: { 
       linebreaks: { automatic: true } 
  }
});

MathJax.Hub.Register.MessageHook("Math Processing Error", function(message) {
  console.log(message)
});

</script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-169185204-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-169185204-1');
</script>

  </head>

  <body>
    <article>
        <h1><a href="/">DRMacIver's Notebook</a></h1>
        <p class=subtitle>The obligation to be who you are</p>

        

<section id="the-post">
<p class=subtitle>The obligation to be who you are</p>
<dl class=metadata>
<dt>Published</dt>
<dd class="post-date">2024-02-07</dd>
</dl>

<p>This post is extremely in the weeds. If you don’t care about moral
philosophy, it’s possibly not for you, though I do think the claim I am
making has important practical implications beyond the theoretical
argument. Also I ran out of steam towards the end.</p>
<p>Anyway, the following footnote to <a href="https://notebook.drmaciver.com/posts/2024-02-06-10:51.html">yesterday’s
post about responsibility</a> sparked some discussion about moral
relativism.</p>
<p>I’d like to stake out a particular position. First, I’m going to need
to stake out some idiosyncratic terminology.<label class="margin-toggle sidenote-number" for="fn1"></label><input class="margin-toggle" id="fn1" type="checkbox"/><span class="sidenote">Possibly many of these have existing terms in the
philosophical literature, or the terms I’m using mean something subtly
different in the literature, but I’m a programmer so I haven’t done the
reading and have to rewrite things in my own terms to understand them.</span></p>
<p>First, let’s sketch out what I mean by an <strong>moral
framework</strong>. I’m not going to define this precisely, but I mean
something like a coherent body of theory and practice that lets you do
things like make judgements about “good” and “bad” and in particular to
make “should” claims, especially about behaviour. Ethical frameworks let
you make judgements about specific questions, and also have a body of
principles and practices for making arguments about moral claims.</p>
<p>The boundaries of specific moral frameworks are fuzzy, and it can be
hard to point and say that two things you might think of as moral
frameworks definitively are the same, but it’s often easy to point out
that they’re definitely not the same by finding subjects on which they
disagree. e.g. someone operating in an moral framework that embraces
vegetarianism will disagree with someone who is non-vegetarian’s moral
framework around wether eating meat is bad.</p>
<p><strong>Moral realism</strong> is the position that there is one<label class="margin-toggle sidenote-number" for="fn2"></label><input class="margin-toggle" id="fn2" type="checkbox"/><span class="sidenote">Up to isomorphism.</span> correct moral framework and all
others are good to the degree they approximate that framework.<label class="margin-toggle sidenote-number" for="fn3"></label><input class="margin-toggle" id="fn3" type="checkbox"/><span class="sidenote">Note that this doesn’t require making a claim that a
particular moral framework is the objectively correct one, or even that
the objectively correct one is in principle fully discoverable.</span></p>
<p><strong>Moral relativism</strong> is the position that there are at
least two moral frameworks that disagree on crucial details and that you
cannot decide between in a non-arbitrary way.<label class="margin-toggle sidenote-number" for="fn4"></label><input class="margin-toggle" id="fn4" type="checkbox"/><span class="sidenote">Note that, at least how I use it, moral relativism is
compatible with the claim that some moral frameworks are objectively
better than other moral frameworks. It doesn’t require that you can’t
decide between <em>any</em> two moral frameworks in a non-arbitrary way,
only that there are genuine degrees of freedom in how you adopt an moral
framework.</span></p>
<p>I’d like to then subdivide these further:</p>
<p><strong>Abstract</strong> realism/relativism is the set of claims of
realism and relativism respectively as regards to whether the moral
framework is theoretically defensible. i.e. it’s a claim about which one
is in some sense “objectively correct”.</p>
<p><strong>Practical</strong> realism/relativism is about how you orient
to other people operating in other moral frameworks than your own, and
whether you treat their moral frameworks as valid for them. This is more
a matter of degrees than the theoretical version is I think (or at
least, certainly is a matter of degrees, and if the theoretical one is
then it’s not obvious to me).</p>
<p>I think it’s clear that everyone operates on some minimal degree of
practical realism, in that people disagree about ethics without needing
to constantly argue about it, and it’s quite important that in a
multicultural society people be allowed to do this.<label class="margin-toggle sidenote-number" for="fn5"></label><input class="margin-toggle" id="fn5" type="checkbox"/><span class="sidenote">Even if you think multiculturalism is bad, you still
have to deal with the fact that other cultures exist and you have to
interact with them. I will grant that someone who is a total cultural
isolationist may not be operating on any degree of practical relativism,
but that would be one of those moral frameworks that I do think is
objectively worse than others.</span></p>
<p>But I’d like to argue for the compatibility of a particular moral
claim that demonstrates the compatibility of strong forms of abstract
realism with practical relativism, based on the following claim: Given
two people, let’s call them Alex and Charlie, who agree on a shared
moral framework (which I’ll make certain implicit basic assumptions
about not being too alien from my own) as the “universally correct” one,
it is possible (and indeed likely, although I won’t argue for this too
strongly), for Alex and Charlie to want to adopt more specific moral
frameworks for their behaviour that make stronger claims than their
shared framework, and each of which make moral claims that are
incompatible with the other’s.</p>
<p>In this view, even if Alex and Charlie are both abstract moral
realists and think that their shared moral framework is objectively
correct, they become practical moral relativists of a particularly
strong form: Each has their own “moral truths” that do not apply to the
other, and they consider both binding for themselves and non-binding for
the other, without thinking the other is wrong for holding their own
moral framework.</p>
<p>First, let’s consider two categories of example where Alex and
Charlie make different moral judgements about their own behaviour that
are <em>not</em> examples of relativism, but will point us in the right
direction:</p>
<ol type="1">
<li>Should I kiss this attractive person who is enthusiastically hitting
on me (and who satisfies all relevant criteria such as being e.g. above
the age of consent, unrelated to me, uncommitted to anyone else,
etc)?</li>
<li>Should I build a bridge that I’ve been asked to build as part of my
job?</li>
</ol>
<p>The first hinges on a particular person-centric question: Do I have
any obligations not to do that? e.g. am I in a committed monogamous
relationship with someone else?</p>
<p>This isn’t moral relativism in that the actual moral principle being
adopted is something like “If you do not have any obligations that are
not committing you to not do so, go for it buddy”. What differs is not
the moral framework but the individual’s specific obligations.</p>
<p>Note that this already gets you quite far towards relativism. If
e.g. you profess to be a devout Christian, this creates a significant
set of obligations to behave as a devout Christian, even if those moral
commitments are not ones that you would have in generality.<label class="margin-toggle sidenote-number" for="fn6"></label><input class="margin-toggle" id="fn6" type="checkbox"/><span class="sidenote">For a sufficienly Christianity-incompatible objective
morality you might of course have an obligation not to be a devout
Christian. No comment here on whether that’s the case, just highlighting
the conditional.</span></p>
<p>The second depends a lot on whether you’re good at building bridges
or not. If you are, and it’s your job (and you’re not in some outlandish
situation where the existence of the bridge itself would be immoral),
then yeah you probably should. If on the other hand you have no
bridge-building related skills, you should signal strongly that this is
not your thing and no you will not build a bridge because it falls
down.</p>
<p>Again, similarly to the above, there is no actual conflict here. I
think you can quite straightforwardly make a moral principle of “don’t
do things you don’t have the skills to do, especially if peoples’ safety
is on the line” which both Alex and Charlie agree on and that just
happens to cash out differently depending on their respective
skills.</p>
<p>Both of these point to a sort of “scoped moral framework” of a type
that I think should be perfectly uncontroversial even for the most
adamant of moral realists (though they might object to labelling it a
“moral framework”): The moral framework you get when you take your
broader moral framework and specialise it down to specific
characteristics of the person in question. The body of judgements etc of
what’s good and bad for someone who is a monogamous artist, or a poly
engineer, or…</p>
<p>These scoped moral frameworks are, from a logically omniscient point
of view, just a subset of the broader moral framework. You just delete
the bits that don’t apply to you, and your behaviour will be perfectly
in line with the broader moral framework because all the bits that could
apply to you are the same as the broader framework’s judgements.</p>
<p>But we’re not logically omniscient. We’re finite beings. And as a
result when you cut down your moral framework more of it comes into
focus and you get to see how more of the parts of it interact. If you
regularly have interactions of a particular type, even if you derive
those interactions from first principles in your broader moral
framework, you’ll get better at that particular action and subsequently
others like it, and this will clarify some of your obligations…</p>
<p>Here’s a trivial example: When you leave the pub, do you take your
empty glasses back to the bar?</p>
<p>If you’ve worked bar, or you know other people who have, you are
probably aware that this makes their lives much easier, especially if
the pub is busy right now. Having the relevant life experience makes you
aware of this, but the facts of the matter are derivable from perfectly
general principles, you just haven’t noticed.<label class="margin-toggle sidenote-number" for="fn7"></label><input class="margin-toggle" id="fn7" type="checkbox"/><span class="sidenote">Or possibly have a genuine disagreement about your
obligations in this space! But even without this genuine disagreement
you can have a different awareness of obligations.</span></p>
<p>Here’s another similar example that went by recently:</p>
<p><a href="https://twitter.com/Kirsten3531/status/1755148835083411515"><img src="/images/baby-plate.png"/></a></p>
<p>I think this is perfectly obvious if you have the relevant life
experiences, and does not require those relevant life experiences to act
on, but is easy to miss.</p>
<p>Everyone is going to have their own collection of these little moral
duties<label class="margin-toggle sidenote-number" for="fn8"></label><input class="margin-toggle" id="fn8" type="checkbox"/><span class="sidenote">If you don’t like the word duty here, me neither. Feel
free to pick some other word. I don’t have a good word that means “like
a duty but not really fully obligatory, just good to do” and while I
like <a href="https://en.wikipedia.org/wiki/Ahkam">the Islamic
labels</a> I don’t know how to idiomatically apply them here.</span> that they adhere to. Even when they
are all derivable in principle from their shared understanding of what
leads to a moral duty, you’ll only have the ones you happen to have
learned, and the specific set will be idiosyncratic to you.</p>
<p>More, it’s not even totally clear that these should all “port
upwards” to be general norms, because of our finiteness. I think it’s
pretty plausible that the collective set of these little moral duties is
too large for any one person to keep in their head and reliably
implement without exhausting themselves, and that we’re better served by
a degree of heterogeneity where different people keep track of different
ones. I think it would be far too happy a coincidence for the exact
distribution that occurs to be the morally optimal one, but I think it’s
at least plausible that it is morally optimal for there to be some
distribution like it.</p>
<p>This creates a, I think intrinsically quite relativistic, stance of
“I acknowledge that this duty would be good to take on, and that it is
good that you have done, but I’m not going to choose to adopt it”.
Perhaps this is a <a href="https://notebook.drmaciver.com/posts/2024-01-17-09:02.html">cheeseburger
ethics</a> thing but it feels different to me.</p>
<p>This also ties into the skill issue. Many of these duties exist
<em>because you notice things</em>, and one of the key things expertise
does is change your perception of the world. Possessing a skill, even
when you’re not actively using it, can cause all sorts of things to come
into focus that you’d otherwise miss.</p>
<p>Note for readers: It was at this point I started running out of steam
in writing this and wanting to wrap it up, so the rest will be more of a
sketch than I intended it to be.</p>
<p>The other thing that I think drives these sorts of individual moral
duties is something like character. e.g. our professions don’t exist in
isolation. If we’re an engineer, we are implicitly committing to being
the sort of person who can do engineering well, and this will tend to
bleed into other areas <em>and we should probably let it</em>.</p>
<p>For example, another thing that came up in discussion of the
responsibilities post is that, as (responsible) software developers,
when problems occur with systems we see, we want to fix the system not
just the problem, and this isn’t widely shared. It seems both good to
retain this habit, both because it’s generally useful and also because
it’s part of the habit of character that allows us to be good at our
jobs, but also it’s sortof hard to argue that it’s a moral duty for
someone who doesn’t have a great deal of professional feedback on how to
develop this skill to also do these things, and a little unreasonable
for us to expect them to understand it when we try to point this out.<label class="margin-toggle sidenote-number" for="fn9"></label><input class="margin-toggle" id="fn9" type="checkbox"/><span class="sidenote">Though I still want them to fix the issue, dammit.</span> This is the skill issue again, but
running in the other direction: It’s not just that the skill alerts us
to obligations that we already have, but that trying to suppress the use
of it is in some sense detrimental to our character as developers.</p>
<p>All of this remains fully compatible with the possibility of a shared
broad moral framework, but the problem is that you can’t really
implement the fully worked out broad moral framework on humans. If Alex
and Charlie have their own moral frameworks with their own well thought
out details, there almost certainly <em>is</em> a moral framework that
unifies the two - it’s the shared framework, as implemented by someone
who has full knowledge of all of Alex and Charlie’s experiences and
possesses all of their skills. The problem is, taking that union quickly
exceeds human capacities.</p>
<p>For my part, I find it easier to think about this in terms of people
just having different moral frameworks. There are practices for sharing
things between our moral frameworks and a broad practice of moral
discourse, and in general we should expect our moral frameworks to be
more or less similar to those we share characteristics with and discuss
our lives with, but there remain plenty of incompatibilities where I can
acknowledge your moral duty as a moral truth for you, but choose not to
take it on as my own..</p>


</section>

    </article>
<footer>
Copyright David R. MacIver.

CSS mostly due to <a href="https://edwardtufte.github.io/tufte-css/">Tufte CSS</a> by Dave Liepmann.
</footer>
  </body>
</html>
